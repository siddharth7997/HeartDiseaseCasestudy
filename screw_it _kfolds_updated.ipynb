{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Risk Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Used: UCI Heart Disease Dataset\n",
    "This directory contains 4 databases concerning heart disease diagnosis.\n",
    "   All attributes are numeric-valued.  The data was collected from the\n",
    "   four following locations:\n",
    "\n",
    "     1. Cleveland Clinic Foundation\n",
    "     2. Hungarian Institute of Cardiology, Budapest\n",
    "     3. V.A. Medical Center, Long Beach, CA\n",
    "     4. University Hospital, Zurich, Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Instances: \n",
    "####        Database:    # of instances:\n",
    "          1. Cleveland: 303\n",
    "          2. Hungarian: 294\n",
    "          3. Switzerland: 123\n",
    "          4. Long Beach VA: 200\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Information:\n",
    "      1. age:age in years       \n",
    "      2. sex:(1 = male; 0 = female)       \n",
    "      3. cp:chest pain type\n",
    "          -- Value 1: typical angina\n",
    "          -- Value 2: atypical angina\n",
    "          -- Value 3: non-anginal pain\n",
    "          -- Value 4: asymptomatic\n",
    "      4. trestbps: resting blood pressure  \n",
    "      5. chol:cholestoral      \n",
    "      6. fbs:(fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)    \n",
    "      7. restecg:\n",
    "          -- Value 0: normal\n",
    "          -- Value 1: having ST-T wave abnormality \n",
    "          -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "      8. thalach:maximum heart rate achieved\n",
    "      9. exang:exercise induced angina (1 = yes; 0 = no)     \n",
    "      10. oldpeak:ST depression induced by exercise relative to rest   \n",
    "      11. slope:the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping     \n",
    "      12. ca: number of major vessels (0-3) colored by flourosopy        \n",
    "      13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "      14. category:diagnosis of heart disease[0-4]       (the predicted attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Information:\n",
    "     This database contains 76 attributes, but all published experiments\n",
    "     refer to using a subset of 14 of them.  In particular, the Cleveland\n",
    "     database is the only one that has been used by ML researchers to \n",
    "     this date.  The \"goal\" field refers to the presence of heart disease\n",
    "     in the patient.  It is integer valued from 0 (no presence) to 4.\n",
    "     Experiments with the Cleveland database have concentrated on simply\n",
    "     attempting to distinguish presence (values 1,2,3,4) from absence (value\n",
    "     0).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution:\n",
    "          Database:    0   1   2   3   4 Total\n",
    "          Cleveland: 164  55  36  35  13   303\n",
    "          Hungarian: 188  37  26  28  15   294\n",
    "        Switzerland:   8  48  32  30   5   123\n",
    "      Long Beach VA:  51  56  41  42  10   200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AGE  SEX  CP THRESTBPS CHOL FBS RESTECG THALACH EXANG OLDPEAK SLOPE CA  \\\n",
      "0   63    1   1       145  233   1       2     150     0     2.3     3  0   \n",
      "1   67    1   4       160  286   0       2     108     1     1.5     2  3   \n",
      "2   67    1   4       120  229   0       2     129     1     2.6     2  2   \n",
      "3   37    1   3       130  250   0       0     187     0     3.5     3  0   \n",
      "4   41    0   2       130  204   0       2     172     0     1.4     1  0   \n",
      "\n",
      "  THAL  CATEGORY  \n",
      "0    6         0  \n",
      "1    3         2  \n",
      "2    7         1  \n",
      "3    3         0  \n",
      "4    3         0  \n"
     ]
    }
   ],
   "source": [
    "df=pandas.read_csv('Preprocessed/data_combined.csv')\n",
    "print df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE           int64\n",
      "SEX           int64\n",
      "CP            int64\n",
      "THRESTBPS    object\n",
      "CHOL         object\n",
      "FBS          object\n",
      "RESTECG      object\n",
      "THALACH      object\n",
      "EXANG        object\n",
      "OLDPEAK      object\n",
      "SLOPE        object\n",
      "CA           object\n",
      "THAL         object\n",
      "CATEGORY      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    411\n",
      "1    265\n",
      "2    109\n",
      "3    107\n",
      "4     28\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Missing Attribute Values(WEKA TOOL)\n",
    "1. THRESTBPS(6%)\n",
    "2. RESTECG(2 values)\n",
    "2. CHOL(3%)\n",
    "3. FBS(10%)\n",
    "4. THALAC(6%)\n",
    "5. EXANG(6%)\n",
    "5. OLDPEAK(7%)\n",
    "6. SLOPE(34%)\n",
    "7. CA(66%)\n",
    "8. THAL(53%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values for THERESTBPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120    131\n",
      "130    115\n",
      "140    102\n",
      "110     59\n",
      "?       59\n",
      "Name: THRESTBPS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['THRESTBPS'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average rest blood pressure is  generally in range 120-140\n",
    "df['THRESTBPS'] = df['THRESTBPS'].replace(['?'],'120')\n",
    "df['THRESTBPS'] = df['THRESTBPS'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values for FBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    692\n",
      "1    138\n",
      "?     90\n",
      "Name: FBS, dtype: int64\n",
      "male:\n",
      "0    528\n",
      "1    119\n",
      "?     79\n",
      "Name: FBS, dtype: int64\n",
      "Female:\n",
      "0    164\n",
      "1     19\n",
      "?     11\n",
      "Name: FBS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print df.columns\n",
    "print df['FBS'].value_counts()\n",
    "print \"male:\\n\",df[df['SEX']==1]['FBS'].value_counts()\n",
    "print \"Female:\\n\",df[df['SEX']==0]['FBS'].value_counts()#directly replace with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    765\n",
      "1    155\n",
      "Name: FBS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#randomly filling values with 80% with 0 and 20% with 1s\n",
    "v=df.FBS.values=='?'\n",
    "df.loc[v, 'FBS'] = numpy.random.choice(('0','1'), v.sum(), p=(0.8,0.2))\n",
    "print df['FBS'].value_counts()\n",
    "df['FBS']=df['FBS'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing missing values in CHOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      172\n",
       "?       30\n",
       "254     10\n",
       "220     10\n",
       "216      9\n",
       "Name: CHOL, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CHOL'].value_counts().head()\n",
    "#evenly distributed...\n",
    "#so will replace with mean of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233 286 229 250 204 236 268 354 254 203 192 294 256 263 199 168 239 275\n",
      " 266 211 283 284 224 206 219 340 226 247 167 230 335 234 177 276 353 243\n",
      " 225 302 212 330 175 417 197 198 290 253 172 273 213 305 216 304 188 282\n",
      " 185 232 326 231 269 267 248 360 258 308 245 270 208 264 321 274 325 235\n",
      " 257 164 141 252 255 201 222 260 182 303 265 309 307 249 186 341 183 407\n",
      " 217 288 220 209 227 261 174 281 221 205 240 289 318 298 564 246 322 299\n",
      " 300 293 277 214 207 223 160 394 184 315 409 244 195 196 126 313 259 200\n",
      " 262 215 228 193 271 210 327 149 295 306 178 237 218 242 319 166 180 311\n",
      " 278 342 169 187 157 176 241 131 132 161 173 194 297 292 339 147 291 358\n",
      " 412 238 163 280 202 328 129 190 179 272 100 468 320 312 171 365 344  85\n",
      " 347 251 287 156 117 466 338 529 392 329 355 603 404 518 285 279 388 336\n",
      " 491 331 393   0 153 316 458 384 349 142 181 310 170 369 165 337 333 139\n",
      " 385]\n"
     ]
    }
   ],
   "source": [
    "df['CHOL']=df['CHOL'].replace('?','-69')#temporarily replacing ? with -69\n",
    "df['CHOL']=df['CHOL'].astype('int64')\n",
    "k=int(df[df['CHOL']!=-69]['CHOL'].mean())\n",
    "df['CHOL']=df['CHOL'].replace(-69,k)\n",
    "\n",
    "\n",
    "print df['CHOL'].unique() #completed !--!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values in RESTECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    551\n",
      "2    188\n",
      "1    179\n",
      "?      2\n",
      "Name: RESTECG, dtype: int64\n",
      "after replacing\n",
      "0    553\n",
      "2    188\n",
      "1    179\n",
      "Name: RESTECG, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['RESTECG'].value_counts()\n",
    "\n",
    "#replacing with max occuring value for attribute\n",
    "df['RESTECG']=df['RESTECG'].replace('?','0')\n",
    "#print df['RESTECG'].unique()\n",
    "#print df['RESTECG'].value_counts()\n",
    "df['RESTECG'] = df['RESTECG'].astype('int64')\n",
    "\n",
    "\n",
    "\n",
    "print \"after replacing\\n\",df['RESTECG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values in THALACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?      55\n",
       "150    43\n",
       "140    41\n",
       "120    35\n",
       "130    30\n",
       "Name: THALACH, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['THALACH'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n"
     ]
    }
   ],
   "source": [
    "df['THALACH']=df['THALACH'].replace('?','-69')#temporarily replacing ? with -69\n",
    "df['THALACH']=df['THALACH'].astype('int64')\n",
    "k=int(df[df['THALACH']!=-69]['THALACH'].mean())\n",
    "print k\n",
    "df['THALACH']=df['THALACH'].replace(-69,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137    60\n",
       "150    43\n",
       "140    41\n",
       "120    35\n",
       "130    30\n",
       "Name: THALACH, dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['THALACH'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values in EXANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    528\n",
      "1    337\n",
      "?     55\n",
      "Name: EXANG, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#exang:exercise induced angina (1 = yes; 0 = no) \n",
    "print df['EXANG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610404624277\n"
     ]
    }
   ],
   "source": [
    "k=528.0/(337.0+528.0)\n",
    "print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    560\n",
      "1    360\n",
      "Name: EXANG, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "v=df.EXANG.values=='?'\n",
    "df.loc[v,'EXANG'] = numpy.random.choice(('0','1'), v.sum(), p=(0.61,0.39))\n",
    "print df['EXANG'].value_counts()\n",
    "df['EXANG']=df[\"EXANG\"].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Replacing missing values in OLDPEAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      370\n",
      "1       83\n",
      "2       76\n",
      "?       62\n",
      "1.5     48\n",
      "Name: OLDPEAK, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['OLDPEAK'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878787878788\n"
     ]
    }
   ],
   "source": [
    "df['OLDPEAK']=df['OLDPEAK'].replace('?','-69')#temporarily replacing ? with -69\n",
    "df['OLDPEAK']=df['OLDPEAK'].astype('float64')\n",
    "k=df[df['OLDPEAK']!=-69]['OLDPEAK'].mean()\n",
    "print k\n",
    "df['OLDPEAK']=df['OLDPEAK'].replace(-69,numpy.round(k,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    370\n",
      "1.0     83\n",
      "2.0     76\n",
      "0.9     66\n",
      "1.5     48\n",
      "Name: OLDPEAK, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['OLDPEAK'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    345\n",
      "?    309\n",
      "1    203\n",
      "3     63\n",
      "Name: SLOPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['SLOPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#k=203.0/(345.0+203.0+63.0)\n",
    "#print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    520\n",
      "1    300\n",
      "3    100\n",
      "Name: SLOPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "v=df.SLOPE.values=='?'\n",
    "df.loc[v,'SLOPE'] = numpy.random.choice(('2','1','3'), v.sum(), p=(0.6,0.30,0.10))\n",
    "print df['SLOPE'].value_counts()\n",
    "df['SLOPE']=df['SLOPE'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?    611\n",
      "0    181\n",
      "1     67\n",
      "2     41\n",
      "3     20\n",
      "Name: CA, dtype: int64\n",
      "0.132686084142\n"
     ]
    }
   ],
   "source": [
    "print df[\"CA\"].value_counts()\n",
    "k=(41.0)/(181+67+41+20)\n",
    "print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    557\n",
      "1    200\n",
      "2    108\n",
      "3     55\n",
      "Name: CA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "v=df.CA.values=='?'\n",
    "df.loc[v,'CA'] = numpy.random.choice(('0','1','2','3'), v.sum(), p=(0.60,0.20,0.13,0.07))\n",
    "df['CA']=df['CA'].astype('int64')\n",
    "print df['CA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?    486\n",
      "3    196\n",
      "7    192\n",
      "6     46\n",
      "Name: THAL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['THAL'].value_counts()\n",
    "#can't use random walk directly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    110\n",
      "0     86\n",
      "Name: SEX, dtype: int64\n",
      "1    171\n",
      "0     21\n",
      "Name: SEX, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df[df['THAL']=='3']['SEX'].value_counts()\n",
    "print df[df['THAL']=='7']['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THAL:3=====>\n",
      "0    138\n",
      "1     30\n",
      "2     14\n",
      "3     12\n",
      "4      2\n",
      "Name: CATEGORY, dtype: int64\n",
      "THAL:7=====>\n",
      "1    63\n",
      "3    43\n",
      "0    38\n",
      "2    37\n",
      "4    11\n",
      "Name: CATEGORY, dtype: int64\n",
      "THAL:6=====>\n",
      "1    13\n",
      "2    12\n",
      "0    11\n",
      "3     7\n",
      "4     3\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"THAL:3=====>\\n\",df[df['THAL']=='3']['CATEGORY'].value_counts()\n",
    "print \"THAL:7=====>\\n\",df[df['THAL']=='7']['CATEGORY'].value_counts()\n",
    "print \"THAL:6=====>\\n\",df[df['THAL']=='6']['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    454\n",
      "3    420\n",
      "6     46\n",
      "Name: THAL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['THAL']=df['THAL'].replace('?',-1)\n",
    "'''\n",
    "df['THAL']=df['THAL'].replace('?',-1)\n",
    "for row in df.iterrows():\n",
    "    if row['THAL']==-1 and row['CATEGORY']>=1:\n",
    "        df.loc[row.Index, 'ifor'] = 7\n",
    "        \n",
    "    elif row['THAL']==-1 and row['CATEGORY']==0:\n",
    "        df.loc[row.Index, 'ifor'] = 3\n",
    "'''\n",
    "df.loc[(df['THAL']==-1)&(df['CATEGORY']!=0),'THAL']='7'\n",
    "#print df['THAL'].value_counts()\n",
    "df.loc[(df['THAL']==-1)&(df['CATEGORY']==0),'THAL']='3'\n",
    "print df['THAL'].value_counts()\n",
    "df['THAL']=df['THAL'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE            int64\n",
      "SEX            int64\n",
      "CP             int64\n",
      "THRESTBPS      int64\n",
      "CHOL           int64\n",
      "FBS            int64\n",
      "RESTECG        int64\n",
      "THALACH        int64\n",
      "EXANG          int64\n",
      "OLDPEAK      float64\n",
      "SLOPE          int64\n",
      "CA             int64\n",
      "THAL           int64\n",
      "CATEGORY       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies = pandas.get_dummies(df[\"CP\"],prefix=\"CP\")\n",
    "df = df.join(dummies)\n",
    "\n",
    "dummies = pandas.get_dummies(df[\"RESTECG\"],prefix=\"RESTECG\")\n",
    "df      = df.join(dummies)\n",
    "\n",
    "dummies = pandas.get_dummies(df[\"SLOPE\"],prefix=\"SLOPE\")\n",
    "df      = df.join(dummies)\n",
    "\n",
    "dummies = pandas.get_dummies(df[\"THAL\"],prefix=\"THAL\")\n",
    "df      = df.join(dummies)\n",
    "\n",
    "#dummies = pandas.get_dummies(df[\"EXANG\"],prefix=\"EXANG\")\n",
    "#df = df.join(dummies)\n",
    "\n",
    "#del df['SEX']\n",
    "del df['CP']\n",
    "del df['RESTECG']\n",
    "del df['SLOPE']\n",
    "del df['THAL']\n",
    "#del df['EXANG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE            int64\n",
      "SEX            int64\n",
      "THRESTBPS      int64\n",
      "CHOL           int64\n",
      "FBS            int64\n",
      "THALACH        int64\n",
      "EXANG          int64\n",
      "OLDPEAK      float64\n",
      "CA             int64\n",
      "CATEGORY       int64\n",
      "CP_1           uint8\n",
      "CP_2           uint8\n",
      "CP_3           uint8\n",
      "CP_4           uint8\n",
      "RESTECG_0      uint8\n",
      "RESTECG_1      uint8\n",
      "RESTECG_2      uint8\n",
      "SLOPE_1        uint8\n",
      "SLOPE_2        uint8\n",
      "SLOPE_3        uint8\n",
      "THAL_3         uint8\n",
      "THAL_6         uint8\n",
      "THAL_7         uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in df.columns:\n",
    "    if df[g].dtype=='uint8':\n",
    "        df[g]=df[g].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df.loc[df['CATEGORY']>0,'CATEGORY']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE 2.49229867231 -2.70681396757\n",
      "THRESTBPS 3.67440591791 -7.03102349108\n",
      "CHOL 3.70670590542 -1.82755513195\n",
      "THALACH 2.56523324659 -3.08339929343\n",
      "OLDPEAK 5.04825042025 -3.30258023693\n",
      "CA 0.789492753623 -0.210507246377\n"
     ]
    }
   ],
   "source": [
    "stdcols = [\"AGE\",\"THRESTBPS\",\"CHOL\",\"THALACH\",\"OLDPEAK\"]\n",
    "nrmcols = [\"CA\"]\n",
    "stddf   = df.copy()\n",
    "stddf[stdcols] = stddf[stdcols].apply(lambda x: (x-x.mean())/x.std())\n",
    "stddf[nrmcols] = stddf[nrmcols].apply(lambda x: (x-x.mean())/(x.max()-x.min()))\n",
    "#stddf[stdcols] = stddf[stdcols].apply(lambda x: (x-x.mean())/(x.max()-x.min()))\n",
    "\n",
    "\n",
    "for g in stdcols:\n",
    "    print g,max(stddf[g]),min(stddf[g])\n",
    "    \n",
    "for g in nrmcols:\n",
    "    print g,max(stddf[g]),min(stddf[g])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE          float64\n",
      "SEX            int64\n",
      "THRESTBPS    float64\n",
      "CHOL         float64\n",
      "FBS            int64\n",
      "THALACH      float64\n",
      "EXANG          int64\n",
      "OLDPEAK      float64\n",
      "CA           float64\n",
      "CATEGORY       int64\n",
      "CP_1           int64\n",
      "CP_2           int64\n",
      "CP_3           int64\n",
      "CP_4           int64\n",
      "RESTECG_0      int64\n",
      "RESTECG_1      int64\n",
      "RESTECG_2      int64\n",
      "SLOPE_1        int64\n",
      "SLOPE_2        int64\n",
      "SLOPE_3        int64\n",
      "THAL_3         int64\n",
      "THAL_6         int64\n",
      "THAL_7         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print stddf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (920, 22)\n"
     ]
    }
   ],
   "source": [
    "df_copy=stddf.copy()\n",
    "df_copy=df_copy.drop(['CATEGORY'],axis=1)\n",
    "\n",
    "dat=df_copy.values\n",
    "#print dat.shape\n",
    "\n",
    "print type(dat),dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0] <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "labels=df['CATEGORY'].values\n",
    "print labels[:5],type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    509\n",
      "0    411\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(dat,labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (690, 22)\n",
      "y_train: (690,)\n",
      "\n",
      "x_test: (230, 22)\n",
      "y_test: (230,)\n"
     ]
    }
   ],
   "source": [
    "print \"x_train:\",x_train.shape\n",
    "print \"y_train:\",y_train.shape\n",
    "print\n",
    "print \"x_test:\",x_test.shape\n",
    "print \"y_test:\",y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 89.1304347826 %\n",
      "Logistic Regression: 88.2608695652 %\n"
     ]
    }
   ],
   "source": [
    "#training and testing\n",
    "#SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=5)\n",
    "clf.fit(x_train,y_train)\n",
    "print \"SVM:\",clf.score(x_test,y_test)*100,\"%\"\n",
    "svmpred=clf.predict(x_test)\n",
    "#print svmpred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#scores = cross_val_score(clf,dat,labels, cv=5)\n",
    "#print scores\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "lrcv=linear_model.LogisticRegressionCV(fit_intercept=True,penalty='l2',dual=False)\n",
    "lrcv.fit(x_train,y_train)\n",
    "print \"Logistic Regression:\",lrcv.score(x_test,y_test)*100,\"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of various features\n",
      "AGE 0.0430948093414\n",
      "SEX 0.0335623949641\n",
      "THRESTBPS 0.0399753743733\n",
      "CHOL 0.065922258698\n",
      "FBS 0.00864986982423\n",
      "THALACH 0.0428641967858\n",
      "EXANG 0.0511826428599\n",
      "OLDPEAK 0.0347466261144\n",
      "CA 0.0356597495659\n",
      "CP_1 0.00700858796546\n",
      "CP_2 0.0421112202428\n",
      "CP_3 0.0105986298357\n",
      "CP_4 0.0489146696255\n",
      "RESTECG_0 0.011312980557\n",
      "RESTECG_1 0.0140054280326\n",
      "RESTECG_2 0.0131781616231\n",
      "SLOPE_1 0.011029097367\n",
      "SLOPE_2 0.0124039872418\n",
      "SLOPE_3 0.00490804312616\n",
      "THAL_3 0.317612451723\n",
      "THAL_6 0.00548549291523\n",
      "THAL_7 0.145773327217\n",
      "(920, 5)\n",
      "after feature sel SVM: 89.5652173913 %\n",
      "Logistic Regression: 90.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(dat,labels)\n",
    "g=clf.feature_importances_\n",
    "c=stddf.drop(['CATEGORY'],axis=1).columns\n",
    "\n",
    "print \"Importance of various features\"\n",
    "for k in range(len(c)):\n",
    "    print c[k],g[k]\n",
    "    \n",
    "    \n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(dat)\n",
    "print X_new.shape\n",
    "\n",
    "\n",
    "tx_train,tx_test,ty_train,ty_test=train_test_split(X_new,labels, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "tclf = svm.SVC(gamma=0.001, C=5)\n",
    "tclf.fit(tx_train,ty_train)\n",
    "print \"after feature sel SVM:\",tclf.score(tx_test,ty_test)*100,\"%\"\n",
    "tsvmpred=tclf.predict(tx_test)\n",
    "#print tsvmpred\n",
    "\n",
    "\n",
    "lrcv=linear_model.LogisticRegressionCV(fit_intercept=True,penalty='l2',dual=False)\n",
    "lrcv.fit(tx_train,ty_train)\n",
    "print \"Logistic Regression:\",lrcv.score(tx_test,ty_test)*100,\"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Activation, Dense\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(activ,opti,ip,layers,trainx,trainy,testx,testy):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0], input_dim=ip, init='uniform', activation=activ))\n",
    "    model.add(Dense(layers[1], init='uniform', activation=activ))\n",
    "    model.add(Dense(1, init='uniform', activation=activ))\n",
    "    model.compile(loss='mse', optimizer=opti, metrics=['accuracy'])\n",
    "    model.fit(trainx,trainy,epochs=600,batch_size=512,verbose=2,validation_data=(testx,testy))\n",
    "    \n",
    "    trainScore = model.evaluate(trainx,trainy, verbose=0)\n",
    "    print \"Train Score: \",100-trainScore[0]*100\n",
    "    testScore = model.evaluate(testx,testy, verbose=0)\n",
    "    print \"Test Score: \",100-testScore[0]*100\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(22, activation=\"sigmoid\", kernel_initializer=\"uniform\", input_dim=22)`\n",
      "  app.launch_new_instance()\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 690 samples, validate on 230 samples\n",
      "Epoch 1/600\n",
      "0s - loss: 0.2512 - acc: 0.4565 - val_loss: 0.2501 - val_acc: 0.4174\n",
      "Epoch 2/600\n",
      "0s - loss: 0.2500 - acc: 0.4681 - val_loss: 0.2492 - val_acc: 0.5826\n",
      "Epoch 3/600\n",
      "0s - loss: 0.2495 - acc: 0.5435 - val_loss: 0.2483 - val_acc: 0.5826\n",
      "Epoch 4/600\n",
      "0s - loss: 0.2491 - acc: 0.5435 - val_loss: 0.2476 - val_acc: 0.5826\n",
      "Epoch 5/600\n",
      "0s - loss: 0.2488 - acc: 0.5435 - val_loss: 0.2473 - val_acc: 0.5826\n",
      "Epoch 6/600\n",
      "0s - loss: 0.2487 - acc: 0.5435 - val_loss: 0.2469 - val_acc: 0.5826\n",
      "Epoch 7/600\n",
      "0s - loss: 0.2485 - acc: 0.5435 - val_loss: 0.2464 - val_acc: 0.5826\n",
      "Epoch 8/600\n",
      "0s - loss: 0.2483 - acc: 0.5435 - val_loss: 0.2462 - val_acc: 0.5826\n",
      "Epoch 9/600\n",
      "0s - loss: 0.2482 - acc: 0.5435 - val_loss: 0.2457 - val_acc: 0.5826\n",
      "Epoch 10/600\n",
      "0s - loss: 0.2481 - acc: 0.5435 - val_loss: 0.2455 - val_acc: 0.5826\n",
      "Epoch 11/600\n",
      "0s - loss: 0.2481 - acc: 0.5435 - val_loss: 0.2455 - val_acc: 0.5826\n",
      "Epoch 12/600\n",
      "0s - loss: 0.2480 - acc: 0.5435 - val_loss: 0.2453 - val_acc: 0.5826\n",
      "Epoch 13/600\n",
      "0s - loss: 0.2480 - acc: 0.5435 - val_loss: 0.2453 - val_acc: 0.5826\n",
      "Epoch 14/600\n",
      "0s - loss: 0.2479 - acc: 0.5435 - val_loss: 0.2451 - val_acc: 0.5826\n",
      "Epoch 15/600\n",
      "0s - loss: 0.2478 - acc: 0.5435 - val_loss: 0.2449 - val_acc: 0.5826\n",
      "Epoch 16/600\n",
      "0s - loss: 0.2477 - acc: 0.5435 - val_loss: 0.2445 - val_acc: 0.5826\n",
      "Epoch 17/600\n",
      "0s - loss: 0.2476 - acc: 0.5435 - val_loss: 0.2442 - val_acc: 0.5826\n",
      "Epoch 18/600\n",
      "0s - loss: 0.2476 - acc: 0.5435 - val_loss: 0.2442 - val_acc: 0.5826\n",
      "Epoch 19/600\n",
      "0s - loss: 0.2475 - acc: 0.5435 - val_loss: 0.2441 - val_acc: 0.5826\n",
      "Epoch 20/600\n",
      "0s - loss: 0.2474 - acc: 0.5435 - val_loss: 0.2439 - val_acc: 0.5826\n",
      "Epoch 21/600\n",
      "0s - loss: 0.2473 - acc: 0.5435 - val_loss: 0.2435 - val_acc: 0.5826\n",
      "Epoch 22/600\n",
      "0s - loss: 0.2472 - acc: 0.5435 - val_loss: 0.2435 - val_acc: 0.5826\n",
      "Epoch 23/600\n",
      "0s - loss: 0.2471 - acc: 0.5435 - val_loss: 0.2433 - val_acc: 0.5826\n",
      "Epoch 24/600\n",
      "0s - loss: 0.2470 - acc: 0.5435 - val_loss: 0.2429 - val_acc: 0.5826\n",
      "Epoch 25/600\n",
      "0s - loss: 0.2469 - acc: 0.5435 - val_loss: 0.2426 - val_acc: 0.5826\n",
      "Epoch 26/600\n",
      "0s - loss: 0.2468 - acc: 0.5435 - val_loss: 0.2423 - val_acc: 0.5826\n",
      "Epoch 27/600\n",
      "0s - loss: 0.2466 - acc: 0.5435 - val_loss: 0.2423 - val_acc: 0.5826\n",
      "Epoch 28/600\n",
      "0s - loss: 0.2465 - acc: 0.5435 - val_loss: 0.2423 - val_acc: 0.5826\n",
      "Epoch 29/600\n",
      "0s - loss: 0.2464 - acc: 0.5435 - val_loss: 0.2421 - val_acc: 0.5826\n",
      "Epoch 30/600\n",
      "0s - loss: 0.2462 - acc: 0.5435 - val_loss: 0.2421 - val_acc: 0.5826\n",
      "Epoch 31/600\n",
      "0s - loss: 0.2461 - acc: 0.5435 - val_loss: 0.2418 - val_acc: 0.5826\n",
      "Epoch 32/600\n",
      "0s - loss: 0.2459 - acc: 0.5435 - val_loss: 0.2414 - val_acc: 0.5826\n",
      "Epoch 33/600\n",
      "0s - loss: 0.2458 - acc: 0.5435 - val_loss: 0.2410 - val_acc: 0.5826\n",
      "Epoch 34/600\n",
      "0s - loss: 0.2456 - acc: 0.5435 - val_loss: 0.2409 - val_acc: 0.5826\n",
      "Epoch 35/600\n",
      "0s - loss: 0.2454 - acc: 0.5435 - val_loss: 0.2406 - val_acc: 0.5826\n",
      "Epoch 36/600\n",
      "0s - loss: 0.2452 - acc: 0.5435 - val_loss: 0.2406 - val_acc: 0.5826\n",
      "Epoch 37/600\n",
      "0s - loss: 0.2450 - acc: 0.5435 - val_loss: 0.2404 - val_acc: 0.5826\n",
      "Epoch 38/600\n",
      "0s - loss: 0.2449 - acc: 0.5435 - val_loss: 0.2399 - val_acc: 0.5826\n",
      "Epoch 39/600\n",
      "0s - loss: 0.2446 - acc: 0.5435 - val_loss: 0.2400 - val_acc: 0.5826\n",
      "Epoch 40/600\n",
      "0s - loss: 0.2444 - acc: 0.5435 - val_loss: 0.2399 - val_acc: 0.5826\n",
      "Epoch 41/600\n",
      "0s - loss: 0.2442 - acc: 0.5435 - val_loss: 0.2398 - val_acc: 0.5826\n",
      "Epoch 42/600\n",
      "0s - loss: 0.2440 - acc: 0.5435 - val_loss: 0.2395 - val_acc: 0.5826\n",
      "Epoch 43/600\n",
      "0s - loss: 0.2438 - acc: 0.5435 - val_loss: 0.2396 - val_acc: 0.5826\n",
      "Epoch 44/600\n",
      "0s - loss: 0.2436 - acc: 0.5435 - val_loss: 0.2391 - val_acc: 0.5826\n",
      "Epoch 45/600\n",
      "0s - loss: 0.2434 - acc: 0.5435 - val_loss: 0.2391 - val_acc: 0.5826\n",
      "Epoch 46/600\n",
      "0s - loss: 0.2432 - acc: 0.5435 - val_loss: 0.2386 - val_acc: 0.5826\n",
      "Epoch 47/600\n",
      "0s - loss: 0.2429 - acc: 0.5435 - val_loss: 0.2382 - val_acc: 0.5826\n",
      "Epoch 48/600\n",
      "0s - loss: 0.2426 - acc: 0.5435 - val_loss: 0.2379 - val_acc: 0.5826\n",
      "Epoch 49/600\n",
      "0s - loss: 0.2424 - acc: 0.5435 - val_loss: 0.2375 - val_acc: 0.5826\n",
      "Epoch 50/600\n",
      "0s - loss: 0.2421 - acc: 0.5435 - val_loss: 0.2372 - val_acc: 0.5826\n",
      "Epoch 51/600\n",
      "0s - loss: 0.2418 - acc: 0.5435 - val_loss: 0.2369 - val_acc: 0.5826\n",
      "Epoch 52/600\n",
      "0s - loss: 0.2416 - acc: 0.5435 - val_loss: 0.2368 - val_acc: 0.5826\n",
      "Epoch 53/600\n",
      "0s - loss: 0.2413 - acc: 0.5435 - val_loss: 0.2364 - val_acc: 0.5826\n",
      "Epoch 54/600\n",
      "0s - loss: 0.2410 - acc: 0.5435 - val_loss: 0.2360 - val_acc: 0.5826\n",
      "Epoch 55/600\n",
      "0s - loss: 0.2407 - acc: 0.5435 - val_loss: 0.2359 - val_acc: 0.5826\n",
      "Epoch 56/600\n",
      "0s - loss: 0.2404 - acc: 0.5435 - val_loss: 0.2354 - val_acc: 0.5826\n",
      "Epoch 57/600\n",
      "0s - loss: 0.2401 - acc: 0.5435 - val_loss: 0.2349 - val_acc: 0.5826\n",
      "Epoch 58/600\n",
      "0s - loss: 0.2397 - acc: 0.5435 - val_loss: 0.2345 - val_acc: 0.5826\n",
      "Epoch 59/600\n",
      "0s - loss: 0.2393 - acc: 0.5435 - val_loss: 0.2340 - val_acc: 0.5826\n",
      "Epoch 60/600\n",
      "0s - loss: 0.2390 - acc: 0.5435 - val_loss: 0.2338 - val_acc: 0.5826\n",
      "Epoch 61/600\n",
      "0s - loss: 0.2386 - acc: 0.5435 - val_loss: 0.2333 - val_acc: 0.5826\n",
      "Epoch 62/600\n",
      "0s - loss: 0.2382 - acc: 0.5435 - val_loss: 0.2329 - val_acc: 0.5826\n",
      "Epoch 63/600\n",
      "0s - loss: 0.2378 - acc: 0.5435 - val_loss: 0.2325 - val_acc: 0.5826\n",
      "Epoch 64/600\n",
      "0s - loss: 0.2374 - acc: 0.5435 - val_loss: 0.2324 - val_acc: 0.5826\n",
      "Epoch 65/600\n",
      "0s - loss: 0.2370 - acc: 0.5435 - val_loss: 0.2318 - val_acc: 0.5826\n",
      "Epoch 66/600\n",
      "0s - loss: 0.2366 - acc: 0.5435 - val_loss: 0.2313 - val_acc: 0.5826\n",
      "Epoch 67/600\n",
      "0s - loss: 0.2362 - acc: 0.5435 - val_loss: 0.2306 - val_acc: 0.5826\n",
      "Epoch 68/600\n",
      "0s - loss: 0.2357 - acc: 0.5435 - val_loss: 0.2302 - val_acc: 0.5826\n",
      "Epoch 69/600\n",
      "0s - loss: 0.2353 - acc: 0.5435 - val_loss: 0.2296 - val_acc: 0.5826\n",
      "Epoch 70/600\n",
      "0s - loss: 0.2348 - acc: 0.5435 - val_loss: 0.2292 - val_acc: 0.5826\n",
      "Epoch 71/600\n",
      "0s - loss: 0.2343 - acc: 0.5435 - val_loss: 0.2286 - val_acc: 0.5826\n",
      "Epoch 72/600\n",
      "0s - loss: 0.2339 - acc: 0.5435 - val_loss: 0.2280 - val_acc: 0.5826\n",
      "Epoch 73/600\n",
      "0s - loss: 0.2334 - acc: 0.5435 - val_loss: 0.2278 - val_acc: 0.5826\n",
      "Epoch 74/600\n",
      "0s - loss: 0.2329 - acc: 0.5435 - val_loss: 0.2275 - val_acc: 0.5826\n",
      "Epoch 75/600\n",
      "0s - loss: 0.2325 - acc: 0.5435 - val_loss: 0.2268 - val_acc: 0.5826\n",
      "Epoch 76/600\n",
      "0s - loss: 0.2320 - acc: 0.5435 - val_loss: 0.2263 - val_acc: 0.5826\n",
      "Epoch 77/600\n",
      "0s - loss: 0.2315 - acc: 0.5435 - val_loss: 0.2258 - val_acc: 0.5826\n",
      "Epoch 78/600\n",
      "0s - loss: 0.2310 - acc: 0.5435 - val_loss: 0.2254 - val_acc: 0.5826\n",
      "Epoch 79/600\n",
      "0s - loss: 0.2305 - acc: 0.5435 - val_loss: 0.2251 - val_acc: 0.5826\n",
      "Epoch 80/600\n",
      "0s - loss: 0.2300 - acc: 0.5435 - val_loss: 0.2242 - val_acc: 0.5826\n",
      "Epoch 81/600\n",
      "0s - loss: 0.2295 - acc: 0.5435 - val_loss: 0.2239 - val_acc: 0.5826\n",
      "Epoch 82/600\n",
      "0s - loss: 0.2290 - acc: 0.5435 - val_loss: 0.2234 - val_acc: 0.5826\n",
      "Epoch 83/600\n",
      "0s - loss: 0.2284 - acc: 0.5435 - val_loss: 0.2228 - val_acc: 0.5826\n",
      "Epoch 84/600\n",
      "0s - loss: 0.2279 - acc: 0.5435 - val_loss: 0.2224 - val_acc: 0.5826\n",
      "Epoch 85/600\n",
      "0s - loss: 0.2273 - acc: 0.5435 - val_loss: 0.2216 - val_acc: 0.5826\n",
      "Epoch 86/600\n",
      "0s - loss: 0.2267 - acc: 0.5435 - val_loss: 0.2212 - val_acc: 0.5826\n",
      "Epoch 87/600\n",
      "0s - loss: 0.2262 - acc: 0.5435 - val_loss: 0.2206 - val_acc: 0.5826\n",
      "Epoch 88/600\n",
      "0s - loss: 0.2256 - acc: 0.5435 - val_loss: 0.2200 - val_acc: 0.5826\n",
      "Epoch 89/600\n",
      "0s - loss: 0.2252 - acc: 0.5464 - val_loss: 0.2197 - val_acc: 0.5826\n",
      "Epoch 90/600\n",
      "0s - loss: 0.2245 - acc: 0.5493 - val_loss: 0.2190 - val_acc: 0.5826\n",
      "Epoch 91/600\n",
      "0s - loss: 0.2239 - acc: 0.5493 - val_loss: 0.2182 - val_acc: 0.5826\n",
      "Epoch 92/600\n",
      "0s - loss: 0.2233 - acc: 0.5493 - val_loss: 0.2174 - val_acc: 0.5826\n",
      "Epoch 93/600\n",
      "0s - loss: 0.2227 - acc: 0.5493 - val_loss: 0.2167 - val_acc: 0.5870\n",
      "Epoch 94/600\n",
      "0s - loss: 0.2221 - acc: 0.5493 - val_loss: 0.2162 - val_acc: 0.6043\n",
      "Epoch 95/600\n",
      "0s - loss: 0.2215 - acc: 0.5580 - val_loss: 0.2156 - val_acc: 0.6130\n",
      "Epoch 96/600\n",
      "0s - loss: 0.2208 - acc: 0.5638 - val_loss: 0.2148 - val_acc: 0.6130\n",
      "Epoch 97/600\n",
      "0s - loss: 0.2202 - acc: 0.5623 - val_loss: 0.2143 - val_acc: 0.6130\n",
      "Epoch 98/600\n",
      "0s - loss: 0.2196 - acc: 0.5725 - val_loss: 0.2138 - val_acc: 0.6304\n",
      "Epoch 99/600\n",
      "0s - loss: 0.2190 - acc: 0.5855 - val_loss: 0.2134 - val_acc: 0.6565\n",
      "Epoch 100/600\n",
      "0s - loss: 0.2183 - acc: 0.5942 - val_loss: 0.2126 - val_acc: 0.6565\n",
      "Epoch 101/600\n",
      "0s - loss: 0.2177 - acc: 0.5942 - val_loss: 0.2120 - val_acc: 0.6565\n",
      "Epoch 102/600\n",
      "0s - loss: 0.2171 - acc: 0.5957 - val_loss: 0.2116 - val_acc: 0.6652\n",
      "Epoch 103/600\n",
      "0s - loss: 0.2164 - acc: 0.6087 - val_loss: 0.2109 - val_acc: 0.6696\n",
      "Epoch 104/600\n",
      "0s - loss: 0.2159 - acc: 0.6145 - val_loss: 0.2106 - val_acc: 0.7000\n",
      "Epoch 105/600\n",
      "0s - loss: 0.2153 - acc: 0.6449 - val_loss: 0.2101 - val_acc: 0.7043\n",
      "Epoch 106/600\n",
      "0s - loss: 0.2146 - acc: 0.6551 - val_loss: 0.2094 - val_acc: 0.7087\n",
      "Epoch 107/600\n",
      "0s - loss: 0.2140 - acc: 0.6536 - val_loss: 0.2087 - val_acc: 0.7130\n",
      "Epoch 108/600\n",
      "0s - loss: 0.2133 - acc: 0.6652 - val_loss: 0.2077 - val_acc: 0.7043\n",
      "Epoch 109/600\n",
      "0s - loss: 0.2126 - acc: 0.6536 - val_loss: 0.2073 - val_acc: 0.7130\n",
      "Epoch 110/600\n",
      "0s - loss: 0.2120 - acc: 0.6725 - val_loss: 0.2065 - val_acc: 0.7130\n",
      "Epoch 111/600\n",
      "0s - loss: 0.2113 - acc: 0.6725 - val_loss: 0.2058 - val_acc: 0.7174\n",
      "Epoch 112/600\n",
      "0s - loss: 0.2106 - acc: 0.6725 - val_loss: 0.2049 - val_acc: 0.7174\n",
      "Epoch 113/600\n",
      "0s - loss: 0.2099 - acc: 0.6710 - val_loss: 0.2043 - val_acc: 0.7217\n",
      "Epoch 114/600\n",
      "0s - loss: 0.2092 - acc: 0.6812 - val_loss: 0.2035 - val_acc: 0.7261\n",
      "Epoch 115/600\n",
      "0s - loss: 0.2085 - acc: 0.6841 - val_loss: 0.2026 - val_acc: 0.7217\n",
      "Epoch 116/600\n",
      "0s - loss: 0.2078 - acc: 0.6783 - val_loss: 0.2019 - val_acc: 0.7304\n",
      "Epoch 117/600\n",
      "0s - loss: 0.2071 - acc: 0.6884 - val_loss: 0.2013 - val_acc: 0.7391\n",
      "Epoch 118/600\n",
      "0s - loss: 0.2063 - acc: 0.6957 - val_loss: 0.2004 - val_acc: 0.7348\n",
      "Epoch 119/600\n",
      "0s - loss: 0.2056 - acc: 0.6957 - val_loss: 0.1998 - val_acc: 0.7348\n",
      "Epoch 120/600\n",
      "0s - loss: 0.2049 - acc: 0.7014 - val_loss: 0.1990 - val_acc: 0.7522\n",
      "Epoch 121/600\n",
      "0s - loss: 0.2041 - acc: 0.7058 - val_loss: 0.1983 - val_acc: 0.7565\n",
      "Epoch 122/600\n",
      "0s - loss: 0.2034 - acc: 0.7203 - val_loss: 0.1973 - val_acc: 0.7522\n",
      "Epoch 123/600\n",
      "0s - loss: 0.2027 - acc: 0.7145 - val_loss: 0.1964 - val_acc: 0.7522\n",
      "Epoch 124/600\n",
      "0s - loss: 0.2020 - acc: 0.7072 - val_loss: 0.1956 - val_acc: 0.7435\n",
      "Epoch 125/600\n",
      "0s - loss: 0.2013 - acc: 0.7058 - val_loss: 0.1950 - val_acc: 0.7609\n",
      "Epoch 126/600\n",
      "0s - loss: 0.2006 - acc: 0.7188 - val_loss: 0.1942 - val_acc: 0.7609\n",
      "Epoch 127/600\n",
      "0s - loss: 0.1998 - acc: 0.7188 - val_loss: 0.1937 - val_acc: 0.7696\n",
      "Epoch 128/600\n",
      "0s - loss: 0.1992 - acc: 0.7406 - val_loss: 0.1929 - val_acc: 0.7652\n",
      "Epoch 129/600\n",
      "0s - loss: 0.1984 - acc: 0.7304 - val_loss: 0.1922 - val_acc: 0.7696\n",
      "Epoch 130/600\n",
      "0s - loss: 0.1978 - acc: 0.7406 - val_loss: 0.1914 - val_acc: 0.7696\n",
      "Epoch 131/600\n",
      "0s - loss: 0.1970 - acc: 0.7362 - val_loss: 0.1909 - val_acc: 0.7739\n",
      "Epoch 132/600\n",
      "0s - loss: 0.1963 - acc: 0.7580 - val_loss: 0.1902 - val_acc: 0.7696\n",
      "Epoch 133/600\n",
      "0s - loss: 0.1956 - acc: 0.7609 - val_loss: 0.1895 - val_acc: 0.7783\n",
      "Epoch 134/600\n",
      "0s - loss: 0.1948 - acc: 0.7667 - val_loss: 0.1888 - val_acc: 0.7783\n",
      "Epoch 135/600\n",
      "0s - loss: 0.1941 - acc: 0.7696 - val_loss: 0.1880 - val_acc: 0.7783\n",
      "Epoch 136/600\n",
      "0s - loss: 0.1934 - acc: 0.7739 - val_loss: 0.1874 - val_acc: 0.7870\n",
      "Epoch 137/600\n",
      "0s - loss: 0.1926 - acc: 0.7783 - val_loss: 0.1867 - val_acc: 0.7870\n",
      "Epoch 138/600\n",
      "0s - loss: 0.1919 - acc: 0.7812 - val_loss: 0.1861 - val_acc: 0.7913\n",
      "Epoch 139/600\n",
      "0s - loss: 0.1911 - acc: 0.7797 - val_loss: 0.1852 - val_acc: 0.7913\n",
      "Epoch 140/600\n",
      "0s - loss: 0.1904 - acc: 0.7797 - val_loss: 0.1846 - val_acc: 0.7957\n",
      "Epoch 141/600\n",
      "0s - loss: 0.1897 - acc: 0.7826 - val_loss: 0.1842 - val_acc: 0.8000\n",
      "Epoch 142/600\n",
      "0s - loss: 0.1889 - acc: 0.7971 - val_loss: 0.1836 - val_acc: 0.8087\n",
      "Epoch 143/600\n",
      "0s - loss: 0.1882 - acc: 0.7986 - val_loss: 0.1828 - val_acc: 0.8130\n",
      "Epoch 144/600\n",
      "0s - loss: 0.1875 - acc: 0.7986 - val_loss: 0.1822 - val_acc: 0.8174\n",
      "Epoch 145/600\n",
      "0s - loss: 0.1867 - acc: 0.8000 - val_loss: 0.1813 - val_acc: 0.8174\n",
      "Epoch 146/600\n",
      "0s - loss: 0.1860 - acc: 0.7986 - val_loss: 0.1807 - val_acc: 0.8217\n",
      "Epoch 147/600\n",
      "0s - loss: 0.1853 - acc: 0.7971 - val_loss: 0.1800 - val_acc: 0.8217\n",
      "Epoch 148/600\n",
      "0s - loss: 0.1845 - acc: 0.7957 - val_loss: 0.1794 - val_acc: 0.8174\n",
      "Epoch 149/600\n",
      "0s - loss: 0.1838 - acc: 0.8000 - val_loss: 0.1784 - val_acc: 0.8217\n",
      "Epoch 150/600\n",
      "0s - loss: 0.1830 - acc: 0.7971 - val_loss: 0.1774 - val_acc: 0.8217\n",
      "Epoch 151/600\n",
      "0s - loss: 0.1823 - acc: 0.8000 - val_loss: 0.1768 - val_acc: 0.8217\n",
      "Epoch 152/600\n",
      "0s - loss: 0.1816 - acc: 0.7986 - val_loss: 0.1759 - val_acc: 0.8217\n",
      "Epoch 153/600\n",
      "0s - loss: 0.1808 - acc: 0.7986 - val_loss: 0.1753 - val_acc: 0.8261\n",
      "Epoch 154/600\n",
      "0s - loss: 0.1801 - acc: 0.8029 - val_loss: 0.1749 - val_acc: 0.8261\n",
      "Epoch 155/600\n",
      "0s - loss: 0.1793 - acc: 0.8029 - val_loss: 0.1745 - val_acc: 0.8217\n",
      "Epoch 156/600\n",
      "0s - loss: 0.1787 - acc: 0.8072 - val_loss: 0.1741 - val_acc: 0.8304\n",
      "Epoch 157/600\n",
      "0s - loss: 0.1780 - acc: 0.8087 - val_loss: 0.1735 - val_acc: 0.8304\n",
      "Epoch 158/600\n",
      "0s - loss: 0.1773 - acc: 0.8087 - val_loss: 0.1727 - val_acc: 0.8304\n",
      "Epoch 159/600\n",
      "0s - loss: 0.1766 - acc: 0.8087 - val_loss: 0.1720 - val_acc: 0.8304\n",
      "Epoch 160/600\n",
      "0s - loss: 0.1758 - acc: 0.8087 - val_loss: 0.1711 - val_acc: 0.8304\n",
      "Epoch 161/600\n",
      "0s - loss: 0.1751 - acc: 0.8087 - val_loss: 0.1703 - val_acc: 0.8304\n",
      "Epoch 162/600\n",
      "0s - loss: 0.1744 - acc: 0.8087 - val_loss: 0.1695 - val_acc: 0.8304\n",
      "Epoch 163/600\n",
      "0s - loss: 0.1737 - acc: 0.8072 - val_loss: 0.1690 - val_acc: 0.8304\n",
      "Epoch 164/600\n",
      "0s - loss: 0.1729 - acc: 0.8130 - val_loss: 0.1685 - val_acc: 0.8304\n",
      "Epoch 165/600\n",
      "0s - loss: 0.1722 - acc: 0.8174 - val_loss: 0.1676 - val_acc: 0.8304\n",
      "Epoch 166/600\n",
      "0s - loss: 0.1715 - acc: 0.8174 - val_loss: 0.1667 - val_acc: 0.8304\n",
      "Epoch 167/600\n",
      "0s - loss: 0.1707 - acc: 0.8145 - val_loss: 0.1662 - val_acc: 0.8304\n",
      "Epoch 168/600\n",
      "0s - loss: 0.1700 - acc: 0.8188 - val_loss: 0.1653 - val_acc: 0.8304\n",
      "Epoch 169/600\n",
      "0s - loss: 0.1693 - acc: 0.8174 - val_loss: 0.1645 - val_acc: 0.8304\n",
      "Epoch 170/600\n",
      "0s - loss: 0.1685 - acc: 0.8174 - val_loss: 0.1637 - val_acc: 0.8304\n",
      "Epoch 171/600\n",
      "0s - loss: 0.1678 - acc: 0.8188 - val_loss: 0.1631 - val_acc: 0.8304\n",
      "Epoch 172/600\n",
      "0s - loss: 0.1671 - acc: 0.8188 - val_loss: 0.1623 - val_acc: 0.8304\n",
      "Epoch 173/600\n",
      "0s - loss: 0.1664 - acc: 0.8203 - val_loss: 0.1615 - val_acc: 0.8304\n",
      "Epoch 174/600\n",
      "0s - loss: 0.1656 - acc: 0.8203 - val_loss: 0.1611 - val_acc: 0.8348\n",
      "Epoch 175/600\n",
      "0s - loss: 0.1649 - acc: 0.8261 - val_loss: 0.1605 - val_acc: 0.8348\n",
      "Epoch 176/600\n",
      "0s - loss: 0.1641 - acc: 0.8261 - val_loss: 0.1597 - val_acc: 0.8348\n",
      "Epoch 177/600\n",
      "0s - loss: 0.1634 - acc: 0.8304 - val_loss: 0.1590 - val_acc: 0.8348\n",
      "Epoch 178/600\n",
      "0s - loss: 0.1627 - acc: 0.8304 - val_loss: 0.1585 - val_acc: 0.8348\n",
      "Epoch 179/600\n",
      "0s - loss: 0.1620 - acc: 0.8290 - val_loss: 0.1576 - val_acc: 0.8348\n",
      "Epoch 180/600\n",
      "0s - loss: 0.1614 - acc: 0.8304 - val_loss: 0.1573 - val_acc: 0.8348\n",
      "Epoch 181/600\n",
      "0s - loss: 0.1605 - acc: 0.8362 - val_loss: 0.1566 - val_acc: 0.8348\n",
      "Epoch 182/600\n",
      "0s - loss: 0.1598 - acc: 0.8377 - val_loss: 0.1559 - val_acc: 0.8348\n",
      "Epoch 183/600\n",
      "0s - loss: 0.1591 - acc: 0.8377 - val_loss: 0.1554 - val_acc: 0.8348\n",
      "Epoch 184/600\n",
      "0s - loss: 0.1584 - acc: 0.8406 - val_loss: 0.1549 - val_acc: 0.8348\n",
      "Epoch 185/600\n",
      "0s - loss: 0.1578 - acc: 0.8406 - val_loss: 0.1542 - val_acc: 0.8348\n",
      "Epoch 186/600\n",
      "0s - loss: 0.1571 - acc: 0.8435 - val_loss: 0.1534 - val_acc: 0.8348\n",
      "Epoch 187/600\n",
      "0s - loss: 0.1564 - acc: 0.8420 - val_loss: 0.1526 - val_acc: 0.8348\n",
      "Epoch 188/600\n",
      "0s - loss: 0.1557 - acc: 0.8420 - val_loss: 0.1521 - val_acc: 0.8348\n",
      "Epoch 189/600\n",
      "0s - loss: 0.1550 - acc: 0.8435 - val_loss: 0.1515 - val_acc: 0.8348\n",
      "Epoch 190/600\n",
      "0s - loss: 0.1543 - acc: 0.8478 - val_loss: 0.1508 - val_acc: 0.8348\n",
      "Epoch 191/600\n",
      "0s - loss: 0.1536 - acc: 0.8478 - val_loss: 0.1499 - val_acc: 0.8348\n",
      "Epoch 192/600\n",
      "0s - loss: 0.1529 - acc: 0.8449 - val_loss: 0.1493 - val_acc: 0.8348\n",
      "Epoch 193/600\n",
      "0s - loss: 0.1522 - acc: 0.8478 - val_loss: 0.1488 - val_acc: 0.8391\n",
      "Epoch 194/600\n",
      "0s - loss: 0.1515 - acc: 0.8464 - val_loss: 0.1484 - val_acc: 0.8391\n",
      "Epoch 195/600\n",
      "0s - loss: 0.1508 - acc: 0.8478 - val_loss: 0.1477 - val_acc: 0.8435\n",
      "Epoch 196/600\n",
      "0s - loss: 0.1501 - acc: 0.8478 - val_loss: 0.1472 - val_acc: 0.8391\n",
      "Epoch 197/600\n",
      "0s - loss: 0.1495 - acc: 0.8493 - val_loss: 0.1467 - val_acc: 0.8391\n",
      "Epoch 198/600\n",
      "0s - loss: 0.1488 - acc: 0.8507 - val_loss: 0.1463 - val_acc: 0.8391\n",
      "Epoch 199/600\n",
      "0s - loss: 0.1482 - acc: 0.8522 - val_loss: 0.1460 - val_acc: 0.8391\n",
      "Epoch 200/600\n",
      "0s - loss: 0.1475 - acc: 0.8551 - val_loss: 0.1452 - val_acc: 0.8391\n",
      "Epoch 201/600\n",
      "0s - loss: 0.1468 - acc: 0.8536 - val_loss: 0.1443 - val_acc: 0.8391\n",
      "Epoch 202/600\n",
      "0s - loss: 0.1461 - acc: 0.8536 - val_loss: 0.1437 - val_acc: 0.8348\n",
      "Epoch 203/600\n",
      "0s - loss: 0.1455 - acc: 0.8536 - val_loss: 0.1432 - val_acc: 0.8391\n",
      "Epoch 204/600\n",
      "0s - loss: 0.1448 - acc: 0.8551 - val_loss: 0.1427 - val_acc: 0.8478\n",
      "Epoch 205/600\n",
      "0s - loss: 0.1442 - acc: 0.8551 - val_loss: 0.1418 - val_acc: 0.8391\n",
      "Epoch 206/600\n",
      "0s - loss: 0.1434 - acc: 0.8551 - val_loss: 0.1413 - val_acc: 0.8435\n",
      "Epoch 207/600\n",
      "0s - loss: 0.1428 - acc: 0.8565 - val_loss: 0.1406 - val_acc: 0.8435\n",
      "Epoch 208/600\n",
      "0s - loss: 0.1421 - acc: 0.8551 - val_loss: 0.1400 - val_acc: 0.8435\n",
      "Epoch 209/600\n",
      "0s - loss: 0.1415 - acc: 0.8565 - val_loss: 0.1393 - val_acc: 0.8435\n",
      "Epoch 210/600\n",
      "0s - loss: 0.1408 - acc: 0.8565 - val_loss: 0.1389 - val_acc: 0.8435\n",
      "Epoch 211/600\n",
      "0s - loss: 0.1402 - acc: 0.8580 - val_loss: 0.1382 - val_acc: 0.8435\n",
      "Epoch 212/600\n",
      "0s - loss: 0.1396 - acc: 0.8565 - val_loss: 0.1378 - val_acc: 0.8478\n",
      "Epoch 213/600\n",
      "0s - loss: 0.1390 - acc: 0.8594 - val_loss: 0.1371 - val_acc: 0.8478\n",
      "Epoch 214/600\n",
      "0s - loss: 0.1383 - acc: 0.8594 - val_loss: 0.1365 - val_acc: 0.8478\n",
      "Epoch 215/600\n",
      "0s - loss: 0.1377 - acc: 0.8594 - val_loss: 0.1360 - val_acc: 0.8478\n",
      "Epoch 216/600\n",
      "0s - loss: 0.1371 - acc: 0.8594 - val_loss: 0.1354 - val_acc: 0.8478\n",
      "Epoch 217/600\n",
      "0s - loss: 0.1364 - acc: 0.8594 - val_loss: 0.1349 - val_acc: 0.8478\n",
      "Epoch 218/600\n",
      "0s - loss: 0.1357 - acc: 0.8594 - val_loss: 0.1345 - val_acc: 0.8522\n",
      "Epoch 219/600\n",
      "0s - loss: 0.1351 - acc: 0.8594 - val_loss: 0.1338 - val_acc: 0.8478\n",
      "Epoch 220/600\n",
      "0s - loss: 0.1345 - acc: 0.8609 - val_loss: 0.1334 - val_acc: 0.8522\n",
      "Epoch 221/600\n",
      "0s - loss: 0.1338 - acc: 0.8638 - val_loss: 0.1328 - val_acc: 0.8522\n",
      "Epoch 222/600\n",
      "0s - loss: 0.1332 - acc: 0.8638 - val_loss: 0.1324 - val_acc: 0.8565\n",
      "Epoch 223/600\n",
      "0s - loss: 0.1326 - acc: 0.8652 - val_loss: 0.1319 - val_acc: 0.8565\n",
      "Epoch 224/600\n",
      "0s - loss: 0.1320 - acc: 0.8652 - val_loss: 0.1313 - val_acc: 0.8522\n",
      "Epoch 225/600\n",
      "0s - loss: 0.1315 - acc: 0.8652 - val_loss: 0.1307 - val_acc: 0.8522\n",
      "Epoch 226/600\n",
      "0s - loss: 0.1308 - acc: 0.8652 - val_loss: 0.1303 - val_acc: 0.8565\n",
      "Epoch 227/600\n",
      "0s - loss: 0.1302 - acc: 0.8667 - val_loss: 0.1301 - val_acc: 0.8565\n",
      "Epoch 228/600\n",
      "0s - loss: 0.1296 - acc: 0.8667 - val_loss: 0.1299 - val_acc: 0.8609\n",
      "Epoch 229/600\n",
      "0s - loss: 0.1290 - acc: 0.8681 - val_loss: 0.1293 - val_acc: 0.8609\n",
      "Epoch 230/600\n",
      "0s - loss: 0.1285 - acc: 0.8681 - val_loss: 0.1288 - val_acc: 0.8609\n",
      "Epoch 231/600\n",
      "0s - loss: 0.1279 - acc: 0.8681 - val_loss: 0.1284 - val_acc: 0.8609\n",
      "Epoch 232/600\n",
      "0s - loss: 0.1274 - acc: 0.8681 - val_loss: 0.1278 - val_acc: 0.8609\n",
      "Epoch 233/600\n",
      "0s - loss: 0.1268 - acc: 0.8696 - val_loss: 0.1275 - val_acc: 0.8652\n",
      "Epoch 234/600\n",
      "0s - loss: 0.1262 - acc: 0.8696 - val_loss: 0.1268 - val_acc: 0.8609\n",
      "Epoch 235/600\n",
      "0s - loss: 0.1257 - acc: 0.8710 - val_loss: 0.1265 - val_acc: 0.8652\n",
      "Epoch 236/600\n",
      "0s - loss: 0.1252 - acc: 0.8710 - val_loss: 0.1259 - val_acc: 0.8609\n",
      "Epoch 237/600\n",
      "0s - loss: 0.1246 - acc: 0.8725 - val_loss: 0.1254 - val_acc: 0.8609\n",
      "Epoch 238/600\n",
      "0s - loss: 0.1240 - acc: 0.8725 - val_loss: 0.1250 - val_acc: 0.8609\n",
      "Epoch 239/600\n",
      "0s - loss: 0.1234 - acc: 0.8710 - val_loss: 0.1246 - val_acc: 0.8609\n",
      "Epoch 240/600\n",
      "0s - loss: 0.1229 - acc: 0.8725 - val_loss: 0.1242 - val_acc: 0.8609\n",
      "Epoch 241/600\n",
      "0s - loss: 0.1223 - acc: 0.8739 - val_loss: 0.1240 - val_acc: 0.8609\n",
      "Epoch 242/600\n",
      "0s - loss: 0.1218 - acc: 0.8739 - val_loss: 0.1235 - val_acc: 0.8609\n",
      "Epoch 243/600\n",
      "0s - loss: 0.1212 - acc: 0.8739 - val_loss: 0.1230 - val_acc: 0.8609\n",
      "Epoch 244/600\n",
      "0s - loss: 0.1207 - acc: 0.8739 - val_loss: 0.1226 - val_acc: 0.8609\n",
      "Epoch 245/600\n",
      "0s - loss: 0.1202 - acc: 0.8754 - val_loss: 0.1225 - val_acc: 0.8652\n",
      "Epoch 246/600\n",
      "0s - loss: 0.1196 - acc: 0.8812 - val_loss: 0.1220 - val_acc: 0.8609\n",
      "Epoch 247/600\n",
      "0s - loss: 0.1191 - acc: 0.8812 - val_loss: 0.1214 - val_acc: 0.8609\n",
      "Epoch 248/600\n",
      "0s - loss: 0.1185 - acc: 0.8783 - val_loss: 0.1211 - val_acc: 0.8609\n",
      "Epoch 249/600\n",
      "0s - loss: 0.1180 - acc: 0.8812 - val_loss: 0.1208 - val_acc: 0.8652\n",
      "Epoch 250/600\n",
      "0s - loss: 0.1175 - acc: 0.8812 - val_loss: 0.1205 - val_acc: 0.8652\n",
      "Epoch 251/600\n",
      "0s - loss: 0.1170 - acc: 0.8812 - val_loss: 0.1201 - val_acc: 0.8652\n",
      "Epoch 252/600\n",
      "0s - loss: 0.1164 - acc: 0.8812 - val_loss: 0.1195 - val_acc: 0.8652\n",
      "Epoch 253/600\n",
      "0s - loss: 0.1160 - acc: 0.8826 - val_loss: 0.1190 - val_acc: 0.8609\n",
      "Epoch 254/600\n",
      "0s - loss: 0.1155 - acc: 0.8826 - val_loss: 0.1189 - val_acc: 0.8652\n",
      "Epoch 255/600\n",
      "0s - loss: 0.1149 - acc: 0.8855 - val_loss: 0.1185 - val_acc: 0.8652\n",
      "Epoch 256/600\n",
      "0s - loss: 0.1145 - acc: 0.8841 - val_loss: 0.1183 - val_acc: 0.8609\n",
      "Epoch 257/600\n",
      "0s - loss: 0.1140 - acc: 0.8855 - val_loss: 0.1181 - val_acc: 0.8609\n",
      "Epoch 258/600\n",
      "0s - loss: 0.1135 - acc: 0.8884 - val_loss: 0.1176 - val_acc: 0.8609\n",
      "Epoch 259/600\n",
      "0s - loss: 0.1130 - acc: 0.8884 - val_loss: 0.1172 - val_acc: 0.8609\n",
      "Epoch 260/600\n",
      "0s - loss: 0.1126 - acc: 0.8884 - val_loss: 0.1169 - val_acc: 0.8609\n",
      "Epoch 261/600\n",
      "0s - loss: 0.1122 - acc: 0.8855 - val_loss: 0.1168 - val_acc: 0.8652\n",
      "Epoch 262/600\n",
      "0s - loss: 0.1117 - acc: 0.8884 - val_loss: 0.1163 - val_acc: 0.8652\n",
      "Epoch 263/600\n",
      "0s - loss: 0.1112 - acc: 0.8870 - val_loss: 0.1159 - val_acc: 0.8652\n",
      "Epoch 264/600\n",
      "0s - loss: 0.1107 - acc: 0.8884 - val_loss: 0.1156 - val_acc: 0.8652\n",
      "Epoch 265/600\n",
      "0s - loss: 0.1103 - acc: 0.8899 - val_loss: 0.1153 - val_acc: 0.8652\n",
      "Epoch 266/600\n",
      "0s - loss: 0.1098 - acc: 0.8899 - val_loss: 0.1150 - val_acc: 0.8652\n",
      "Epoch 267/600\n",
      "0s - loss: 0.1094 - acc: 0.8899 - val_loss: 0.1144 - val_acc: 0.8652\n",
      "Epoch 268/600\n",
      "0s - loss: 0.1089 - acc: 0.8899 - val_loss: 0.1143 - val_acc: 0.8652\n",
      "Epoch 269/600\n",
      "0s - loss: 0.1084 - acc: 0.8899 - val_loss: 0.1140 - val_acc: 0.8652\n",
      "Epoch 270/600\n",
      "0s - loss: 0.1080 - acc: 0.8884 - val_loss: 0.1135 - val_acc: 0.8696\n",
      "Epoch 271/600\n",
      "0s - loss: 0.1075 - acc: 0.8899 - val_loss: 0.1130 - val_acc: 0.8696\n",
      "Epoch 272/600\n",
      "0s - loss: 0.1071 - acc: 0.8899 - val_loss: 0.1126 - val_acc: 0.8696\n",
      "Epoch 273/600\n",
      "0s - loss: 0.1066 - acc: 0.8899 - val_loss: 0.1122 - val_acc: 0.8696\n",
      "Epoch 274/600\n",
      "0s - loss: 0.1062 - acc: 0.8899 - val_loss: 0.1119 - val_acc: 0.8696\n",
      "Epoch 275/600\n",
      "0s - loss: 0.1058 - acc: 0.8884 - val_loss: 0.1119 - val_acc: 0.8696\n",
      "Epoch 276/600\n",
      "0s - loss: 0.1053 - acc: 0.8899 - val_loss: 0.1115 - val_acc: 0.8696\n",
      "Epoch 277/600\n",
      "0s - loss: 0.1049 - acc: 0.8899 - val_loss: 0.1114 - val_acc: 0.8696\n",
      "Epoch 278/600\n",
      "0s - loss: 0.1044 - acc: 0.8942 - val_loss: 0.1111 - val_acc: 0.8696\n",
      "Epoch 279/600\n",
      "0s - loss: 0.1040 - acc: 0.8942 - val_loss: 0.1107 - val_acc: 0.8696\n",
      "Epoch 280/600\n",
      "0s - loss: 0.1036 - acc: 0.8942 - val_loss: 0.1104 - val_acc: 0.8696\n",
      "Epoch 281/600\n",
      "0s - loss: 0.1032 - acc: 0.8957 - val_loss: 0.1101 - val_acc: 0.8696\n",
      "Epoch 282/600\n",
      "0s - loss: 0.1028 - acc: 0.8957 - val_loss: 0.1100 - val_acc: 0.8652\n",
      "Epoch 283/600\n",
      "0s - loss: 0.1024 - acc: 0.8942 - val_loss: 0.1099 - val_acc: 0.8652\n",
      "Epoch 284/600\n",
      "0s - loss: 0.1020 - acc: 0.8942 - val_loss: 0.1094 - val_acc: 0.8652\n",
      "Epoch 285/600\n",
      "0s - loss: 0.1016 - acc: 0.8942 - val_loss: 0.1092 - val_acc: 0.8652\n",
      "Epoch 286/600\n",
      "0s - loss: 0.1012 - acc: 0.8942 - val_loss: 0.1088 - val_acc: 0.8652\n",
      "Epoch 287/600\n",
      "0s - loss: 0.1008 - acc: 0.8942 - val_loss: 0.1084 - val_acc: 0.8652\n",
      "Epoch 288/600\n",
      "0s - loss: 0.1004 - acc: 0.8957 - val_loss: 0.1081 - val_acc: 0.8652\n",
      "Epoch 289/600\n",
      "0s - loss: 0.1000 - acc: 0.8942 - val_loss: 0.1080 - val_acc: 0.8652\n",
      "Epoch 290/600\n",
      "0s - loss: 0.0996 - acc: 0.8928 - val_loss: 0.1077 - val_acc: 0.8652\n",
      "Epoch 291/600\n",
      "0s - loss: 0.0992 - acc: 0.8928 - val_loss: 0.1077 - val_acc: 0.8609\n",
      "Epoch 292/600\n",
      "0s - loss: 0.0988 - acc: 0.8913 - val_loss: 0.1074 - val_acc: 0.8609\n",
      "Epoch 293/600\n",
      "0s - loss: 0.0984 - acc: 0.8928 - val_loss: 0.1072 - val_acc: 0.8609\n",
      "Epoch 294/600\n",
      "0s - loss: 0.0980 - acc: 0.8899 - val_loss: 0.1069 - val_acc: 0.8609\n",
      "Epoch 295/600\n",
      "0s - loss: 0.0977 - acc: 0.8899 - val_loss: 0.1064 - val_acc: 0.8609\n",
      "Epoch 296/600\n",
      "0s - loss: 0.0973 - acc: 0.8928 - val_loss: 0.1060 - val_acc: 0.8609\n",
      "Epoch 297/600\n",
      "0s - loss: 0.0969 - acc: 0.8942 - val_loss: 0.1059 - val_acc: 0.8565\n",
      "Epoch 298/600\n",
      "0s - loss: 0.0966 - acc: 0.8928 - val_loss: 0.1060 - val_acc: 0.8565\n",
      "Epoch 299/600\n",
      "0s - loss: 0.0962 - acc: 0.8913 - val_loss: 0.1055 - val_acc: 0.8565\n",
      "Epoch 300/600\n",
      "0s - loss: 0.0958 - acc: 0.8928 - val_loss: 0.1052 - val_acc: 0.8565\n",
      "Epoch 301/600\n",
      "0s - loss: 0.0955 - acc: 0.8928 - val_loss: 0.1050 - val_acc: 0.8565\n",
      "Epoch 302/600\n",
      "0s - loss: 0.0951 - acc: 0.8928 - val_loss: 0.1048 - val_acc: 0.8565\n",
      "Epoch 303/600\n",
      "0s - loss: 0.0948 - acc: 0.8928 - val_loss: 0.1043 - val_acc: 0.8652\n",
      "Epoch 304/600\n",
      "0s - loss: 0.0945 - acc: 0.8957 - val_loss: 0.1043 - val_acc: 0.8565\n",
      "Epoch 305/600\n",
      "0s - loss: 0.0941 - acc: 0.8928 - val_loss: 0.1042 - val_acc: 0.8565\n",
      "Epoch 306/600\n",
      "0s - loss: 0.0938 - acc: 0.8928 - val_loss: 0.1040 - val_acc: 0.8565\n",
      "Epoch 307/600\n",
      "0s - loss: 0.0934 - acc: 0.8928 - val_loss: 0.1037 - val_acc: 0.8565\n",
      "Epoch 308/600\n",
      "0s - loss: 0.0931 - acc: 0.8928 - val_loss: 0.1034 - val_acc: 0.8565\n",
      "Epoch 309/600\n",
      "0s - loss: 0.0928 - acc: 0.8971 - val_loss: 0.1030 - val_acc: 0.8565\n",
      "Epoch 310/600\n",
      "0s - loss: 0.0926 - acc: 0.8957 - val_loss: 0.1027 - val_acc: 0.8609\n",
      "Epoch 311/600\n",
      "0s - loss: 0.0922 - acc: 0.8971 - val_loss: 0.1025 - val_acc: 0.8609\n",
      "Epoch 312/600\n",
      "0s - loss: 0.0919 - acc: 0.8971 - val_loss: 0.1022 - val_acc: 0.8652\n",
      "Epoch 313/600\n",
      "0s - loss: 0.0916 - acc: 0.8971 - val_loss: 0.1023 - val_acc: 0.8565\n",
      "Epoch 314/600\n",
      "0s - loss: 0.0912 - acc: 0.8971 - val_loss: 0.1021 - val_acc: 0.8565\n",
      "Epoch 315/600\n",
      "0s - loss: 0.0909 - acc: 0.8971 - val_loss: 0.1020 - val_acc: 0.8565\n",
      "Epoch 316/600\n",
      "0s - loss: 0.0907 - acc: 0.8986 - val_loss: 0.1016 - val_acc: 0.8652\n",
      "Epoch 317/600\n",
      "0s - loss: 0.0904 - acc: 0.8986 - val_loss: 0.1016 - val_acc: 0.8609\n",
      "Epoch 318/600\n",
      "0s - loss: 0.0901 - acc: 0.8986 - val_loss: 0.1013 - val_acc: 0.8696\n",
      "Epoch 319/600\n",
      "0s - loss: 0.0899 - acc: 0.8971 - val_loss: 0.1014 - val_acc: 0.8609\n",
      "Epoch 320/600\n",
      "0s - loss: 0.0895 - acc: 0.9043 - val_loss: 0.1013 - val_acc: 0.8609\n",
      "Epoch 321/600\n",
      "0s - loss: 0.0893 - acc: 0.9043 - val_loss: 0.1011 - val_acc: 0.8609\n",
      "Epoch 322/600\n",
      "0s - loss: 0.0890 - acc: 0.9043 - val_loss: 0.1010 - val_acc: 0.8609\n",
      "Epoch 323/600\n",
      "0s - loss: 0.0887 - acc: 0.9043 - val_loss: 0.1009 - val_acc: 0.8609\n",
      "Epoch 324/600\n",
      "0s - loss: 0.0885 - acc: 0.9043 - val_loss: 0.1005 - val_acc: 0.8696\n",
      "Epoch 325/600\n",
      "0s - loss: 0.0882 - acc: 0.9029 - val_loss: 0.1005 - val_acc: 0.8652\n",
      "Epoch 326/600\n",
      "0s - loss: 0.0880 - acc: 0.9029 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 327/600\n",
      "0s - loss: 0.0877 - acc: 0.9029 - val_loss: 0.1003 - val_acc: 0.8652\n",
      "Epoch 328/600\n",
      "0s - loss: 0.0875 - acc: 0.9029 - val_loss: 0.1003 - val_acc: 0.8609\n",
      "Epoch 329/600\n",
      "0s - loss: 0.0872 - acc: 0.9029 - val_loss: 0.1001 - val_acc: 0.8609\n",
      "Epoch 330/600\n",
      "0s - loss: 0.0870 - acc: 0.9029 - val_loss: 0.0997 - val_acc: 0.8652\n",
      "Epoch 331/600\n",
      "0s - loss: 0.0867 - acc: 0.9029 - val_loss: 0.0995 - val_acc: 0.8696\n",
      "Epoch 332/600\n",
      "0s - loss: 0.0864 - acc: 0.9043 - val_loss: 0.0993 - val_acc: 0.8696\n",
      "Epoch 333/600\n",
      "0s - loss: 0.0862 - acc: 0.9043 - val_loss: 0.0992 - val_acc: 0.8696\n",
      "Epoch 334/600\n",
      "0s - loss: 0.0860 - acc: 0.9043 - val_loss: 0.0988 - val_acc: 0.8696\n",
      "Epoch 335/600\n",
      "0s - loss: 0.0857 - acc: 0.9029 - val_loss: 0.0988 - val_acc: 0.8696\n",
      "Epoch 336/600\n",
      "0s - loss: 0.0855 - acc: 0.9043 - val_loss: 0.0986 - val_acc: 0.8696\n",
      "Epoch 337/600\n",
      "0s - loss: 0.0852 - acc: 0.9029 - val_loss: 0.0984 - val_acc: 0.8696\n",
      "Epoch 338/600\n",
      "0s - loss: 0.0850 - acc: 0.9029 - val_loss: 0.0986 - val_acc: 0.8652\n",
      "Epoch 339/600\n",
      "0s - loss: 0.0847 - acc: 0.9072 - val_loss: 0.0982 - val_acc: 0.8696\n",
      "Epoch 340/600\n",
      "0s - loss: 0.0845 - acc: 0.9058 - val_loss: 0.0979 - val_acc: 0.8696\n",
      "Epoch 341/600\n",
      "0s - loss: 0.0843 - acc: 0.9029 - val_loss: 0.0976 - val_acc: 0.8696\n",
      "Epoch 342/600\n",
      "0s - loss: 0.0840 - acc: 0.9043 - val_loss: 0.0974 - val_acc: 0.8696\n",
      "Epoch 343/600\n",
      "0s - loss: 0.0838 - acc: 0.9043 - val_loss: 0.0976 - val_acc: 0.8696\n",
      "Epoch 344/600\n",
      "0s - loss: 0.0836 - acc: 0.9072 - val_loss: 0.0975 - val_acc: 0.8652\n",
      "Epoch 345/600\n",
      "0s - loss: 0.0834 - acc: 0.9072 - val_loss: 0.0972 - val_acc: 0.8696\n",
      "Epoch 346/600\n",
      "0s - loss: 0.0832 - acc: 0.9072 - val_loss: 0.0973 - val_acc: 0.8652\n",
      "Epoch 347/600\n",
      "0s - loss: 0.0831 - acc: 0.9072 - val_loss: 0.0975 - val_acc: 0.8609\n",
      "Epoch 348/600\n",
      "0s - loss: 0.0829 - acc: 0.9072 - val_loss: 0.0973 - val_acc: 0.8652\n",
      "Epoch 349/600\n",
      "0s - loss: 0.0827 - acc: 0.9072 - val_loss: 0.0968 - val_acc: 0.8696\n",
      "Epoch 350/600\n",
      "0s - loss: 0.0825 - acc: 0.9072 - val_loss: 0.0965 - val_acc: 0.8696\n",
      "Epoch 351/600\n",
      "0s - loss: 0.0823 - acc: 0.9072 - val_loss: 0.0963 - val_acc: 0.8696\n",
      "Epoch 352/600\n",
      "0s - loss: 0.0821 - acc: 0.9072 - val_loss: 0.0965 - val_acc: 0.8696\n",
      "Epoch 353/600\n",
      "0s - loss: 0.0820 - acc: 0.9072 - val_loss: 0.0967 - val_acc: 0.8696\n",
      "Epoch 354/600\n",
      "0s - loss: 0.0817 - acc: 0.9072 - val_loss: 0.0964 - val_acc: 0.8696\n",
      "Epoch 355/600\n",
      "0s - loss: 0.0815 - acc: 0.9072 - val_loss: 0.0962 - val_acc: 0.8696\n",
      "Epoch 356/600\n",
      "0s - loss: 0.0814 - acc: 0.9072 - val_loss: 0.0959 - val_acc: 0.8696\n",
      "Epoch 357/600\n",
      "0s - loss: 0.0812 - acc: 0.9058 - val_loss: 0.0960 - val_acc: 0.8696\n",
      "Epoch 358/600\n",
      "0s - loss: 0.0811 - acc: 0.9072 - val_loss: 0.0955 - val_acc: 0.8739\n",
      "Epoch 359/600\n",
      "0s - loss: 0.0809 - acc: 0.9043 - val_loss: 0.0956 - val_acc: 0.8739\n",
      "Epoch 360/600\n",
      "0s - loss: 0.0808 - acc: 0.9058 - val_loss: 0.0953 - val_acc: 0.8739\n",
      "Epoch 361/600\n",
      "0s - loss: 0.0806 - acc: 0.9043 - val_loss: 0.0953 - val_acc: 0.8739\n",
      "Epoch 362/600\n",
      "0s - loss: 0.0805 - acc: 0.9058 - val_loss: 0.0955 - val_acc: 0.8696\n",
      "Epoch 363/600\n",
      "0s - loss: 0.0803 - acc: 0.9058 - val_loss: 0.0954 - val_acc: 0.8696\n",
      "Epoch 364/600\n",
      "0s - loss: 0.0802 - acc: 0.9043 - val_loss: 0.0956 - val_acc: 0.8652\n",
      "Epoch 365/600\n",
      "0s - loss: 0.0800 - acc: 0.9058 - val_loss: 0.0956 - val_acc: 0.8652\n",
      "Epoch 366/600\n",
      "0s - loss: 0.0799 - acc: 0.9043 - val_loss: 0.0952 - val_acc: 0.8696\n",
      "Epoch 367/600\n",
      "0s - loss: 0.0797 - acc: 0.9043 - val_loss: 0.0951 - val_acc: 0.8696\n",
      "Epoch 368/600\n",
      "0s - loss: 0.0796 - acc: 0.9043 - val_loss: 0.0953 - val_acc: 0.8652\n",
      "Epoch 369/600\n",
      "0s - loss: 0.0795 - acc: 0.9043 - val_loss: 0.0953 - val_acc: 0.8652\n",
      "Epoch 370/600\n",
      "0s - loss: 0.0793 - acc: 0.9014 - val_loss: 0.0950 - val_acc: 0.8652\n",
      "Epoch 371/600\n",
      "0s - loss: 0.0791 - acc: 0.9029 - val_loss: 0.0947 - val_acc: 0.8696\n",
      "Epoch 372/600\n",
      "0s - loss: 0.0789 - acc: 0.9043 - val_loss: 0.0946 - val_acc: 0.8696\n",
      "Epoch 373/600\n",
      "0s - loss: 0.0788 - acc: 0.9029 - val_loss: 0.0942 - val_acc: 0.8696\n",
      "Epoch 374/600\n",
      "0s - loss: 0.0787 - acc: 0.9043 - val_loss: 0.0941 - val_acc: 0.8696\n",
      "Epoch 375/600\n",
      "0s - loss: 0.0786 - acc: 0.9058 - val_loss: 0.0942 - val_acc: 0.8696\n",
      "Epoch 376/600\n",
      "0s - loss: 0.0784 - acc: 0.9043 - val_loss: 0.0941 - val_acc: 0.8696\n",
      "Epoch 377/600\n",
      "0s - loss: 0.0784 - acc: 0.9043 - val_loss: 0.0944 - val_acc: 0.8696\n",
      "Epoch 378/600\n",
      "0s - loss: 0.0782 - acc: 0.9014 - val_loss: 0.0945 - val_acc: 0.8652\n",
      "Epoch 379/600\n",
      "0s - loss: 0.0782 - acc: 0.9014 - val_loss: 0.0940 - val_acc: 0.8696\n",
      "Epoch 380/600\n",
      "0s - loss: 0.0780 - acc: 0.9029 - val_loss: 0.0939 - val_acc: 0.8696\n",
      "Epoch 381/600\n",
      "0s - loss: 0.0779 - acc: 0.9029 - val_loss: 0.0936 - val_acc: 0.8739\n",
      "Epoch 382/600\n",
      "0s - loss: 0.0777 - acc: 0.9043 - val_loss: 0.0937 - val_acc: 0.8739\n",
      "Epoch 383/600\n",
      "0s - loss: 0.0776 - acc: 0.9029 - val_loss: 0.0937 - val_acc: 0.8739\n",
      "Epoch 384/600\n",
      "0s - loss: 0.0775 - acc: 0.9014 - val_loss: 0.0936 - val_acc: 0.8739\n",
      "Epoch 385/600\n",
      "0s - loss: 0.0774 - acc: 0.9014 - val_loss: 0.0937 - val_acc: 0.8696\n",
      "Epoch 386/600\n",
      "0s - loss: 0.0773 - acc: 0.9014 - val_loss: 0.0933 - val_acc: 0.8739\n",
      "Epoch 387/600\n",
      "0s - loss: 0.0771 - acc: 0.9014 - val_loss: 0.0931 - val_acc: 0.8739\n",
      "Epoch 388/600\n",
      "0s - loss: 0.0770 - acc: 0.9014 - val_loss: 0.0931 - val_acc: 0.8739\n",
      "Epoch 389/600\n",
      "0s - loss: 0.0769 - acc: 0.9014 - val_loss: 0.0929 - val_acc: 0.8739\n",
      "Epoch 390/600\n",
      "0s - loss: 0.0768 - acc: 0.9014 - val_loss: 0.0930 - val_acc: 0.8739\n",
      "Epoch 391/600\n",
      "0s - loss: 0.0767 - acc: 0.9014 - val_loss: 0.0926 - val_acc: 0.8739\n",
      "Epoch 392/600\n",
      "0s - loss: 0.0766 - acc: 0.8986 - val_loss: 0.0928 - val_acc: 0.8739\n",
      "Epoch 393/600\n",
      "0s - loss: 0.0765 - acc: 0.9014 - val_loss: 0.0926 - val_acc: 0.8739\n",
      "Epoch 394/600\n",
      "0s - loss: 0.0764 - acc: 0.8986 - val_loss: 0.0924 - val_acc: 0.8739\n",
      "Epoch 395/600\n",
      "0s - loss: 0.0763 - acc: 0.8986 - val_loss: 0.0925 - val_acc: 0.8739\n",
      "Epoch 396/600\n",
      "0s - loss: 0.0762 - acc: 0.8986 - val_loss: 0.0922 - val_acc: 0.8739\n",
      "Epoch 397/600\n",
      "0s - loss: 0.0761 - acc: 0.8986 - val_loss: 0.0925 - val_acc: 0.8739\n",
      "Epoch 398/600\n",
      "0s - loss: 0.0761 - acc: 0.8986 - val_loss: 0.0921 - val_acc: 0.8739\n",
      "Epoch 399/600\n",
      "0s - loss: 0.0760 - acc: 0.9000 - val_loss: 0.0921 - val_acc: 0.8739\n",
      "Epoch 400/600\n",
      "0s - loss: 0.0759 - acc: 0.8986 - val_loss: 0.0923 - val_acc: 0.8739\n",
      "Epoch 401/600\n",
      "0s - loss: 0.0758 - acc: 0.8986 - val_loss: 0.0923 - val_acc: 0.8739\n",
      "Epoch 402/600\n",
      "0s - loss: 0.0757 - acc: 0.8986 - val_loss: 0.0921 - val_acc: 0.8739\n",
      "Epoch 403/600\n",
      "0s - loss: 0.0756 - acc: 0.8986 - val_loss: 0.0923 - val_acc: 0.8739\n",
      "Epoch 404/600\n",
      "0s - loss: 0.0756 - acc: 0.9000 - val_loss: 0.0920 - val_acc: 0.8739\n",
      "Epoch 405/600\n",
      "0s - loss: 0.0755 - acc: 0.8986 - val_loss: 0.0919 - val_acc: 0.8739\n",
      "Epoch 406/600\n",
      "0s - loss: 0.0754 - acc: 0.9000 - val_loss: 0.0919 - val_acc: 0.8739\n",
      "Epoch 407/600\n",
      "0s - loss: 0.0753 - acc: 0.9000 - val_loss: 0.0919 - val_acc: 0.8739\n",
      "Epoch 408/600\n",
      "0s - loss: 0.0753 - acc: 0.9000 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 409/600\n",
      "0s - loss: 0.0753 - acc: 0.9014 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 410/600\n",
      "0s - loss: 0.0752 - acc: 0.9029 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 411/600\n",
      "0s - loss: 0.0751 - acc: 0.9029 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 412/600\n",
      "0s - loss: 0.0750 - acc: 0.9014 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 413/600\n",
      "0s - loss: 0.0750 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 414/600\n",
      "0s - loss: 0.0749 - acc: 0.9029 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 415/600\n",
      "0s - loss: 0.0748 - acc: 0.9029 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 416/600\n",
      "0s - loss: 0.0747 - acc: 0.9029 - val_loss: 0.0913 - val_acc: 0.8739\n",
      "Epoch 417/600\n",
      "0s - loss: 0.0747 - acc: 0.9029 - val_loss: 0.0913 - val_acc: 0.8739\n",
      "Epoch 418/600\n",
      "0s - loss: 0.0746 - acc: 0.9029 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 419/600\n",
      "0s - loss: 0.0745 - acc: 0.9043 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 420/600\n",
      "0s - loss: 0.0745 - acc: 0.9043 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 421/600\n",
      "0s - loss: 0.0744 - acc: 0.9043 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 422/600\n",
      "0s - loss: 0.0743 - acc: 0.9043 - val_loss: 0.0916 - val_acc: 0.8739\n",
      "Epoch 423/600\n",
      "0s - loss: 0.0743 - acc: 0.9043 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 424/600\n",
      "0s - loss: 0.0742 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 425/600\n",
      "0s - loss: 0.0742 - acc: 0.9043 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 426/600\n",
      "0s - loss: 0.0741 - acc: 0.9029 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 427/600\n",
      "0s - loss: 0.0741 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 428/600\n",
      "0s - loss: 0.0740 - acc: 0.9043 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 429/600\n",
      "0s - loss: 0.0740 - acc: 0.9043 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 430/600\n",
      "0s - loss: 0.0739 - acc: 0.9043 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 431/600\n",
      "0s - loss: 0.0739 - acc: 0.9029 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 432/600\n",
      "0s - loss: 0.0740 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 433/600\n",
      "0s - loss: 0.0738 - acc: 0.9014 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 434/600\n",
      "0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 435/600\n",
      "0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 436/600\n",
      "0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 437/600\n",
      "0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8783\n",
      "Epoch 438/600\n",
      "0s - loss: 0.0736 - acc: 0.9043 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 439/600\n",
      "0s - loss: 0.0736 - acc: 0.9043 - val_loss: 0.0916 - val_acc: 0.8826\n",
      "Epoch 440/600\n",
      "0s - loss: 0.0737 - acc: 0.9029 - val_loss: 0.0918 - val_acc: 0.8826\n",
      "Epoch 441/600\n",
      "0s - loss: 0.0736 - acc: 0.9029 - val_loss: 0.0918 - val_acc: 0.8826\n",
      "Epoch 442/600\n",
      "0s - loss: 0.0736 - acc: 0.9029 - val_loss: 0.0917 - val_acc: 0.8826\n",
      "Epoch 443/600\n",
      "0s - loss: 0.0735 - acc: 0.9029 - val_loss: 0.0914 - val_acc: 0.8783\n",
      "Epoch 444/600\n",
      "0s - loss: 0.0734 - acc: 0.9058 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 445/600\n",
      "0s - loss: 0.0734 - acc: 0.9058 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 446/600\n",
      "0s - loss: 0.0734 - acc: 0.9043 - val_loss: 0.0908 - val_acc: 0.8783\n",
      "Epoch 447/600\n",
      "0s - loss: 0.0734 - acc: 0.9043 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 448/600\n",
      "0s - loss: 0.0733 - acc: 0.9058 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 449/600\n",
      "0s - loss: 0.0733 - acc: 0.9058 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 450/600\n",
      "0s - loss: 0.0732 - acc: 0.9058 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 451/600\n",
      "0s - loss: 0.0732 - acc: 0.9058 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 452/600\n",
      "0s - loss: 0.0732 - acc: 0.9058 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 453/600\n",
      "0s - loss: 0.0732 - acc: 0.9058 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 454/600\n",
      "0s - loss: 0.0731 - acc: 0.9058 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 455/600\n",
      "0s - loss: 0.0731 - acc: 0.9072 - val_loss: 0.0914 - val_acc: 0.8783\n",
      "Epoch 456/600\n",
      "0s - loss: 0.0731 - acc: 0.9058 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 457/600\n",
      "0s - loss: 0.0731 - acc: 0.9058 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 458/600\n",
      "0s - loss: 0.0731 - acc: 0.9072 - val_loss: 0.0915 - val_acc: 0.8783\n",
      "Epoch 459/600\n",
      "0s - loss: 0.0731 - acc: 0.9058 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 460/600\n",
      "0s - loss: 0.0730 - acc: 0.9058 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 461/600\n",
      "0s - loss: 0.0730 - acc: 0.9058 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 462/600\n",
      "0s - loss: 0.0730 - acc: 0.9072 - val_loss: 0.0908 - val_acc: 0.8783\n",
      "Epoch 463/600\n",
      "0s - loss: 0.0729 - acc: 0.9087 - val_loss: 0.0908 - val_acc: 0.8783\n",
      "Epoch 464/600\n",
      "0s - loss: 0.0729 - acc: 0.9072 - val_loss: 0.0905 - val_acc: 0.8783\n",
      "Epoch 465/600\n",
      "0s - loss: 0.0729 - acc: 0.9072 - val_loss: 0.0906 - val_acc: 0.8783\n",
      "Epoch 466/600\n",
      "0s - loss: 0.0729 - acc: 0.9087 - val_loss: 0.0905 - val_acc: 0.8783\n",
      "Epoch 467/600\n",
      "0s - loss: 0.0728 - acc: 0.9087 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 468/600\n",
      "0s - loss: 0.0729 - acc: 0.9058 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 469/600\n",
      "0s - loss: 0.0728 - acc: 0.9101 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 470/600\n",
      "0s - loss: 0.0727 - acc: 0.9101 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 471/600\n",
      "0s - loss: 0.0727 - acc: 0.9101 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 472/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 473/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0906 - val_acc: 0.8783\n",
      "Epoch 474/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0906 - val_acc: 0.8783\n",
      "Epoch 475/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0905 - val_acc: 0.8783\n",
      "Epoch 476/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 477/600\n",
      "0s - loss: 0.0727 - acc: 0.9087 - val_loss: 0.0906 - val_acc: 0.8783\n",
      "Epoch 478/600\n",
      "0s - loss: 0.0726 - acc: 0.9087 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 479/600\n",
      "0s - loss: 0.0726 - acc: 0.9087 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 480/600\n",
      "0s - loss: 0.0725 - acc: 0.9087 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 481/600\n",
      "0s - loss: 0.0726 - acc: 0.9101 - val_loss: 0.0906 - val_acc: 0.8783\n",
      "Epoch 482/600\n",
      "0s - loss: 0.0725 - acc: 0.9130 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 483/600\n",
      "0s - loss: 0.0725 - acc: 0.9116 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 484/600\n",
      "0s - loss: 0.0725 - acc: 0.9087 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 485/600\n",
      "0s - loss: 0.0725 - acc: 0.9087 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 486/600\n",
      "0s - loss: 0.0725 - acc: 0.9116 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 487/600\n",
      "0s - loss: 0.0724 - acc: 0.9116 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 488/600\n",
      "0s - loss: 0.0724 - acc: 0.9101 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 489/600\n",
      "0s - loss: 0.0725 - acc: 0.9087 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 490/600\n",
      "0s - loss: 0.0724 - acc: 0.9087 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 491/600\n",
      "0s - loss: 0.0724 - acc: 0.9101 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 492/600\n",
      "0s - loss: 0.0724 - acc: 0.9101 - val_loss: 0.0908 - val_acc: 0.8783\n",
      "Epoch 493/600\n",
      "0s - loss: 0.0724 - acc: 0.9101 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 494/600\n",
      "0s - loss: 0.0724 - acc: 0.9116 - val_loss: 0.0908 - val_acc: 0.8739\n",
      "Epoch 495/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 496/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0908 - val_acc: 0.8783\n",
      "Epoch 497/600\n",
      "0s - loss: 0.0724 - acc: 0.9101 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 498/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 499/600\n",
      "0s - loss: 0.0723 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 500/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 501/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0913 - val_acc: 0.8739\n",
      "Epoch 502/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 503/600\n",
      "0s - loss: 0.0724 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 504/600\n",
      "0s - loss: 0.0722 - acc: 0.9116 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 505/600\n",
      "0s - loss: 0.0723 - acc: 0.9101 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 506/600\n",
      "0s - loss: 0.0722 - acc: 0.9116 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 507/600\n",
      "0s - loss: 0.0722 - acc: 0.9116 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 508/600\n",
      "0s - loss: 0.0722 - acc: 0.9116 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 509/600\n",
      "0s - loss: 0.0722 - acc: 0.9116 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 510/600\n",
      "0s - loss: 0.0722 - acc: 0.9130 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 511/600\n",
      "0s - loss: 0.0722 - acc: 0.9101 - val_loss: 0.0907 - val_acc: 0.8739\n",
      "Epoch 512/600\n",
      "0s - loss: 0.0722 - acc: 0.9101 - val_loss: 0.0905 - val_acc: 0.8783\n",
      "Epoch 513/600\n",
      "0s - loss: 0.0722 - acc: 0.9130 - val_loss: 0.0906 - val_acc: 0.8739\n",
      "Epoch 514/600\n",
      "0s - loss: 0.0722 - acc: 0.9101 - val_loss: 0.0906 - val_acc: 0.8739\n",
      "Epoch 515/600\n",
      "0s - loss: 0.0722 - acc: 0.9145 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 516/600\n",
      "0s - loss: 0.0721 - acc: 0.9116 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 517/600\n",
      "0s - loss: 0.0721 - acc: 0.9116 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 518/600\n",
      "0s - loss: 0.0721 - acc: 0.9130 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 519/600\n",
      "0s - loss: 0.0721 - acc: 0.9116 - val_loss: 0.0909 - val_acc: 0.8739\n",
      "Epoch 520/600\n",
      "0s - loss: 0.0721 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 521/600\n",
      "0s - loss: 0.0721 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 522/600\n",
      "0s - loss: 0.0721 - acc: 0.9145 - val_loss: 0.0908 - val_acc: 0.8739\n",
      "Epoch 523/600\n",
      "0s - loss: 0.0721 - acc: 0.9116 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 524/600\n",
      "0s - loss: 0.0720 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 525/600\n",
      "0s - loss: 0.0720 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 526/600\n",
      "0s - loss: 0.0720 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 527/600\n",
      "0s - loss: 0.0720 - acc: 0.9116 - val_loss: 0.0908 - val_acc: 0.8739\n",
      "Epoch 528/600\n",
      "0s - loss: 0.0720 - acc: 0.9116 - val_loss: 0.0910 - val_acc: 0.8739\n",
      "Epoch 529/600\n",
      "0s - loss: 0.0720 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 530/600\n",
      "0s - loss: 0.0720 - acc: 0.9145 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 531/600\n",
      "0s - loss: 0.0719 - acc: 0.9145 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 532/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 533/600\n",
      "0s - loss: 0.0719 - acc: 0.9145 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 534/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8739\n",
      "Epoch 535/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 536/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 537/600\n",
      "0s - loss: 0.0719 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8739\n",
      "Epoch 538/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 539/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 540/600\n",
      "0s - loss: 0.0718 - acc: 0.9116 - val_loss: 0.0912 - val_acc: 0.8739\n",
      "Epoch 541/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 542/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0917 - val_acc: 0.8739\n",
      "Epoch 543/600\n",
      "0s - loss: 0.0719 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8739\n",
      "Epoch 544/600\n",
      "0s - loss: 0.0718 - acc: 0.9145 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 545/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 546/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 547/600\n",
      "0s - loss: 0.0718 - acc: 0.9116 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 548/600\n",
      "0s - loss: 0.0718 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 549/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 550/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 551/600\n",
      "0s - loss: 0.0718 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8783\n",
      "Epoch 552/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 553/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 554/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 555/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 556/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 557/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0915 - val_acc: 0.8739\n",
      "Epoch 558/600\n",
      "0s - loss: 0.0717 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 559/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 560/600\n",
      "0s - loss: 0.0716 - acc: 0.9145 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 561/600\n",
      "0s - loss: 0.0716 - acc: 0.9145 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 562/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 563/600\n",
      "0s - loss: 0.0717 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 564/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 565/600\n",
      "0s - loss: 0.0717 - acc: 0.9145 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 566/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 567/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 568/600\n",
      "0s - loss: 0.0716 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 569/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 570/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 571/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 572/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 573/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 574/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 575/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 576/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 577/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0907 - val_acc: 0.8783\n",
      "Epoch 578/600\n",
      "0s - loss: 0.0716 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 579/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 580/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 581/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 582/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8739\n",
      "Epoch 583/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0914 - val_acc: 0.8783\n",
      "Epoch 584/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 585/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0915 - val_acc: 0.8783\n",
      "Epoch 586/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 587/600\n",
      "0s - loss: 0.0715 - acc: 0.9130 - val_loss: 0.0909 - val_acc: 0.8783\n",
      "Epoch 588/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 589/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 590/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 591/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Epoch 592/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 593/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 594/600\n",
      "0s - loss: 0.0713 - acc: 0.9130 - val_loss: 0.0913 - val_acc: 0.8783\n",
      "Epoch 595/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 596/600\n",
      "0s - loss: 0.0714 - acc: 0.9116 - val_loss: 0.0908 - val_acc: 0.8826\n",
      "Epoch 597/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0907 - val_acc: 0.8826\n",
      "Epoch 598/600\n",
      "0s - loss: 0.0714 - acc: 0.9130 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 599/600\n",
      "0s - loss: 0.0713 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8783\n",
      "Epoch 600/600\n",
      "0s - loss: 0.0713 - acc: 0.9145 - val_loss: 0.0912 - val_acc: 0.8783\n",
      "Train Score:  92.8743422377\n",
      "Test Score:  90.882385101\n"
     ]
    }
   ],
   "source": [
    "#without k best features,sigmoid and rmsprop\n",
    "m1=make_model('sigmoid','rmsprop',x_train.shape[1],[x_train.shape[1],16],x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected 1 predicted: 0.127955   0\n",
      "expected 1 predicted: 0.22189   1\n",
      "expected 0 predicted: 0.718349   1\n",
      "expected 0 predicted: 0.966084   1\n",
      "expected 0 predicted: 0.880699   1\n",
      "expected 1 predicted: 0.126082   1\n",
      "expected 1 predicted: 0.0665667   0\n",
      "expected 1 predicted: 0.220216   0\n",
      "expected 1 predicted: 0.162432   0\n",
      "expected 0 predicted: 0.623086   1\n",
      "expected 1 predicted: 0.150062   0\n",
      "expected 1 predicted: 0.653981   0\n",
      "expected 0 predicted: 0.845451   1\n",
      "expected 0 predicted: 0.887515   1\n",
      "expected 1 predicted: 0.11685   0\n",
      "expected 1 predicted: 0.137596   0\n",
      "expected 1 predicted: 0.525477   0\n",
      "expected 0 predicted: 0.937237   1\n",
      "expected 1 predicted: 0.490873   0\n",
      "expected 1 predicted: 0.235449   0\n",
      "expected 1 predicted: 0.562639   0\n",
      "expected 0 predicted: 0.930634   1\n",
      "expected 0 predicted: 0.687741   1\n",
      "expected 0 predicted: 0.92892   1\n",
      "expected 1 predicted: 0.0514194   0\n",
      "error 10\n"
     ]
    }
   ],
   "source": [
    "pr=m1.predict(x_test)\n",
    "u=0\n",
    "k=0\n",
    "k=0\n",
    "for u in range(len(x_test)):\n",
    "    if round(pr[u][0],1)>=0.3 and round(pr[u][0],1)<=0.8:\n",
    "        g=svmpred[u]\n",
    "    else:\n",
    "        g=round(pr[u][0],0)\n",
    "    if g!=y_test[u]:    \n",
    "        print \"expected\",y_test[u],\"predicted:\",pr[u][0],\" \",svmpred[u]\n",
    "        k=k+1\n",
    "print \"error\",k*100/len(y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 5)\n"
     ]
    }
   ],
   "source": [
    "print tx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=\"sigmoid\", kernel_initializer=\"uniform\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 690 samples, validate on 230 samples\n",
      "Epoch 1/600\n",
      "0s - loss: 0.2494 - acc: 0.5435 - val_loss: 0.2470 - val_acc: 0.5826\n",
      "Epoch 2/600\n",
      "0s - loss: 0.2486 - acc: 0.5435 - val_loss: 0.2459 - val_acc: 0.5826\n",
      "Epoch 3/600\n",
      "0s - loss: 0.2482 - acc: 0.5435 - val_loss: 0.2456 - val_acc: 0.5826\n",
      "Epoch 4/600\n",
      "0s - loss: 0.2482 - acc: 0.5435 - val_loss: 0.2456 - val_acc: 0.5826\n",
      "Epoch 5/600\n",
      "0s - loss: 0.2482 - acc: 0.5435 - val_loss: 0.2456 - val_acc: 0.5826\n",
      "Epoch 6/600\n",
      "0s - loss: 0.2481 - acc: 0.5435 - val_loss: 0.2453 - val_acc: 0.5826\n",
      "Epoch 7/600\n",
      "0s - loss: 0.2480 - acc: 0.5435 - val_loss: 0.2450 - val_acc: 0.5826\n",
      "Epoch 8/600\n",
      "0s - loss: 0.2480 - acc: 0.5435 - val_loss: 0.2447 - val_acc: 0.5826\n",
      "Epoch 9/600\n",
      "0s - loss: 0.2479 - acc: 0.5435 - val_loss: 0.2446 - val_acc: 0.5826\n",
      "Epoch 10/600\n",
      "0s - loss: 0.2479 - acc: 0.5435 - val_loss: 0.2443 - val_acc: 0.5826\n",
      "Epoch 11/600\n",
      "0s - loss: 0.2480 - acc: 0.5435 - val_loss: 0.2446 - val_acc: 0.5826\n",
      "Epoch 12/600\n",
      "0s - loss: 0.2478 - acc: 0.5435 - val_loss: 0.2445 - val_acc: 0.5826\n",
      "Epoch 13/600\n",
      "0s - loss: 0.2478 - acc: 0.5435 - val_loss: 0.2447 - val_acc: 0.5826\n",
      "Epoch 14/600\n",
      "0s - loss: 0.2478 - acc: 0.5435 - val_loss: 0.2443 - val_acc: 0.5826\n",
      "Epoch 15/600\n",
      "0s - loss: 0.2477 - acc: 0.5435 - val_loss: 0.2441 - val_acc: 0.5826\n",
      "Epoch 16/600\n",
      "0s - loss: 0.2477 - acc: 0.5435 - val_loss: 0.2440 - val_acc: 0.5826\n",
      "Epoch 17/600\n",
      "0s - loss: 0.2477 - acc: 0.5435 - val_loss: 0.2437 - val_acc: 0.5826\n",
      "Epoch 18/600\n",
      "0s - loss: 0.2476 - acc: 0.5435 - val_loss: 0.2438 - val_acc: 0.5826\n",
      "Epoch 19/600\n",
      "0s - loss: 0.2476 - acc: 0.5435 - val_loss: 0.2435 - val_acc: 0.5826\n",
      "Epoch 20/600\n",
      "0s - loss: 0.2475 - acc: 0.5435 - val_loss: 0.2436 - val_acc: 0.5826\n",
      "Epoch 21/600\n",
      "0s - loss: 0.2474 - acc: 0.5435 - val_loss: 0.2437 - val_acc: 0.5826\n",
      "Epoch 22/600\n",
      "0s - loss: 0.2474 - acc: 0.5435 - val_loss: 0.2435 - val_acc: 0.5826\n",
      "Epoch 23/600\n",
      "0s - loss: 0.2473 - acc: 0.5435 - val_loss: 0.2433 - val_acc: 0.5826\n",
      "Epoch 24/600\n",
      "0s - loss: 0.2472 - acc: 0.5435 - val_loss: 0.2432 - val_acc: 0.5826\n",
      "Epoch 25/600\n",
      "0s - loss: 0.2472 - acc: 0.5435 - val_loss: 0.2435 - val_acc: 0.5826\n",
      "Epoch 26/600\n",
      "0s - loss: 0.2470 - acc: 0.5435 - val_loss: 0.2434 - val_acc: 0.5826\n",
      "Epoch 27/600\n",
      "0s - loss: 0.2470 - acc: 0.5435 - val_loss: 0.2436 - val_acc: 0.5826\n",
      "Epoch 28/600\n",
      "0s - loss: 0.2469 - acc: 0.5435 - val_loss: 0.2434 - val_acc: 0.5826\n",
      "Epoch 29/600\n",
      "0s - loss: 0.2469 - acc: 0.5435 - val_loss: 0.2429 - val_acc: 0.5826\n",
      "Epoch 30/600\n",
      "0s - loss: 0.2467 - acc: 0.5435 - val_loss: 0.2426 - val_acc: 0.5826\n",
      "Epoch 31/600\n",
      "0s - loss: 0.2466 - acc: 0.5435 - val_loss: 0.2426 - val_acc: 0.5826\n",
      "Epoch 32/600\n",
      "0s - loss: 0.2465 - acc: 0.5435 - val_loss: 0.2424 - val_acc: 0.5826\n",
      "Epoch 33/600\n",
      "0s - loss: 0.2463 - acc: 0.5435 - val_loss: 0.2422 - val_acc: 0.5826\n",
      "Epoch 34/600\n",
      "0s - loss: 0.2462 - acc: 0.5435 - val_loss: 0.2420 - val_acc: 0.5826\n",
      "Epoch 35/600\n",
      "0s - loss: 0.2461 - acc: 0.5435 - val_loss: 0.2420 - val_acc: 0.5826\n",
      "Epoch 36/600\n",
      "0s - loss: 0.2460 - acc: 0.5435 - val_loss: 0.2422 - val_acc: 0.5826\n",
      "Epoch 37/600\n",
      "0s - loss: 0.2458 - acc: 0.5435 - val_loss: 0.2418 - val_acc: 0.5826\n",
      "Epoch 38/600\n",
      "0s - loss: 0.2456 - acc: 0.5435 - val_loss: 0.2415 - val_acc: 0.5826\n",
      "Epoch 39/600\n",
      "0s - loss: 0.2455 - acc: 0.5435 - val_loss: 0.2412 - val_acc: 0.5826\n",
      "Epoch 40/600\n",
      "0s - loss: 0.2453 - acc: 0.5435 - val_loss: 0.2409 - val_acc: 0.5826\n",
      "Epoch 41/600\n",
      "0s - loss: 0.2451 - acc: 0.5435 - val_loss: 0.2408 - val_acc: 0.5826\n",
      "Epoch 42/600\n",
      "0s - loss: 0.2449 - acc: 0.5435 - val_loss: 0.2406 - val_acc: 0.5826\n",
      "Epoch 43/600\n",
      "0s - loss: 0.2449 - acc: 0.5435 - val_loss: 0.2402 - val_acc: 0.5826\n",
      "Epoch 44/600\n",
      "0s - loss: 0.2446 - acc: 0.5435 - val_loss: 0.2403 - val_acc: 0.5826\n",
      "Epoch 45/600\n",
      "0s - loss: 0.2443 - acc: 0.5435 - val_loss: 0.2400 - val_acc: 0.5826\n",
      "Epoch 46/600\n",
      "0s - loss: 0.2441 - acc: 0.5435 - val_loss: 0.2399 - val_acc: 0.5826\n",
      "Epoch 47/600\n",
      "0s - loss: 0.2439 - acc: 0.5435 - val_loss: 0.2396 - val_acc: 0.5826\n",
      "Epoch 48/600\n",
      "0s - loss: 0.2436 - acc: 0.5435 - val_loss: 0.2395 - val_acc: 0.5826\n",
      "Epoch 49/600\n",
      "0s - loss: 0.2434 - acc: 0.5435 - val_loss: 0.2390 - val_acc: 0.5826\n",
      "Epoch 50/600\n",
      "0s - loss: 0.2431 - acc: 0.5435 - val_loss: 0.2386 - val_acc: 0.5826\n",
      "Epoch 51/600\n",
      "0s - loss: 0.2428 - acc: 0.5435 - val_loss: 0.2383 - val_acc: 0.5826\n",
      "Epoch 52/600\n",
      "0s - loss: 0.2426 - acc: 0.5435 - val_loss: 0.2383 - val_acc: 0.5826\n",
      "Epoch 53/600\n",
      "0s - loss: 0.2422 - acc: 0.5435 - val_loss: 0.2379 - val_acc: 0.5826\n",
      "Epoch 54/600\n",
      "0s - loss: 0.2420 - acc: 0.5435 - val_loss: 0.2378 - val_acc: 0.5826\n",
      "Epoch 55/600\n",
      "0s - loss: 0.2416 - acc: 0.5435 - val_loss: 0.2373 - val_acc: 0.5826\n",
      "Epoch 56/600\n",
      "0s - loss: 0.2413 - acc: 0.5435 - val_loss: 0.2366 - val_acc: 0.5826\n",
      "Epoch 57/600\n",
      "0s - loss: 0.2409 - acc: 0.5435 - val_loss: 0.2362 - val_acc: 0.5826\n",
      "Epoch 58/600\n",
      "0s - loss: 0.2406 - acc: 0.5435 - val_loss: 0.2357 - val_acc: 0.5826\n",
      "Epoch 59/600\n",
      "0s - loss: 0.2402 - acc: 0.5435 - val_loss: 0.2357 - val_acc: 0.5826\n",
      "Epoch 60/600\n",
      "0s - loss: 0.2398 - acc: 0.5435 - val_loss: 0.2350 - val_acc: 0.5826\n",
      "Epoch 61/600\n",
      "0s - loss: 0.2394 - acc: 0.5435 - val_loss: 0.2346 - val_acc: 0.5826\n",
      "Epoch 62/600\n",
      "0s - loss: 0.2390 - acc: 0.5435 - val_loss: 0.2344 - val_acc: 0.5826\n",
      "Epoch 63/600\n",
      "0s - loss: 0.2385 - acc: 0.5435 - val_loss: 0.2337 - val_acc: 0.5826\n",
      "Epoch 64/600\n",
      "0s - loss: 0.2381 - acc: 0.5435 - val_loss: 0.2332 - val_acc: 0.5826\n",
      "Epoch 65/600\n",
      "0s - loss: 0.2377 - acc: 0.5435 - val_loss: 0.2330 - val_acc: 0.5826\n",
      "Epoch 66/600\n",
      "0s - loss: 0.2372 - acc: 0.5435 - val_loss: 0.2328 - val_acc: 0.5826\n",
      "Epoch 67/600\n",
      "0s - loss: 0.2367 - acc: 0.5435 - val_loss: 0.2320 - val_acc: 0.5826\n",
      "Epoch 68/600\n",
      "0s - loss: 0.2362 - acc: 0.5435 - val_loss: 0.2312 - val_acc: 0.5826\n",
      "Epoch 69/600\n",
      "0s - loss: 0.2357 - acc: 0.5435 - val_loss: 0.2308 - val_acc: 0.5826\n",
      "Epoch 70/600\n",
      "0s - loss: 0.2351 - acc: 0.5435 - val_loss: 0.2302 - val_acc: 0.5826\n",
      "Epoch 71/600\n",
      "0s - loss: 0.2345 - acc: 0.5435 - val_loss: 0.2296 - val_acc: 0.5826\n",
      "Epoch 72/600\n",
      "0s - loss: 0.2339 - acc: 0.5435 - val_loss: 0.2288 - val_acc: 0.5826\n",
      "Epoch 73/600\n",
      "0s - loss: 0.2333 - acc: 0.5435 - val_loss: 0.2284 - val_acc: 0.5826\n",
      "Epoch 74/600\n",
      "0s - loss: 0.2328 - acc: 0.5435 - val_loss: 0.2281 - val_acc: 0.5826\n",
      "Epoch 75/600\n",
      "0s - loss: 0.2321 - acc: 0.5435 - val_loss: 0.2272 - val_acc: 0.5826\n",
      "Epoch 76/600\n",
      "0s - loss: 0.2314 - acc: 0.5435 - val_loss: 0.2264 - val_acc: 0.5826\n",
      "Epoch 77/600\n",
      "0s - loss: 0.2308 - acc: 0.5435 - val_loss: 0.2254 - val_acc: 0.5826\n",
      "Epoch 78/600\n",
      "0s - loss: 0.2300 - acc: 0.5435 - val_loss: 0.2248 - val_acc: 0.5826\n",
      "Epoch 79/600\n",
      "0s - loss: 0.2294 - acc: 0.5449 - val_loss: 0.2245 - val_acc: 0.5826\n",
      "Epoch 80/600\n",
      "0s - loss: 0.2287 - acc: 0.5464 - val_loss: 0.2233 - val_acc: 0.5826\n",
      "Epoch 81/600\n",
      "0s - loss: 0.2279 - acc: 0.5449 - val_loss: 0.2227 - val_acc: 0.5826\n",
      "Epoch 82/600\n",
      "0s - loss: 0.2272 - acc: 0.5464 - val_loss: 0.2219 - val_acc: 0.5826\n",
      "Epoch 83/600\n",
      "0s - loss: 0.2265 - acc: 0.5464 - val_loss: 0.2209 - val_acc: 0.5826\n",
      "Epoch 84/600\n",
      "0s - loss: 0.2257 - acc: 0.5478 - val_loss: 0.2200 - val_acc: 0.5826\n",
      "Epoch 85/600\n",
      "0s - loss: 0.2249 - acc: 0.5478 - val_loss: 0.2191 - val_acc: 0.5826\n",
      "Epoch 86/600\n",
      "0s - loss: 0.2241 - acc: 0.5478 - val_loss: 0.2186 - val_acc: 0.5826\n",
      "Epoch 87/600\n",
      "0s - loss: 0.2233 - acc: 0.5493 - val_loss: 0.2181 - val_acc: 0.5913\n",
      "Epoch 88/600\n",
      "0s - loss: 0.2224 - acc: 0.5638 - val_loss: 0.2169 - val_acc: 0.5826\n",
      "Epoch 89/600\n",
      "0s - loss: 0.2216 - acc: 0.5580 - val_loss: 0.2158 - val_acc: 0.5826\n",
      "Epoch 90/600\n",
      "0s - loss: 0.2207 - acc: 0.5580 - val_loss: 0.2149 - val_acc: 0.5957\n",
      "Epoch 91/600\n",
      "0s - loss: 0.2198 - acc: 0.5594 - val_loss: 0.2140 - val_acc: 0.5957\n",
      "Epoch 92/600\n",
      "0s - loss: 0.2189 - acc: 0.5681 - val_loss: 0.2132 - val_acc: 0.6174\n",
      "Epoch 93/600\n",
      "0s - loss: 0.2180 - acc: 0.5783 - val_loss: 0.2124 - val_acc: 0.6391\n",
      "Epoch 94/600\n",
      "0s - loss: 0.2171 - acc: 0.5884 - val_loss: 0.2114 - val_acc: 0.6435\n",
      "Epoch 95/600\n",
      "0s - loss: 0.2161 - acc: 0.5913 - val_loss: 0.2106 - val_acc: 0.6652\n",
      "Epoch 96/600\n",
      "0s - loss: 0.2152 - acc: 0.6188 - val_loss: 0.2092 - val_acc: 0.6522\n",
      "Epoch 97/600\n",
      "0s - loss: 0.2142 - acc: 0.6014 - val_loss: 0.2084 - val_acc: 0.6739\n",
      "Epoch 98/600\n",
      "0s - loss: 0.2132 - acc: 0.6319 - val_loss: 0.2076 - val_acc: 0.7087\n",
      "Epoch 99/600\n",
      "0s - loss: 0.2121 - acc: 0.6507 - val_loss: 0.2064 - val_acc: 0.7130\n",
      "Epoch 100/600\n",
      "0s - loss: 0.2111 - acc: 0.6522 - val_loss: 0.2057 - val_acc: 0.7391\n",
      "Epoch 101/600\n",
      "0s - loss: 0.2102 - acc: 0.6841 - val_loss: 0.2042 - val_acc: 0.7217\n",
      "Epoch 102/600\n",
      "0s - loss: 0.2091 - acc: 0.6565 - val_loss: 0.2031 - val_acc: 0.7348\n",
      "Epoch 103/600\n",
      "0s - loss: 0.2080 - acc: 0.6638 - val_loss: 0.2021 - val_acc: 0.7391\n",
      "Epoch 104/600\n",
      "0s - loss: 0.2071 - acc: 0.6797 - val_loss: 0.2008 - val_acc: 0.7348\n",
      "Epoch 105/600\n",
      "0s - loss: 0.2060 - acc: 0.6667 - val_loss: 0.1998 - val_acc: 0.7435\n",
      "Epoch 106/600\n",
      "0s - loss: 0.2049 - acc: 0.6942 - val_loss: 0.1987 - val_acc: 0.7565\n",
      "Epoch 107/600\n",
      "0s - loss: 0.2038 - acc: 0.7159 - val_loss: 0.1976 - val_acc: 0.7826\n",
      "Epoch 108/600\n",
      "0s - loss: 0.2026 - acc: 0.7406 - val_loss: 0.1966 - val_acc: 0.8043\n",
      "Epoch 109/600\n",
      "0s - loss: 0.2015 - acc: 0.7652 - val_loss: 0.1957 - val_acc: 0.8217\n",
      "Epoch 110/600\n",
      "0s - loss: 0.2004 - acc: 0.7754 - val_loss: 0.1942 - val_acc: 0.8130\n",
      "Epoch 111/600\n",
      "0s - loss: 0.1992 - acc: 0.7754 - val_loss: 0.1928 - val_acc: 0.8130\n",
      "Epoch 112/600\n",
      "0s - loss: 0.1980 - acc: 0.7739 - val_loss: 0.1917 - val_acc: 0.8217\n",
      "Epoch 113/600\n",
      "0s - loss: 0.1969 - acc: 0.7768 - val_loss: 0.1904 - val_acc: 0.8217\n",
      "Epoch 114/600\n",
      "0s - loss: 0.1957 - acc: 0.7754 - val_loss: 0.1895 - val_acc: 0.8391\n",
      "Epoch 115/600\n",
      "0s - loss: 0.1944 - acc: 0.7899 - val_loss: 0.1887 - val_acc: 0.8478\n",
      "Epoch 116/600\n",
      "0s - loss: 0.1932 - acc: 0.7971 - val_loss: 0.1873 - val_acc: 0.8522\n",
      "Epoch 117/600\n",
      "0s - loss: 0.1920 - acc: 0.8000 - val_loss: 0.1859 - val_acc: 0.8522\n",
      "Epoch 118/600\n",
      "0s - loss: 0.1908 - acc: 0.8014 - val_loss: 0.1843 - val_acc: 0.8478\n",
      "Epoch 119/600\n",
      "0s - loss: 0.1896 - acc: 0.8000 - val_loss: 0.1830 - val_acc: 0.8435\n",
      "Epoch 120/600\n",
      "0s - loss: 0.1883 - acc: 0.7971 - val_loss: 0.1821 - val_acc: 0.8522\n",
      "Epoch 121/600\n",
      "0s - loss: 0.1870 - acc: 0.8072 - val_loss: 0.1807 - val_acc: 0.8522\n",
      "Epoch 122/600\n",
      "0s - loss: 0.1857 - acc: 0.8101 - val_loss: 0.1794 - val_acc: 0.8565\n",
      "Epoch 123/600\n",
      "0s - loss: 0.1845 - acc: 0.8116 - val_loss: 0.1786 - val_acc: 0.8609\n",
      "Epoch 124/600\n",
      "0s - loss: 0.1832 - acc: 0.8217 - val_loss: 0.1776 - val_acc: 0.8696\n",
      "Epoch 125/600\n",
      "0s - loss: 0.1820 - acc: 0.8304 - val_loss: 0.1759 - val_acc: 0.8652\n",
      "Epoch 126/600\n",
      "0s - loss: 0.1807 - acc: 0.8217 - val_loss: 0.1748 - val_acc: 0.8696\n",
      "Epoch 127/600\n",
      "0s - loss: 0.1794 - acc: 0.8261 - val_loss: 0.1734 - val_acc: 0.8696\n",
      "Epoch 128/600\n",
      "0s - loss: 0.1782 - acc: 0.8319 - val_loss: 0.1718 - val_acc: 0.8696\n",
      "Epoch 129/600\n",
      "0s - loss: 0.1769 - acc: 0.8203 - val_loss: 0.1709 - val_acc: 0.8696\n",
      "Epoch 130/600\n",
      "0s - loss: 0.1756 - acc: 0.8391 - val_loss: 0.1699 - val_acc: 0.8739\n",
      "Epoch 131/600\n",
      "0s - loss: 0.1744 - acc: 0.8464 - val_loss: 0.1686 - val_acc: 0.8739\n",
      "Epoch 132/600\n",
      "0s - loss: 0.1731 - acc: 0.8464 - val_loss: 0.1673 - val_acc: 0.8739\n",
      "Epoch 133/600\n",
      "0s - loss: 0.1718 - acc: 0.8449 - val_loss: 0.1660 - val_acc: 0.8739\n",
      "Epoch 134/600\n",
      "0s - loss: 0.1705 - acc: 0.8493 - val_loss: 0.1645 - val_acc: 0.8739\n",
      "Epoch 135/600\n",
      "0s - loss: 0.1693 - acc: 0.8493 - val_loss: 0.1628 - val_acc: 0.8696\n",
      "Epoch 136/600\n",
      "0s - loss: 0.1680 - acc: 0.8449 - val_loss: 0.1619 - val_acc: 0.8739\n",
      "Epoch 137/600\n",
      "0s - loss: 0.1667 - acc: 0.8522 - val_loss: 0.1609 - val_acc: 0.8783\n",
      "Epoch 138/600\n",
      "0s - loss: 0.1655 - acc: 0.8565 - val_loss: 0.1593 - val_acc: 0.8739\n",
      "Epoch 139/600\n",
      "0s - loss: 0.1643 - acc: 0.8522 - val_loss: 0.1587 - val_acc: 0.8783\n",
      "Epoch 140/600\n",
      "0s - loss: 0.1630 - acc: 0.8522 - val_loss: 0.1575 - val_acc: 0.8783\n",
      "Epoch 141/600\n",
      "0s - loss: 0.1618 - acc: 0.8536 - val_loss: 0.1558 - val_acc: 0.8783\n",
      "Epoch 142/600\n",
      "0s - loss: 0.1606 - acc: 0.8536 - val_loss: 0.1542 - val_acc: 0.8783\n",
      "Epoch 143/600\n",
      "0s - loss: 0.1595 - acc: 0.8551 - val_loss: 0.1527 - val_acc: 0.8783\n",
      "Epoch 144/600\n",
      "0s - loss: 0.1583 - acc: 0.8536 - val_loss: 0.1521 - val_acc: 0.8826\n",
      "Epoch 145/600\n",
      "0s - loss: 0.1570 - acc: 0.8536 - val_loss: 0.1512 - val_acc: 0.8826\n",
      "Epoch 146/600\n",
      "0s - loss: 0.1559 - acc: 0.8594 - val_loss: 0.1503 - val_acc: 0.8826\n",
      "Epoch 147/600\n",
      "0s - loss: 0.1547 - acc: 0.8609 - val_loss: 0.1490 - val_acc: 0.8826\n",
      "Epoch 148/600\n",
      "0s - loss: 0.1535 - acc: 0.8609 - val_loss: 0.1473 - val_acc: 0.8826\n",
      "Epoch 149/600\n",
      "0s - loss: 0.1524 - acc: 0.8623 - val_loss: 0.1458 - val_acc: 0.8826\n",
      "Epoch 150/600\n",
      "0s - loss: 0.1512 - acc: 0.8565 - val_loss: 0.1450 - val_acc: 0.8826\n",
      "Epoch 151/600\n",
      "0s - loss: 0.1499 - acc: 0.8609 - val_loss: 0.1437 - val_acc: 0.8826\n",
      "Epoch 152/600\n",
      "0s - loss: 0.1488 - acc: 0.8623 - val_loss: 0.1427 - val_acc: 0.8870\n",
      "Epoch 153/600\n",
      "0s - loss: 0.1476 - acc: 0.8638 - val_loss: 0.1417 - val_acc: 0.8957\n",
      "Epoch 154/600\n",
      "0s - loss: 0.1464 - acc: 0.8652 - val_loss: 0.1402 - val_acc: 0.8913\n",
      "Epoch 155/600\n",
      "0s - loss: 0.1452 - acc: 0.8638 - val_loss: 0.1389 - val_acc: 0.8913\n",
      "Epoch 156/600\n",
      "0s - loss: 0.1440 - acc: 0.8638 - val_loss: 0.1379 - val_acc: 0.8957\n",
      "Epoch 157/600\n",
      "0s - loss: 0.1428 - acc: 0.8652 - val_loss: 0.1368 - val_acc: 0.9000\n",
      "Epoch 158/600\n",
      "0s - loss: 0.1416 - acc: 0.8667 - val_loss: 0.1357 - val_acc: 0.9000\n",
      "Epoch 159/600\n",
      "0s - loss: 0.1405 - acc: 0.8667 - val_loss: 0.1339 - val_acc: 0.8957\n",
      "Epoch 160/600\n",
      "0s - loss: 0.1394 - acc: 0.8638 - val_loss: 0.1337 - val_acc: 0.8957\n",
      "Epoch 161/600\n",
      "0s - loss: 0.1383 - acc: 0.8696 - val_loss: 0.1324 - val_acc: 0.9000\n",
      "Epoch 162/600\n",
      "0s - loss: 0.1373 - acc: 0.8667 - val_loss: 0.1307 - val_acc: 0.8957\n",
      "Epoch 163/600\n",
      "0s - loss: 0.1362 - acc: 0.8638 - val_loss: 0.1304 - val_acc: 0.8957\n",
      "Epoch 164/600\n",
      "0s - loss: 0.1351 - acc: 0.8725 - val_loss: 0.1290 - val_acc: 0.9000\n",
      "Epoch 165/600\n",
      "0s - loss: 0.1342 - acc: 0.8739 - val_loss: 0.1276 - val_acc: 0.8957\n",
      "Epoch 166/600\n",
      "0s - loss: 0.1332 - acc: 0.8710 - val_loss: 0.1270 - val_acc: 0.9000\n",
      "Epoch 167/600\n",
      "0s - loss: 0.1322 - acc: 0.8754 - val_loss: 0.1259 - val_acc: 0.9000\n",
      "Epoch 168/600\n",
      "0s - loss: 0.1312 - acc: 0.8739 - val_loss: 0.1247 - val_acc: 0.9000\n",
      "Epoch 169/600\n",
      "0s - loss: 0.1301 - acc: 0.8754 - val_loss: 0.1240 - val_acc: 0.8957\n",
      "Epoch 170/600\n",
      "0s - loss: 0.1291 - acc: 0.8754 - val_loss: 0.1233 - val_acc: 0.9000\n",
      "Epoch 171/600\n",
      "0s - loss: 0.1282 - acc: 0.8739 - val_loss: 0.1229 - val_acc: 0.8957\n",
      "Epoch 172/600\n",
      "0s - loss: 0.1272 - acc: 0.8768 - val_loss: 0.1210 - val_acc: 0.9000\n",
      "Epoch 173/600\n",
      "0s - loss: 0.1262 - acc: 0.8739 - val_loss: 0.1202 - val_acc: 0.9000\n",
      "Epoch 174/600\n",
      "0s - loss: 0.1253 - acc: 0.8739 - val_loss: 0.1188 - val_acc: 0.9000\n",
      "Epoch 175/600\n",
      "0s - loss: 0.1244 - acc: 0.8739 - val_loss: 0.1177 - val_acc: 0.9043\n",
      "Epoch 176/600\n",
      "0s - loss: 0.1235 - acc: 0.8768 - val_loss: 0.1168 - val_acc: 0.9043\n",
      "Epoch 177/600\n",
      "0s - loss: 0.1225 - acc: 0.8768 - val_loss: 0.1164 - val_acc: 0.9000\n",
      "Epoch 178/600\n",
      "0s - loss: 0.1216 - acc: 0.8739 - val_loss: 0.1154 - val_acc: 0.9000\n",
      "Epoch 179/600\n",
      "0s - loss: 0.1207 - acc: 0.8739 - val_loss: 0.1152 - val_acc: 0.9000\n",
      "Epoch 180/600\n",
      "0s - loss: 0.1199 - acc: 0.8768 - val_loss: 0.1135 - val_acc: 0.9000\n",
      "Epoch 181/600\n",
      "0s - loss: 0.1191 - acc: 0.8754 - val_loss: 0.1134 - val_acc: 0.9000\n",
      "Epoch 182/600\n",
      "0s - loss: 0.1182 - acc: 0.8768 - val_loss: 0.1119 - val_acc: 0.9000\n",
      "Epoch 183/600\n",
      "0s - loss: 0.1174 - acc: 0.8768 - val_loss: 0.1114 - val_acc: 0.9000\n",
      "Epoch 184/600\n",
      "0s - loss: 0.1167 - acc: 0.8797 - val_loss: 0.1112 - val_acc: 0.9000\n",
      "Epoch 185/600\n",
      "0s - loss: 0.1159 - acc: 0.8754 - val_loss: 0.1105 - val_acc: 0.9000\n",
      "Epoch 186/600\n",
      "0s - loss: 0.1151 - acc: 0.8768 - val_loss: 0.1094 - val_acc: 0.9000\n",
      "Epoch 187/600\n",
      "0s - loss: 0.1144 - acc: 0.8783 - val_loss: 0.1085 - val_acc: 0.9000\n",
      "Epoch 188/600\n",
      "0s - loss: 0.1136 - acc: 0.8783 - val_loss: 0.1076 - val_acc: 0.9000\n",
      "Epoch 189/600\n",
      "0s - loss: 0.1128 - acc: 0.8797 - val_loss: 0.1066 - val_acc: 0.9000\n",
      "Epoch 190/600\n",
      "0s - loss: 0.1121 - acc: 0.8797 - val_loss: 0.1061 - val_acc: 0.9000\n",
      "Epoch 191/600\n",
      "0s - loss: 0.1114 - acc: 0.8812 - val_loss: 0.1050 - val_acc: 0.9000\n",
      "Epoch 192/600\n",
      "0s - loss: 0.1108 - acc: 0.8797 - val_loss: 0.1040 - val_acc: 0.8957\n",
      "Epoch 193/600\n",
      "0s - loss: 0.1101 - acc: 0.8783 - val_loss: 0.1038 - val_acc: 0.9000\n",
      "Epoch 194/600\n",
      "0s - loss: 0.1093 - acc: 0.8826 - val_loss: 0.1031 - val_acc: 0.9000\n",
      "Epoch 195/600\n",
      "0s - loss: 0.1089 - acc: 0.8783 - val_loss: 0.1035 - val_acc: 0.9043\n",
      "Epoch 196/600\n",
      "0s - loss: 0.1080 - acc: 0.8812 - val_loss: 0.1024 - val_acc: 0.9043\n",
      "Epoch 197/600\n",
      "0s - loss: 0.1074 - acc: 0.8841 - val_loss: 0.1021 - val_acc: 0.9043\n",
      "Epoch 198/600\n",
      "0s - loss: 0.1070 - acc: 0.8797 - val_loss: 0.1022 - val_acc: 0.9000\n",
      "Epoch 199/600\n",
      "0s - loss: 0.1064 - acc: 0.8797 - val_loss: 0.1014 - val_acc: 0.9000\n",
      "Epoch 200/600\n",
      "0s - loss: 0.1058 - acc: 0.8797 - val_loss: 0.1002 - val_acc: 0.9043\n",
      "Epoch 201/600\n",
      "0s - loss: 0.1053 - acc: 0.8812 - val_loss: 0.0996 - val_acc: 0.9043\n",
      "Epoch 202/600\n",
      "0s - loss: 0.1048 - acc: 0.8797 - val_loss: 0.0992 - val_acc: 0.9000\n",
      "Epoch 203/600\n",
      "0s - loss: 0.1042 - acc: 0.8812 - val_loss: 0.0981 - val_acc: 0.9043\n",
      "Epoch 204/600\n",
      "0s - loss: 0.1037 - acc: 0.8797 - val_loss: 0.0973 - val_acc: 0.9087\n",
      "Epoch 205/600\n",
      "0s - loss: 0.1031 - acc: 0.8812 - val_loss: 0.0968 - val_acc: 0.9087\n",
      "Epoch 206/600\n",
      "0s - loss: 0.1026 - acc: 0.8797 - val_loss: 0.0971 - val_acc: 0.9000\n",
      "Epoch 207/600\n",
      "0s - loss: 0.1021 - acc: 0.8841 - val_loss: 0.0957 - val_acc: 0.9087\n",
      "Epoch 208/600\n",
      "0s - loss: 0.1016 - acc: 0.8768 - val_loss: 0.0953 - val_acc: 0.9043\n",
      "Epoch 209/600\n",
      "0s - loss: 0.1011 - acc: 0.8783 - val_loss: 0.0948 - val_acc: 0.9043\n",
      "Epoch 210/600\n",
      "0s - loss: 0.1009 - acc: 0.8797 - val_loss: 0.0954 - val_acc: 0.9000\n",
      "Epoch 211/600\n",
      "0s - loss: 0.1002 - acc: 0.8841 - val_loss: 0.0948 - val_acc: 0.9000\n",
      "Epoch 212/600\n",
      "0s - loss: 0.0998 - acc: 0.8841 - val_loss: 0.0945 - val_acc: 0.9000\n",
      "Epoch 213/600\n",
      "0s - loss: 0.0995 - acc: 0.8826 - val_loss: 0.0942 - val_acc: 0.9000\n",
      "Epoch 214/600\n",
      "0s - loss: 0.0990 - acc: 0.8841 - val_loss: 0.0932 - val_acc: 0.9000\n",
      "Epoch 215/600\n",
      "0s - loss: 0.0987 - acc: 0.8841 - val_loss: 0.0935 - val_acc: 0.9000\n",
      "Epoch 216/600\n",
      "0s - loss: 0.0983 - acc: 0.8826 - val_loss: 0.0929 - val_acc: 0.9000\n",
      "Epoch 217/600\n",
      "0s - loss: 0.0979 - acc: 0.8841 - val_loss: 0.0927 - val_acc: 0.9000\n",
      "Epoch 218/600\n",
      "0s - loss: 0.0975 - acc: 0.8826 - val_loss: 0.0916 - val_acc: 0.9000\n",
      "Epoch 219/600\n",
      "0s - loss: 0.0971 - acc: 0.8826 - val_loss: 0.0912 - val_acc: 0.9000\n",
      "Epoch 220/600\n",
      "0s - loss: 0.0968 - acc: 0.8841 - val_loss: 0.0903 - val_acc: 0.9000\n",
      "Epoch 221/600\n",
      "0s - loss: 0.0964 - acc: 0.8841 - val_loss: 0.0901 - val_acc: 0.9000\n",
      "Epoch 222/600\n",
      "0s - loss: 0.0961 - acc: 0.8841 - val_loss: 0.0893 - val_acc: 0.9000\n",
      "Epoch 223/600\n",
      "0s - loss: 0.0958 - acc: 0.8841 - val_loss: 0.0888 - val_acc: 0.9000\n",
      "Epoch 224/600\n",
      "0s - loss: 0.0955 - acc: 0.8841 - val_loss: 0.0883 - val_acc: 0.9043\n",
      "Epoch 225/600\n",
      "0s - loss: 0.0953 - acc: 0.8826 - val_loss: 0.0880 - val_acc: 0.9043\n",
      "Epoch 226/600\n",
      "0s - loss: 0.0949 - acc: 0.8841 - val_loss: 0.0885 - val_acc: 0.9000\n",
      "Epoch 227/600\n",
      "0s - loss: 0.0946 - acc: 0.8841 - val_loss: 0.0884 - val_acc: 0.9000\n",
      "Epoch 228/600\n",
      "0s - loss: 0.0943 - acc: 0.8855 - val_loss: 0.0885 - val_acc: 0.8913\n",
      "Epoch 229/600\n",
      "0s - loss: 0.0941 - acc: 0.8841 - val_loss: 0.0886 - val_acc: 0.8870\n",
      "Epoch 230/600\n",
      "0s - loss: 0.0940 - acc: 0.8826 - val_loss: 0.0887 - val_acc: 0.8870\n",
      "Epoch 231/600\n",
      "0s - loss: 0.0937 - acc: 0.8826 - val_loss: 0.0878 - val_acc: 0.8870\n",
      "Epoch 232/600\n",
      "0s - loss: 0.0934 - acc: 0.8841 - val_loss: 0.0866 - val_acc: 0.8957\n",
      "Epoch 233/600\n",
      "0s - loss: 0.0931 - acc: 0.8841 - val_loss: 0.0859 - val_acc: 0.9043\n",
      "Epoch 234/600\n",
      "0s - loss: 0.0929 - acc: 0.8841 - val_loss: 0.0855 - val_acc: 0.9043\n",
      "Epoch 235/600\n",
      "0s - loss: 0.0927 - acc: 0.8841 - val_loss: 0.0862 - val_acc: 0.8870\n",
      "Epoch 236/600\n",
      "0s - loss: 0.0925 - acc: 0.8855 - val_loss: 0.0862 - val_acc: 0.8870\n",
      "Epoch 237/600\n",
      "0s - loss: 0.0923 - acc: 0.8841 - val_loss: 0.0863 - val_acc: 0.8870\n",
      "Epoch 238/600\n",
      "0s - loss: 0.0923 - acc: 0.8826 - val_loss: 0.0867 - val_acc: 0.8870\n",
      "Epoch 239/600\n",
      "0s - loss: 0.0920 - acc: 0.8855 - val_loss: 0.0861 - val_acc: 0.8870\n",
      "Epoch 240/600\n",
      "0s - loss: 0.0918 - acc: 0.8855 - val_loss: 0.0853 - val_acc: 0.8913\n",
      "Epoch 241/600\n",
      "0s - loss: 0.0916 - acc: 0.8841 - val_loss: 0.0849 - val_acc: 0.8913\n",
      "Epoch 242/600\n",
      "0s - loss: 0.0916 - acc: 0.8841 - val_loss: 0.0857 - val_acc: 0.8870\n",
      "Epoch 243/600\n",
      "0s - loss: 0.0913 - acc: 0.8855 - val_loss: 0.0851 - val_acc: 0.8870\n",
      "Epoch 244/600\n",
      "0s - loss: 0.0912 - acc: 0.8841 - val_loss: 0.0841 - val_acc: 0.8913\n",
      "Epoch 245/600\n",
      "0s - loss: 0.0911 - acc: 0.8855 - val_loss: 0.0844 - val_acc: 0.8913\n",
      "Epoch 246/600\n",
      "0s - loss: 0.0910 - acc: 0.8841 - val_loss: 0.0849 - val_acc: 0.8870\n",
      "Epoch 247/600\n",
      "0s - loss: 0.0912 - acc: 0.8855 - val_loss: 0.0836 - val_acc: 0.8913\n",
      "Epoch 248/600\n",
      "0s - loss: 0.0907 - acc: 0.8855 - val_loss: 0.0839 - val_acc: 0.8913\n",
      "Epoch 249/600\n",
      "0s - loss: 0.0906 - acc: 0.8841 - val_loss: 0.0837 - val_acc: 0.8913\n",
      "Epoch 250/600\n",
      "0s - loss: 0.0905 - acc: 0.8841 - val_loss: 0.0836 - val_acc: 0.8913\n",
      "Epoch 251/600\n",
      "0s - loss: 0.0905 - acc: 0.8841 - val_loss: 0.0839 - val_acc: 0.8913\n",
      "Epoch 252/600\n",
      "0s - loss: 0.0904 - acc: 0.8855 - val_loss: 0.0833 - val_acc: 0.8913\n",
      "Epoch 253/600\n",
      "0s - loss: 0.0903 - acc: 0.8841 - val_loss: 0.0833 - val_acc: 0.8913\n",
      "Epoch 254/600\n",
      "0s - loss: 0.0901 - acc: 0.8855 - val_loss: 0.0829 - val_acc: 0.8913\n",
      "Epoch 255/600\n",
      "0s - loss: 0.0901 - acc: 0.8841 - val_loss: 0.0828 - val_acc: 0.8913\n",
      "Epoch 256/600\n",
      "0s - loss: 0.0900 - acc: 0.8855 - val_loss: 0.0826 - val_acc: 0.8913\n",
      "Epoch 257/600\n",
      "0s - loss: 0.0900 - acc: 0.8855 - val_loss: 0.0835 - val_acc: 0.8957\n",
      "Epoch 258/600\n",
      "0s - loss: 0.0898 - acc: 0.8855 - val_loss: 0.0829 - val_acc: 0.8913\n",
      "Epoch 259/600\n",
      "0s - loss: 0.0898 - acc: 0.8855 - val_loss: 0.0821 - val_acc: 0.8913\n",
      "Epoch 260/600\n",
      "0s - loss: 0.0897 - acc: 0.8870 - val_loss: 0.0817 - val_acc: 0.8913\n",
      "Epoch 261/600\n",
      "0s - loss: 0.0897 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8913\n",
      "Epoch 262/600\n",
      "0s - loss: 0.0896 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8913\n",
      "Epoch 263/600\n",
      "0s - loss: 0.0895 - acc: 0.8870 - val_loss: 0.0814 - val_acc: 0.8913\n",
      "Epoch 264/600\n",
      "0s - loss: 0.0894 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8913\n",
      "Epoch 265/600\n",
      "0s - loss: 0.0893 - acc: 0.8870 - val_loss: 0.0813 - val_acc: 0.8913\n",
      "Epoch 266/600\n",
      "0s - loss: 0.0893 - acc: 0.8870 - val_loss: 0.0819 - val_acc: 0.8913\n",
      "Epoch 267/600\n",
      "0s - loss: 0.0892 - acc: 0.8870 - val_loss: 0.0813 - val_acc: 0.8913\n",
      "Epoch 268/600\n",
      "0s - loss: 0.0891 - acc: 0.8870 - val_loss: 0.0817 - val_acc: 0.8913\n",
      "Epoch 269/600\n",
      "0s - loss: 0.0891 - acc: 0.8870 - val_loss: 0.0814 - val_acc: 0.8913\n",
      "Epoch 270/600\n",
      "0s - loss: 0.0890 - acc: 0.8870 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 271/600\n",
      "0s - loss: 0.0894 - acc: 0.8826 - val_loss: 0.0828 - val_acc: 0.8957\n",
      "Epoch 272/600\n",
      "0s - loss: 0.0890 - acc: 0.8841 - val_loss: 0.0826 - val_acc: 0.8957\n",
      "Epoch 273/600\n",
      "0s - loss: 0.0889 - acc: 0.8841 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 274/600\n",
      "0s - loss: 0.0889 - acc: 0.8855 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 275/600\n",
      "0s - loss: 0.0888 - acc: 0.8870 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 276/600\n",
      "0s - loss: 0.0888 - acc: 0.8870 - val_loss: 0.0812 - val_acc: 0.8913\n",
      "Epoch 277/600\n",
      "0s - loss: 0.0887 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8913\n",
      "Epoch 278/600\n",
      "0s - loss: 0.0888 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 279/600\n",
      "0s - loss: 0.0887 - acc: 0.8884 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 280/600\n",
      "0s - loss: 0.0887 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 281/600\n",
      "0s - loss: 0.0886 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 282/600\n",
      "0s - loss: 0.0886 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 283/600\n",
      "0s - loss: 0.0886 - acc: 0.8855 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 284/600\n",
      "0s - loss: 0.0886 - acc: 0.8855 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 285/600\n",
      "0s - loss: 0.0885 - acc: 0.8855 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 286/600\n",
      "0s - loss: 0.0884 - acc: 0.8855 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 287/600\n",
      "0s - loss: 0.0884 - acc: 0.8870 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 288/600\n",
      "0s - loss: 0.0885 - acc: 0.8855 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 289/600\n",
      "0s - loss: 0.0883 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8957\n",
      "Epoch 290/600\n",
      "0s - loss: 0.0883 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 291/600\n",
      "0s - loss: 0.0883 - acc: 0.8855 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 292/600\n",
      "0s - loss: 0.0883 - acc: 0.8855 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 293/600\n",
      "0s - loss: 0.0883 - acc: 0.8855 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 294/600\n",
      "0s - loss: 0.0883 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 295/600\n",
      "0s - loss: 0.0882 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 296/600\n",
      "0s - loss: 0.0882 - acc: 0.8884 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 297/600\n",
      "0s - loss: 0.0882 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 298/600\n",
      "0s - loss: 0.0881 - acc: 0.8899 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 299/600\n",
      "0s - loss: 0.0881 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 300/600\n",
      "0s - loss: 0.0881 - acc: 0.8884 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 301/600\n",
      "0s - loss: 0.0881 - acc: 0.8899 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 302/600\n",
      "0s - loss: 0.0880 - acc: 0.8855 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 303/600\n",
      "0s - loss: 0.0880 - acc: 0.8884 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 304/600\n",
      "0s - loss: 0.0882 - acc: 0.8870 - val_loss: 0.0794 - val_acc: 0.8913\n",
      "Epoch 305/600\n",
      "0s - loss: 0.0881 - acc: 0.8884 - val_loss: 0.0793 - val_acc: 0.8913\n",
      "Epoch 306/600\n",
      "0s - loss: 0.0882 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 307/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 308/600\n",
      "0s - loss: 0.0880 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 309/600\n",
      "0s - loss: 0.0879 - acc: 0.8855 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 310/600\n",
      "0s - loss: 0.0879 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 311/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 312/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 313/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 314/600\n",
      "0s - loss: 0.0879 - acc: 0.8855 - val_loss: 0.0812 - val_acc: 0.8913\n",
      "Epoch 315/600\n",
      "0s - loss: 0.0879 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8913\n",
      "Epoch 316/600\n",
      "0s - loss: 0.0879 - acc: 0.8855 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 317/600\n",
      "0s - loss: 0.0878 - acc: 0.8884 - val_loss: 0.0808 - val_acc: 0.8957\n",
      "Epoch 318/600\n",
      "0s - loss: 0.0878 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8913\n",
      "Epoch 319/600\n",
      "0s - loss: 0.0878 - acc: 0.8855 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 320/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0816 - val_acc: 0.8913\n",
      "Epoch 321/600\n",
      "0s - loss: 0.0878 - acc: 0.8855 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 322/600\n",
      "0s - loss: 0.0879 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8913\n",
      "Epoch 323/600\n",
      "0s - loss: 0.0878 - acc: 0.8855 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 324/600\n",
      "0s - loss: 0.0877 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 325/600\n",
      "0s - loss: 0.0878 - acc: 0.8899 - val_loss: 0.0795 - val_acc: 0.8913\n",
      "Epoch 326/600\n",
      "0s - loss: 0.0877 - acc: 0.8884 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 327/600\n",
      "0s - loss: 0.0877 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 328/600\n",
      "0s - loss: 0.0877 - acc: 0.8884 - val_loss: 0.0794 - val_acc: 0.8913\n",
      "Epoch 329/600\n",
      "0s - loss: 0.0877 - acc: 0.8884 - val_loss: 0.0792 - val_acc: 0.8913\n",
      "Epoch 330/600\n",
      "0s - loss: 0.0878 - acc: 0.8884 - val_loss: 0.0790 - val_acc: 0.8913\n",
      "Epoch 331/600\n",
      "0s - loss: 0.0877 - acc: 0.8855 - val_loss: 0.0795 - val_acc: 0.8913\n",
      "Epoch 332/600\n",
      "0s - loss: 0.0876 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 333/600\n",
      "0s - loss: 0.0876 - acc: 0.8899 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 334/600\n",
      "0s - loss: 0.0877 - acc: 0.8884 - val_loss: 0.0792 - val_acc: 0.8913\n",
      "Epoch 335/600\n",
      "0s - loss: 0.0876 - acc: 0.8884 - val_loss: 0.0794 - val_acc: 0.8913\n",
      "Epoch 336/600\n",
      "0s - loss: 0.0876 - acc: 0.8884 - val_loss: 0.0795 - val_acc: 0.8913\n",
      "Epoch 337/600\n",
      "0s - loss: 0.0876 - acc: 0.8899 - val_loss: 0.0792 - val_acc: 0.8913\n",
      "Epoch 338/600\n",
      "0s - loss: 0.0876 - acc: 0.8884 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 339/600\n",
      "0s - loss: 0.0876 - acc: 0.8899 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 340/600\n",
      "0s - loss: 0.0876 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 341/600\n",
      "0s - loss: 0.0875 - acc: 0.8884 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 342/600\n",
      "0s - loss: 0.0875 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 343/600\n",
      "0s - loss: 0.0875 - acc: 0.8884 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 344/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 345/600\n",
      "0s - loss: 0.0875 - acc: 0.8899 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 346/600\n",
      "0s - loss: 0.0875 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8913\n",
      "Epoch 347/600\n",
      "0s - loss: 0.0875 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 348/600\n",
      "0s - loss: 0.0875 - acc: 0.8870 - val_loss: 0.0803 - val_acc: 0.8870\n",
      "Epoch 349/600\n",
      "0s - loss: 0.0875 - acc: 0.8899 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 350/600\n",
      "0s - loss: 0.0874 - acc: 0.8870 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 351/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 352/600\n",
      "0s - loss: 0.0874 - acc: 0.8870 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 353/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 354/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0795 - val_acc: 0.8913\n",
      "Epoch 355/600\n",
      "0s - loss: 0.0874 - acc: 0.8884 - val_loss: 0.0795 - val_acc: 0.8913\n",
      "Epoch 356/600\n",
      "0s - loss: 0.0874 - acc: 0.8884 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 357/600\n",
      "0s - loss: 0.0874 - acc: 0.8884 - val_loss: 0.0792 - val_acc: 0.8957\n",
      "Epoch 358/600\n",
      "0s - loss: 0.0875 - acc: 0.8899 - val_loss: 0.0789 - val_acc: 0.8957\n",
      "Epoch 359/600\n",
      "0s - loss: 0.0874 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 360/600\n",
      "0s - loss: 0.0874 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 361/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 362/600\n",
      "0s - loss: 0.0873 - acc: 0.8870 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 363/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 364/600\n",
      "0s - loss: 0.0873 - acc: 0.8899 - val_loss: 0.0797 - val_acc: 0.8913\n",
      "Epoch 365/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0802 - val_acc: 0.8870\n",
      "Epoch 366/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0803 - val_acc: 0.8870\n",
      "Epoch 367/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 368/600\n",
      "0s - loss: 0.0873 - acc: 0.8899 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 369/600\n",
      "0s - loss: 0.0873 - acc: 0.8870 - val_loss: 0.0803 - val_acc: 0.8870\n",
      "Epoch 370/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 371/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 372/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0808 - val_acc: 0.8913\n",
      "Epoch 373/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 374/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 375/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0818 - val_acc: 0.8913\n",
      "Epoch 376/600\n",
      "0s - loss: 0.0873 - acc: 0.8870 - val_loss: 0.0810 - val_acc: 0.8913\n",
      "Epoch 377/600\n",
      "0s - loss: 0.0872 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 378/600\n",
      "0s - loss: 0.0874 - acc: 0.8899 - val_loss: 0.0797 - val_acc: 0.8957\n",
      "Epoch 379/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 380/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 381/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 382/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 383/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 384/600\n",
      "0s - loss: 0.0873 - acc: 0.8899 - val_loss: 0.0814 - val_acc: 0.8913\n",
      "Epoch 385/600\n",
      "0s - loss: 0.0872 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8913\n",
      "Epoch 386/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8957\n",
      "Epoch 387/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0793 - val_acc: 0.8957\n",
      "Epoch 388/600\n",
      "0s - loss: 0.0872 - acc: 0.8870 - val_loss: 0.0800 - val_acc: 0.8957\n",
      "Epoch 389/600\n",
      "0s - loss: 0.0872 - acc: 0.8899 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 390/600\n",
      "0s - loss: 0.0871 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 391/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 392/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 393/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0797 - val_acc: 0.8957\n",
      "Epoch 394/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 395/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0795 - val_acc: 0.8957\n",
      "Epoch 396/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 397/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 398/600\n",
      "0s - loss: 0.0872 - acc: 0.8884 - val_loss: 0.0795 - val_acc: 0.8957\n",
      "Epoch 399/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 400/600\n",
      "0s - loss: 0.0871 - acc: 0.8884 - val_loss: 0.0794 - val_acc: 0.8957\n",
      "Epoch 401/600\n",
      "0s - loss: 0.0872 - acc: 0.8870 - val_loss: 0.0793 - val_acc: 0.8957\n",
      "Epoch 402/600\n",
      "0s - loss: 0.0873 - acc: 0.8884 - val_loss: 0.0789 - val_acc: 0.8957\n",
      "Epoch 403/600\n",
      "0s - loss: 0.0872 - acc: 0.8870 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 404/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0793 - val_acc: 0.8957\n",
      "Epoch 405/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 406/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 407/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0797 - val_acc: 0.8957\n",
      "Epoch 408/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0799 - val_acc: 0.8957\n",
      "Epoch 409/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8957\n",
      "Epoch 410/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 411/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 412/600\n",
      "0s - loss: 0.0871 - acc: 0.8884 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 413/600\n",
      "0s - loss: 0.0871 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 414/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 415/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 416/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 417/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 418/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 419/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 420/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 421/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0797 - val_acc: 0.8913\n",
      "Epoch 422/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0797 - val_acc: 0.8957\n",
      "Epoch 423/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 424/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0796 - val_acc: 0.8957\n",
      "Epoch 425/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 426/600\n",
      "0s - loss: 0.0871 - acc: 0.8899 - val_loss: 0.0815 - val_acc: 0.8957\n",
      "Epoch 427/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 428/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 429/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 430/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0796 - val_acc: 0.8913\n",
      "Epoch 431/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 432/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 433/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 434/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 435/600\n",
      "0s - loss: 0.0870 - acc: 0.8899 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 436/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 437/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 438/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 439/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 440/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 441/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 442/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 443/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 444/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 445/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 446/600\n",
      "0s - loss: 0.0870 - acc: 0.8884 - val_loss: 0.0795 - val_acc: 0.8957\n",
      "Epoch 447/600\n",
      "0s - loss: 0.0870 - acc: 0.8870 - val_loss: 0.0795 - val_acc: 0.8957\n",
      "Epoch 448/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 449/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 450/600\n",
      "0s - loss: 0.0868 - acc: 0.8899 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 451/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 452/600\n",
      "0s - loss: 0.0868 - acc: 0.8899 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 453/600\n",
      "0s - loss: 0.0871 - acc: 0.8884 - val_loss: 0.0797 - val_acc: 0.8957\n",
      "Epoch 454/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0794 - val_acc: 0.8957\n",
      "Epoch 455/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 456/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 457/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 458/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 459/600\n",
      "0s - loss: 0.0869 - acc: 0.8870 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 460/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 461/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 462/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 463/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 464/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 465/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 466/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 467/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 468/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 469/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 470/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0815 - val_acc: 0.8957\n",
      "Epoch 471/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 472/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 473/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 474/600\n",
      "0s - loss: 0.0869 - acc: 0.8899 - val_loss: 0.0822 - val_acc: 0.8957\n",
      "Epoch 475/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 476/600\n",
      "0s - loss: 0.0868 - acc: 0.8913 - val_loss: 0.0816 - val_acc: 0.8957\n",
      "Epoch 477/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8957\n",
      "Epoch 478/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 479/600\n",
      "0s - loss: 0.0869 - acc: 0.8884 - val_loss: 0.0797 - val_acc: 0.8913\n",
      "Epoch 480/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 481/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 482/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 483/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 484/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 485/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 486/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 487/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0822 - val_acc: 0.8957\n",
      "Epoch 488/600\n",
      "0s - loss: 0.0868 - acc: 0.8899 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 489/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8957\n",
      "Epoch 490/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 491/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 492/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 493/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 494/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8913\n",
      "Epoch 495/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 496/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 497/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0801 - val_acc: 0.8913\n",
      "Epoch 498/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 499/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 500/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0816 - val_acc: 0.8957\n",
      "Epoch 501/600\n",
      "0s - loss: 0.0867 - acc: 0.8899 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 502/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 503/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 504/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 505/600\n",
      "0s - loss: 0.0868 - acc: 0.8870 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 506/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 507/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 508/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 509/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0797 - val_acc: 0.8913\n",
      "Epoch 510/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 511/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0798 - val_acc: 0.8913\n",
      "Epoch 512/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 513/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 514/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 515/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 516/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 517/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 518/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 519/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 520/600\n",
      "0s - loss: 0.0868 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8913\n",
      "Epoch 521/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 522/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 523/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 524/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 525/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 526/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0819 - val_acc: 0.8957\n",
      "Epoch 527/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 528/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 529/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 530/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 531/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 532/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 533/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 534/600\n",
      "0s - loss: 0.0867 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 535/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0816 - val_acc: 0.8957\n",
      "Epoch 536/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 537/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0805 - val_acc: 0.8913\n",
      "Epoch 538/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 539/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 540/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 541/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 542/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 543/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 544/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 545/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 546/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 547/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0806 - val_acc: 0.8957\n",
      "Epoch 548/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 549/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 550/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 551/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0803 - val_acc: 0.8913\n",
      "Epoch 552/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0799 - val_acc: 0.8957\n",
      "Epoch 553/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0808 - val_acc: 0.8957\n",
      "Epoch 554/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8957\n",
      "Epoch 555/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0803 - val_acc: 0.8957\n",
      "Epoch 556/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0799 - val_acc: 0.8957\n",
      "Epoch 557/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 558/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 559/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 560/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0810 - val_acc: 0.8957\n",
      "Epoch 561/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0805 - val_acc: 0.8957\n",
      "Epoch 562/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0802 - val_acc: 0.8913\n",
      "Epoch 563/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0798 - val_acc: 0.8957\n",
      "Epoch 564/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0804 - val_acc: 0.8957\n",
      "Epoch 565/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 566/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0807 - val_acc: 0.8957\n",
      "Epoch 567/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 568/600\n",
      "0s - loss: 0.0867 - acc: 0.8870 - val_loss: 0.0822 - val_acc: 0.8957\n",
      "Epoch 569/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0818 - val_acc: 0.8957\n",
      "Epoch 570/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0823 - val_acc: 0.8957\n",
      "Epoch 571/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 572/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 573/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0819 - val_acc: 0.8957\n",
      "Epoch 574/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 575/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0826 - val_acc: 0.8957\n",
      "Epoch 576/600\n",
      "0s - loss: 0.0866 - acc: 0.8899 - val_loss: 0.0830 - val_acc: 0.8957\n",
      "Epoch 577/600\n",
      "0s - loss: 0.0866 - acc: 0.8899 - val_loss: 0.0825 - val_acc: 0.8957\n",
      "Epoch 578/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0823 - val_acc: 0.8957\n",
      "Epoch 579/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0814 - val_acc: 0.8957\n",
      "Epoch 580/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0815 - val_acc: 0.8957\n",
      "Epoch 581/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0806 - val_acc: 0.8913\n",
      "Epoch 582/600\n",
      "0s - loss: 0.0866 - acc: 0.8884 - val_loss: 0.0800 - val_acc: 0.8913\n",
      "Epoch 583/600\n",
      "0s - loss: 0.0865 - acc: 0.8870 - val_loss: 0.0808 - val_acc: 0.8913\n",
      "Epoch 584/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 585/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 586/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0817 - val_acc: 0.8957\n",
      "Epoch 587/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0807 - val_acc: 0.8913\n",
      "Epoch 588/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 589/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 590/600\n",
      "0s - loss: 0.0866 - acc: 0.8870 - val_loss: 0.0804 - val_acc: 0.8913\n",
      "Epoch 591/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 592/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0813 - val_acc: 0.8957\n",
      "Epoch 593/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 594/600\n",
      "0s - loss: 0.0865 - acc: 0.8899 - val_loss: 0.0809 - val_acc: 0.8913\n",
      "Epoch 595/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0811 - val_acc: 0.8957\n",
      "Epoch 596/600\n",
      "0s - loss: 0.0863 - acc: 0.8884 - val_loss: 0.0812 - val_acc: 0.8957\n",
      "Epoch 597/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0820 - val_acc: 0.8957\n",
      "Epoch 598/600\n",
      "0s - loss: 0.0864 - acc: 0.8870 - val_loss: 0.0821 - val_acc: 0.8957\n",
      "Epoch 599/600\n",
      "0s - loss: 0.0865 - acc: 0.8884 - val_loss: 0.0809 - val_acc: 0.8957\n",
      "Epoch 600/600\n",
      "0s - loss: 0.0864 - acc: 0.8884 - val_loss: 0.0815 - val_acc: 0.8957\n",
      "Train Score:  91.3664408201\n",
      "Test Score:  91.8467316938\n"
     ]
    }
   ],
   "source": [
    "m2=make_model('sigmoid','rmsprop',tx_train.shape[1],[tx_train.shape[1]*10,16],tx_train,ty_train,tx_test,ty_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected 1 predicted: 0.450232   0\n",
      "expected 1 predicted: 0.309441   0\n",
      "expected 0 predicted: 0.644813   1\n",
      "expected 0 predicted: 0.892456   1\n",
      "expected 0 predicted: 0.967451   1\n",
      "expected 1 predicted: 0.128892   0\n",
      "expected 1 predicted: 0.367067   0\n",
      "expected 1 predicted: 0.440748   0\n",
      "expected 0 predicted: 0.409086   1\n",
      "expected 1 predicted: 0.0799265   0\n",
      "expected 1 predicted: 0.261614   0\n",
      "expected 0 predicted: 0.758133   0\n",
      "expected 0 predicted: 0.705016   1\n",
      "expected 1 predicted: 0.450232   0\n",
      "expected 1 predicted: 0.122519   0\n",
      "expected 1 predicted: 0.137053   0\n",
      "expected 0 predicted: 0.935495   1\n",
      "expected 1 predicted: 0.323703   0\n",
      "expected 0 predicted: 0.605108   1\n",
      "expected 1 predicted: 0.243381   0\n",
      "expected 0 predicted: 0.865637   1\n",
      "expected 0 predicted: 0.941152   1\n",
      "expected 0 predicted: 0.652864   1\n",
      "expected 1 predicted: 0.0661002   0\n",
      "error 10\n"
     ]
    }
   ],
   "source": [
    "pr=m2.predict(tx_test)\n",
    "u=0\n",
    "k=0\n",
    "k=0\n",
    "for u in range(len(tx_test)):\n",
    "    if round(pr[u][0],1)>=0.2 and round(pr[u][0],1)<=0.75:\n",
    "        g=tsvmpred[u]\n",
    "    else:\n",
    "        g=round(pr[u][0],0)\n",
    "    if g!=ty_test[u]:    \n",
    "        print \"expected\",ty_test[u],\"predicted:\",pr[u][0],\" \",tsvmpred[u]\n",
    "        k=k+1\n",
    "print \"error\",k*100/len(ty_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(22, activation=\"relu\", kernel_initializer=\"uniform\", input_dim=22)`\n",
      "  app.launch_new_instance()\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/siddharth/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 690 samples, validate on 230 samples\n",
      "Epoch 1/600\n",
      "0s - loss: 0.5423 - acc: 0.4565 - val_loss: 0.5724 - val_acc: 0.4174\n",
      "Epoch 2/600\n",
      "0s - loss: 0.5328 - acc: 0.4565 - val_loss: 0.5631 - val_acc: 0.4174\n",
      "Epoch 3/600\n",
      "0s - loss: 0.5241 - acc: 0.4565 - val_loss: 0.5534 - val_acc: 0.4174\n",
      "Epoch 4/600\n",
      "0s - loss: 0.5150 - acc: 0.4565 - val_loss: 0.5425 - val_acc: 0.4174\n",
      "Epoch 5/600\n",
      "0s - loss: 0.5046 - acc: 0.4565 - val_loss: 0.5297 - val_acc: 0.4174\n",
      "Epoch 6/600\n",
      "0s - loss: 0.4925 - acc: 0.4565 - val_loss: 0.5152 - val_acc: 0.4174\n",
      "Epoch 7/600\n",
      "0s - loss: 0.4786 - acc: 0.4565 - val_loss: 0.4985 - val_acc: 0.4174\n",
      "Epoch 8/600\n",
      "0s - loss: 0.4629 - acc: 0.4565 - val_loss: 0.4804 - val_acc: 0.4174\n",
      "Epoch 9/600\n",
      "0s - loss: 0.4457 - acc: 0.4565 - val_loss: 0.4602 - val_acc: 0.4174\n",
      "Epoch 10/600\n",
      "0s - loss: 0.4267 - acc: 0.4565 - val_loss: 0.4385 - val_acc: 0.4174\n",
      "Epoch 11/600\n",
      "0s - loss: 0.4063 - acc: 0.4565 - val_loss: 0.4154 - val_acc: 0.4174\n",
      "Epoch 12/600\n",
      "0s - loss: 0.3850 - acc: 0.4565 - val_loss: 0.3926 - val_acc: 0.4174\n",
      "Epoch 13/600\n",
      "0s - loss: 0.3635 - acc: 0.4565 - val_loss: 0.3681 - val_acc: 0.4174\n",
      "Epoch 14/600\n",
      "0s - loss: 0.3408 - acc: 0.4565 - val_loss: 0.3437 - val_acc: 0.4174\n",
      "Epoch 15/600\n",
      "0s - loss: 0.3185 - acc: 0.4565 - val_loss: 0.3202 - val_acc: 0.4174\n",
      "Epoch 16/600\n",
      "0s - loss: 0.2967 - acc: 0.4565 - val_loss: 0.2963 - val_acc: 0.4174\n",
      "Epoch 17/600\n",
      "0s - loss: 0.2754 - acc: 0.4565 - val_loss: 0.2749 - val_acc: 0.4261\n",
      "Epoch 18/600\n",
      "0s - loss: 0.2560 - acc: 0.4739 - val_loss: 0.2547 - val_acc: 0.4913\n",
      "Epoch 19/600\n",
      "0s - loss: 0.2373 - acc: 0.5087 - val_loss: 0.2341 - val_acc: 0.5435\n",
      "Epoch 20/600\n",
      "0s - loss: 0.2195 - acc: 0.5899 - val_loss: 0.2175 - val_acc: 0.6304\n",
      "Epoch 21/600\n",
      "0s - loss: 0.2046 - acc: 0.6420 - val_loss: 0.2021 - val_acc: 0.6565\n",
      "Epoch 22/600\n",
      "0s - loss: 0.1910 - acc: 0.7000 - val_loss: 0.1879 - val_acc: 0.7130\n",
      "Epoch 23/600\n",
      "0s - loss: 0.1785 - acc: 0.7551 - val_loss: 0.1753 - val_acc: 0.7696\n",
      "Epoch 24/600\n",
      "0s - loss: 0.1677 - acc: 0.7942 - val_loss: 0.1642 - val_acc: 0.7913\n",
      "Epoch 25/600\n",
      "0s - loss: 0.1586 - acc: 0.8029 - val_loss: 0.1563 - val_acc: 0.8087\n",
      "Epoch 26/600\n",
      "0s - loss: 0.1517 - acc: 0.8174 - val_loss: 0.1490 - val_acc: 0.8174\n",
      "Epoch 27/600\n",
      "0s - loss: 0.1456 - acc: 0.8217 - val_loss: 0.1432 - val_acc: 0.8217\n",
      "Epoch 28/600\n",
      "0s - loss: 0.1408 - acc: 0.8275 - val_loss: 0.1381 - val_acc: 0.8261\n",
      "Epoch 29/600\n",
      "0s - loss: 0.1368 - acc: 0.8261 - val_loss: 0.1349 - val_acc: 0.8304\n",
      "Epoch 30/600\n",
      "0s - loss: 0.1338 - acc: 0.8348 - val_loss: 0.1320 - val_acc: 0.8304\n",
      "Epoch 31/600\n",
      "0s - loss: 0.1312 - acc: 0.8377 - val_loss: 0.1304 - val_acc: 0.8304\n",
      "Epoch 32/600\n",
      "0s - loss: 0.1292 - acc: 0.8362 - val_loss: 0.1280 - val_acc: 0.8304\n",
      "Epoch 33/600\n",
      "0s - loss: 0.1271 - acc: 0.8406 - val_loss: 0.1263 - val_acc: 0.8304\n",
      "Epoch 34/600\n",
      "0s - loss: 0.1252 - acc: 0.8391 - val_loss: 0.1238 - val_acc: 0.8391\n",
      "Epoch 35/600\n",
      "0s - loss: 0.1233 - acc: 0.8406 - val_loss: 0.1226 - val_acc: 0.8391\n",
      "Epoch 36/600\n",
      "0s - loss: 0.1216 - acc: 0.8406 - val_loss: 0.1209 - val_acc: 0.8391\n",
      "Epoch 37/600\n",
      "0s - loss: 0.1199 - acc: 0.8464 - val_loss: 0.1194 - val_acc: 0.8391\n",
      "Epoch 38/600\n",
      "0s - loss: 0.1180 - acc: 0.8449 - val_loss: 0.1183 - val_acc: 0.8478\n",
      "Epoch 39/600\n",
      "0s - loss: 0.1165 - acc: 0.8478 - val_loss: 0.1167 - val_acc: 0.8435\n",
      "Epoch 40/600\n",
      "0s - loss: 0.1150 - acc: 0.8478 - val_loss: 0.1155 - val_acc: 0.8478\n",
      "Epoch 41/600\n",
      "0s - loss: 0.1135 - acc: 0.8493 - val_loss: 0.1141 - val_acc: 0.8391\n",
      "Epoch 42/600\n",
      "0s - loss: 0.1122 - acc: 0.8536 - val_loss: 0.1131 - val_acc: 0.8522\n",
      "Epoch 43/600\n",
      "0s - loss: 0.1103 - acc: 0.8565 - val_loss: 0.1123 - val_acc: 0.8478\n",
      "Epoch 44/600\n",
      "0s - loss: 0.1088 - acc: 0.8667 - val_loss: 0.1112 - val_acc: 0.8565\n",
      "Epoch 45/600\n",
      "0s - loss: 0.1074 - acc: 0.8696 - val_loss: 0.1098 - val_acc: 0.8522\n",
      "Epoch 46/600\n",
      "0s - loss: 0.1063 - acc: 0.8681 - val_loss: 0.1102 - val_acc: 0.8609\n",
      "Epoch 47/600\n",
      "0s - loss: 0.1049 - acc: 0.8797 - val_loss: 0.1069 - val_acc: 0.8565\n",
      "Epoch 48/600\n",
      "0s - loss: 0.1031 - acc: 0.8768 - val_loss: 0.1062 - val_acc: 0.8609\n",
      "Epoch 49/600\n",
      "0s - loss: 0.1017 - acc: 0.8783 - val_loss: 0.1049 - val_acc: 0.8652\n",
      "Epoch 50/600\n",
      "0s - loss: 0.1006 - acc: 0.8826 - val_loss: 0.1038 - val_acc: 0.8652\n",
      "Epoch 51/600\n",
      "0s - loss: 0.0992 - acc: 0.8855 - val_loss: 0.1046 - val_acc: 0.8783\n",
      "Epoch 52/600\n",
      "0s - loss: 0.0985 - acc: 0.8826 - val_loss: 0.1026 - val_acc: 0.8696\n",
      "Epoch 53/600\n",
      "0s - loss: 0.0967 - acc: 0.8870 - val_loss: 0.1009 - val_acc: 0.8696\n",
      "Epoch 54/600\n",
      "0s - loss: 0.0955 - acc: 0.8884 - val_loss: 0.1005 - val_acc: 0.8783\n",
      "Epoch 55/600\n",
      "0s - loss: 0.0943 - acc: 0.8928 - val_loss: 0.0989 - val_acc: 0.8696\n",
      "Epoch 56/600\n",
      "0s - loss: 0.0931 - acc: 0.8884 - val_loss: 0.0991 - val_acc: 0.8739\n",
      "Epoch 57/600\n",
      "0s - loss: 0.0925 - acc: 0.8942 - val_loss: 0.0982 - val_acc: 0.8783\n",
      "Epoch 58/600\n",
      "0s - loss: 0.0919 - acc: 0.8957 - val_loss: 0.0985 - val_acc: 0.8739\n",
      "Epoch 59/600\n",
      "0s - loss: 0.0907 - acc: 0.8928 - val_loss: 0.0960 - val_acc: 0.8783\n",
      "Epoch 60/600\n",
      "0s - loss: 0.0893 - acc: 0.8971 - val_loss: 0.0954 - val_acc: 0.8739\n",
      "Epoch 61/600\n",
      "0s - loss: 0.0884 - acc: 0.8942 - val_loss: 0.0946 - val_acc: 0.8739\n",
      "Epoch 62/600\n",
      "0s - loss: 0.0879 - acc: 0.8971 - val_loss: 0.0941 - val_acc: 0.8826\n",
      "Epoch 63/600\n",
      "0s - loss: 0.0870 - acc: 0.8942 - val_loss: 0.0940 - val_acc: 0.8739\n",
      "Epoch 64/600\n",
      "0s - loss: 0.0864 - acc: 0.8986 - val_loss: 0.0931 - val_acc: 0.8739\n",
      "Epoch 65/600\n",
      "0s - loss: 0.0855 - acc: 0.8971 - val_loss: 0.0924 - val_acc: 0.8696\n",
      "Epoch 66/600\n",
      "0s - loss: 0.0847 - acc: 0.8957 - val_loss: 0.0919 - val_acc: 0.8870\n",
      "Epoch 67/600\n",
      "0s - loss: 0.0842 - acc: 0.8957 - val_loss: 0.0915 - val_acc: 0.8826\n",
      "Epoch 68/600\n",
      "0s - loss: 0.0846 - acc: 0.8957 - val_loss: 0.0909 - val_acc: 0.8826\n",
      "Epoch 69/600\n",
      "0s - loss: 0.0833 - acc: 0.8957 - val_loss: 0.0908 - val_acc: 0.8913\n",
      "Epoch 70/600\n",
      "0s - loss: 0.0833 - acc: 0.8986 - val_loss: 0.0925 - val_acc: 0.8783\n",
      "Epoch 71/600\n",
      "0s - loss: 0.0831 - acc: 0.9000 - val_loss: 0.0900 - val_acc: 0.8913\n",
      "Epoch 72/600\n",
      "0s - loss: 0.0819 - acc: 0.9029 - val_loss: 0.0893 - val_acc: 0.8870\n",
      "Epoch 73/600\n",
      "0s - loss: 0.0817 - acc: 0.8986 - val_loss: 0.0907 - val_acc: 0.8870\n",
      "Epoch 74/600\n",
      "0s - loss: 0.0818 - acc: 0.9029 - val_loss: 0.0893 - val_acc: 0.8870\n",
      "Epoch 75/600\n",
      "0s - loss: 0.0810 - acc: 0.9000 - val_loss: 0.0891 - val_acc: 0.8870\n",
      "Epoch 76/600\n",
      "0s - loss: 0.0809 - acc: 0.9014 - val_loss: 0.0893 - val_acc: 0.8870\n",
      "Epoch 77/600\n",
      "0s - loss: 0.0807 - acc: 0.9043 - val_loss: 0.0890 - val_acc: 0.8913\n",
      "Epoch 78/600\n",
      "0s - loss: 0.0813 - acc: 0.8971 - val_loss: 0.0886 - val_acc: 0.8870\n",
      "Epoch 79/600\n",
      "0s - loss: 0.0803 - acc: 0.9014 - val_loss: 0.0883 - val_acc: 0.8870\n",
      "Epoch 80/600\n",
      "0s - loss: 0.0801 - acc: 0.9000 - val_loss: 0.0879 - val_acc: 0.8826\n",
      "Epoch 81/600\n",
      "0s - loss: 0.0797 - acc: 0.9029 - val_loss: 0.0878 - val_acc: 0.8870\n",
      "Epoch 82/600\n",
      "0s - loss: 0.0797 - acc: 0.9058 - val_loss: 0.0878 - val_acc: 0.8826\n",
      "Epoch 83/600\n",
      "0s - loss: 0.0795 - acc: 0.9000 - val_loss: 0.0881 - val_acc: 0.8826\n",
      "Epoch 84/600\n",
      "0s - loss: 0.0793 - acc: 0.8957 - val_loss: 0.0869 - val_acc: 0.8870\n",
      "Epoch 85/600\n",
      "0s - loss: 0.0791 - acc: 0.8986 - val_loss: 0.0887 - val_acc: 0.8913\n",
      "Epoch 86/600\n",
      "0s - loss: 0.0801 - acc: 0.8957 - val_loss: 0.0878 - val_acc: 0.8870\n",
      "Epoch 87/600\n",
      "0s - loss: 0.0791 - acc: 0.8971 - val_loss: 0.0866 - val_acc: 0.8826\n",
      "Epoch 88/600\n",
      "0s - loss: 0.0786 - acc: 0.8986 - val_loss: 0.0873 - val_acc: 0.8826\n",
      "Epoch 89/600\n",
      "0s - loss: 0.0788 - acc: 0.8971 - val_loss: 0.0873 - val_acc: 0.8826\n",
      "Epoch 90/600\n",
      "0s - loss: 0.0789 - acc: 0.8986 - val_loss: 0.0872 - val_acc: 0.8870\n",
      "Epoch 91/600\n",
      "0s - loss: 0.0785 - acc: 0.9000 - val_loss: 0.0863 - val_acc: 0.8826\n",
      "Epoch 92/600\n",
      "0s - loss: 0.0780 - acc: 0.8971 - val_loss: 0.0860 - val_acc: 0.8826\n",
      "Epoch 93/600\n",
      "0s - loss: 0.0782 - acc: 0.8986 - val_loss: 0.0862 - val_acc: 0.8826\n",
      "Epoch 94/600\n",
      "0s - loss: 0.0780 - acc: 0.8971 - val_loss: 0.0862 - val_acc: 0.8826\n",
      "Epoch 95/600\n",
      "0s - loss: 0.0778 - acc: 0.8986 - val_loss: 0.0861 - val_acc: 0.8870\n",
      "Epoch 96/600\n",
      "0s - loss: 0.0775 - acc: 0.8957 - val_loss: 0.0862 - val_acc: 0.8870\n",
      "Epoch 97/600\n",
      "0s - loss: 0.0775 - acc: 0.8971 - val_loss: 0.0867 - val_acc: 0.8913\n",
      "Epoch 98/600\n",
      "0s - loss: 0.0776 - acc: 0.8986 - val_loss: 0.0860 - val_acc: 0.8870\n",
      "Epoch 99/600\n",
      "0s - loss: 0.0772 - acc: 0.8971 - val_loss: 0.0863 - val_acc: 0.8913\n",
      "Epoch 100/600\n",
      "0s - loss: 0.0774 - acc: 0.8986 - val_loss: 0.0867 - val_acc: 0.8913\n",
      "Epoch 101/600\n",
      "0s - loss: 0.0772 - acc: 0.8971 - val_loss: 0.0858 - val_acc: 0.8870\n",
      "Epoch 102/600\n",
      "0s - loss: 0.0767 - acc: 0.8957 - val_loss: 0.0866 - val_acc: 0.8913\n",
      "Epoch 103/600\n",
      "0s - loss: 0.0767 - acc: 0.9000 - val_loss: 0.0858 - val_acc: 0.8826\n",
      "Epoch 104/600\n",
      "0s - loss: 0.0766 - acc: 0.8957 - val_loss: 0.0854 - val_acc: 0.8826\n",
      "Epoch 105/600\n",
      "0s - loss: 0.0769 - acc: 0.8986 - val_loss: 0.0856 - val_acc: 0.8826\n",
      "Epoch 106/600\n",
      "0s - loss: 0.0766 - acc: 0.9000 - val_loss: 0.0858 - val_acc: 0.8913\n",
      "Epoch 107/600\n",
      "0s - loss: 0.0761 - acc: 0.8986 - val_loss: 0.0851 - val_acc: 0.8826\n",
      "Epoch 108/600\n",
      "0s - loss: 0.0765 - acc: 0.8971 - val_loss: 0.0849 - val_acc: 0.8913\n",
      "Epoch 109/600\n",
      "0s - loss: 0.0758 - acc: 0.8986 - val_loss: 0.0849 - val_acc: 0.8826\n",
      "Epoch 110/600\n",
      "0s - loss: 0.0758 - acc: 0.8942 - val_loss: 0.0850 - val_acc: 0.8913\n",
      "Epoch 111/600\n",
      "0s - loss: 0.0756 - acc: 0.8971 - val_loss: 0.0865 - val_acc: 0.8913\n",
      "Epoch 112/600\n",
      "0s - loss: 0.0758 - acc: 0.8986 - val_loss: 0.0845 - val_acc: 0.8870\n",
      "Epoch 113/600\n",
      "0s - loss: 0.0753 - acc: 0.8971 - val_loss: 0.0844 - val_acc: 0.8870\n",
      "Epoch 114/600\n",
      "0s - loss: 0.0751 - acc: 0.8986 - val_loss: 0.0843 - val_acc: 0.8913\n",
      "Epoch 115/600\n",
      "0s - loss: 0.0753 - acc: 0.8957 - val_loss: 0.0846 - val_acc: 0.8783\n",
      "Epoch 116/600\n",
      "0s - loss: 0.0755 - acc: 0.9014 - val_loss: 0.0845 - val_acc: 0.8913\n",
      "Epoch 117/600\n",
      "0s - loss: 0.0749 - acc: 0.8971 - val_loss: 0.0843 - val_acc: 0.8913\n",
      "Epoch 118/600\n",
      "0s - loss: 0.0748 - acc: 0.8986 - val_loss: 0.0857 - val_acc: 0.8913\n",
      "Epoch 119/600\n",
      "0s - loss: 0.0748 - acc: 0.8986 - val_loss: 0.0844 - val_acc: 0.8870\n",
      "Epoch 120/600\n",
      "0s - loss: 0.0745 - acc: 0.8957 - val_loss: 0.0844 - val_acc: 0.8826\n",
      "Epoch 121/600\n",
      "0s - loss: 0.0745 - acc: 0.8986 - val_loss: 0.0844 - val_acc: 0.8913\n",
      "Epoch 122/600\n",
      "0s - loss: 0.0741 - acc: 0.8942 - val_loss: 0.0843 - val_acc: 0.8913\n",
      "Epoch 123/600\n",
      "0s - loss: 0.0741 - acc: 0.8957 - val_loss: 0.0849 - val_acc: 0.8913\n",
      "Epoch 124/600\n",
      "0s - loss: 0.0742 - acc: 0.8942 - val_loss: 0.0837 - val_acc: 0.8913\n",
      "Epoch 125/600\n",
      "0s - loss: 0.0739 - acc: 0.8986 - val_loss: 0.0834 - val_acc: 0.8826\n",
      "Epoch 126/600\n",
      "0s - loss: 0.0738 - acc: 0.8971 - val_loss: 0.0835 - val_acc: 0.8913\n",
      "Epoch 127/600\n",
      "0s - loss: 0.0735 - acc: 0.8957 - val_loss: 0.0835 - val_acc: 0.8870\n",
      "Epoch 128/600\n",
      "0s - loss: 0.0738 - acc: 0.8971 - val_loss: 0.0836 - val_acc: 0.8870\n",
      "Epoch 129/600\n",
      "0s - loss: 0.0733 - acc: 0.8971 - val_loss: 0.0834 - val_acc: 0.8870\n",
      "Epoch 130/600\n",
      "0s - loss: 0.0741 - acc: 0.9000 - val_loss: 0.0829 - val_acc: 0.8826\n",
      "Epoch 131/600\n",
      "0s - loss: 0.0731 - acc: 0.9000 - val_loss: 0.0836 - val_acc: 0.8913\n",
      "Epoch 132/600\n",
      "0s - loss: 0.0728 - acc: 0.8986 - val_loss: 0.0830 - val_acc: 0.8826\n",
      "Epoch 133/600\n",
      "0s - loss: 0.0727 - acc: 0.8986 - val_loss: 0.0852 - val_acc: 0.8913\n",
      "Epoch 134/600\n",
      "0s - loss: 0.0729 - acc: 0.9014 - val_loss: 0.0831 - val_acc: 0.8826\n",
      "Epoch 135/600\n",
      "0s - loss: 0.0733 - acc: 0.9000 - val_loss: 0.0834 - val_acc: 0.8826\n",
      "Epoch 136/600\n",
      "0s - loss: 0.0727 - acc: 0.8986 - val_loss: 0.0847 - val_acc: 0.8870\n",
      "Epoch 137/600\n",
      "0s - loss: 0.0726 - acc: 0.9000 - val_loss: 0.0846 - val_acc: 0.8870\n",
      "Epoch 138/600\n",
      "0s - loss: 0.0722 - acc: 0.8971 - val_loss: 0.0836 - val_acc: 0.8826\n",
      "Epoch 139/600\n",
      "0s - loss: 0.0724 - acc: 0.8986 - val_loss: 0.0836 - val_acc: 0.8826\n",
      "Epoch 140/600\n",
      "0s - loss: 0.0720 - acc: 0.9000 - val_loss: 0.0836 - val_acc: 0.8870\n",
      "Epoch 141/600\n",
      "0s - loss: 0.0718 - acc: 0.9000 - val_loss: 0.0831 - val_acc: 0.8826\n",
      "Epoch 142/600\n",
      "0s - loss: 0.0719 - acc: 0.8986 - val_loss: 0.0830 - val_acc: 0.8870\n",
      "Epoch 143/600\n",
      "0s - loss: 0.0717 - acc: 0.9014 - val_loss: 0.0857 - val_acc: 0.8870\n",
      "Epoch 144/600\n",
      "0s - loss: 0.0719 - acc: 0.9000 - val_loss: 0.0834 - val_acc: 0.8826\n",
      "Epoch 145/600\n",
      "0s - loss: 0.0720 - acc: 0.8986 - val_loss: 0.0831 - val_acc: 0.8826\n",
      "Epoch 146/600\n",
      "0s - loss: 0.0722 - acc: 0.8971 - val_loss: 0.0828 - val_acc: 0.8826\n",
      "Epoch 147/600\n",
      "0s - loss: 0.0715 - acc: 0.8986 - val_loss: 0.0835 - val_acc: 0.8870\n",
      "Epoch 148/600\n",
      "0s - loss: 0.0708 - acc: 0.9014 - val_loss: 0.0829 - val_acc: 0.8826\n",
      "Epoch 149/600\n",
      "0s - loss: 0.0708 - acc: 0.9014 - val_loss: 0.0831 - val_acc: 0.8870\n",
      "Epoch 150/600\n",
      "0s - loss: 0.0709 - acc: 0.9000 - val_loss: 0.0834 - val_acc: 0.8826\n",
      "Epoch 151/600\n",
      "0s - loss: 0.0714 - acc: 0.8986 - val_loss: 0.0828 - val_acc: 0.8870\n",
      "Epoch 152/600\n",
      "0s - loss: 0.0705 - acc: 0.9014 - val_loss: 0.0842 - val_acc: 0.8870\n",
      "Epoch 153/600\n",
      "0s - loss: 0.0706 - acc: 0.9029 - val_loss: 0.0842 - val_acc: 0.8870\n",
      "Epoch 154/600\n",
      "0s - loss: 0.0702 - acc: 0.9029 - val_loss: 0.0829 - val_acc: 0.8870\n",
      "Epoch 155/600\n",
      "0s - loss: 0.0702 - acc: 0.9043 - val_loss: 0.0843 - val_acc: 0.8870\n",
      "Epoch 156/600\n",
      "0s - loss: 0.0701 - acc: 0.9000 - val_loss: 0.0829 - val_acc: 0.8783\n",
      "Epoch 157/600\n",
      "0s - loss: 0.0702 - acc: 0.9014 - val_loss: 0.0849 - val_acc: 0.8870\n",
      "Epoch 158/600\n",
      "0s - loss: 0.0700 - acc: 0.9043 - val_loss: 0.0832 - val_acc: 0.8870\n",
      "Epoch 159/600\n",
      "0s - loss: 0.0697 - acc: 0.9043 - val_loss: 0.0835 - val_acc: 0.8870\n",
      "Epoch 160/600\n",
      "0s - loss: 0.0696 - acc: 0.9029 - val_loss: 0.0828 - val_acc: 0.8826\n",
      "Epoch 161/600\n",
      "0s - loss: 0.0695 - acc: 0.9043 - val_loss: 0.0832 - val_acc: 0.8870\n",
      "Epoch 162/600\n",
      "0s - loss: 0.0695 - acc: 0.9029 - val_loss: 0.0828 - val_acc: 0.8739\n",
      "Epoch 163/600\n",
      "0s - loss: 0.0700 - acc: 0.8986 - val_loss: 0.0828 - val_acc: 0.8739\n",
      "Epoch 164/600\n",
      "0s - loss: 0.0692 - acc: 0.9058 - val_loss: 0.0863 - val_acc: 0.8870\n",
      "Epoch 165/600\n",
      "0s - loss: 0.0704 - acc: 0.9000 - val_loss: 0.0837 - val_acc: 0.8870\n",
      "Epoch 166/600\n",
      "0s - loss: 0.0689 - acc: 0.9043 - val_loss: 0.0828 - val_acc: 0.8870\n",
      "Epoch 167/600\n",
      "0s - loss: 0.0690 - acc: 0.9058 - val_loss: 0.0821 - val_acc: 0.8870\n",
      "Epoch 168/600\n",
      "0s - loss: 0.0689 - acc: 0.8986 - val_loss: 0.0840 - val_acc: 0.8870\n",
      "Epoch 169/600\n",
      "0s - loss: 0.0686 - acc: 0.9043 - val_loss: 0.0832 - val_acc: 0.8870\n",
      "Epoch 170/600\n",
      "0s - loss: 0.0683 - acc: 0.9043 - val_loss: 0.0829 - val_acc: 0.8870\n",
      "Epoch 171/600\n",
      "0s - loss: 0.0683 - acc: 0.9043 - val_loss: 0.0848 - val_acc: 0.8870\n",
      "Epoch 172/600\n",
      "0s - loss: 0.0685 - acc: 0.9029 - val_loss: 0.0835 - val_acc: 0.8870\n",
      "Epoch 173/600\n",
      "0s - loss: 0.0685 - acc: 0.9058 - val_loss: 0.0868 - val_acc: 0.8826\n",
      "Epoch 174/600\n",
      "0s - loss: 0.0689 - acc: 0.9043 - val_loss: 0.0833 - val_acc: 0.8826\n",
      "Epoch 175/600\n",
      "0s - loss: 0.0678 - acc: 0.9072 - val_loss: 0.0848 - val_acc: 0.8870\n",
      "Epoch 176/600\n",
      "0s - loss: 0.0678 - acc: 0.9087 - val_loss: 0.0856 - val_acc: 0.8870\n",
      "Epoch 177/600\n",
      "0s - loss: 0.0678 - acc: 0.9072 - val_loss: 0.0834 - val_acc: 0.8826\n",
      "Epoch 178/600\n",
      "0s - loss: 0.0675 - acc: 0.9058 - val_loss: 0.0838 - val_acc: 0.8826\n",
      "Epoch 179/600\n",
      "0s - loss: 0.0674 - acc: 0.9058 - val_loss: 0.0844 - val_acc: 0.8870\n",
      "Epoch 180/600\n",
      "0s - loss: 0.0678 - acc: 0.9087 - val_loss: 0.0858 - val_acc: 0.8783\n",
      "Epoch 181/600\n",
      "0s - loss: 0.0673 - acc: 0.9087 - val_loss: 0.0823 - val_acc: 0.8783\n",
      "Epoch 182/600\n",
      "0s - loss: 0.0674 - acc: 0.9087 - val_loss: 0.0846 - val_acc: 0.8870\n",
      "Epoch 183/600\n",
      "0s - loss: 0.0670 - acc: 0.9072 - val_loss: 0.0830 - val_acc: 0.8870\n",
      "Epoch 184/600\n",
      "0s - loss: 0.0668 - acc: 0.9087 - val_loss: 0.0840 - val_acc: 0.8870\n",
      "Epoch 185/600\n",
      "0s - loss: 0.0667 - acc: 0.9072 - val_loss: 0.0842 - val_acc: 0.8870\n",
      "Epoch 186/600\n",
      "0s - loss: 0.0669 - acc: 0.9087 - val_loss: 0.0876 - val_acc: 0.8783\n",
      "Epoch 187/600\n",
      "0s - loss: 0.0673 - acc: 0.9058 - val_loss: 0.0843 - val_acc: 0.8870\n",
      "Epoch 188/600\n",
      "0s - loss: 0.0661 - acc: 0.9101 - val_loss: 0.0838 - val_acc: 0.8826\n",
      "Epoch 189/600\n",
      "0s - loss: 0.0661 - acc: 0.9058 - val_loss: 0.0827 - val_acc: 0.8739\n",
      "Epoch 190/600\n",
      "0s - loss: 0.0661 - acc: 0.9058 - val_loss: 0.0841 - val_acc: 0.8783\n",
      "Epoch 191/600\n",
      "0s - loss: 0.0658 - acc: 0.9072 - val_loss: 0.0843 - val_acc: 0.8783\n",
      "Epoch 192/600\n",
      "0s - loss: 0.0660 - acc: 0.9072 - val_loss: 0.0832 - val_acc: 0.8783\n",
      "Epoch 193/600\n",
      "0s - loss: 0.0672 - acc: 0.9101 - val_loss: 0.0832 - val_acc: 0.8783\n",
      "Epoch 194/600\n",
      "0s - loss: 0.0658 - acc: 0.9043 - val_loss: 0.0843 - val_acc: 0.8783\n",
      "Epoch 195/600\n",
      "0s - loss: 0.0653 - acc: 0.9072 - val_loss: 0.0850 - val_acc: 0.8783\n",
      "Epoch 196/600\n",
      "0s - loss: 0.0653 - acc: 0.9072 - val_loss: 0.0845 - val_acc: 0.8739\n",
      "Epoch 197/600\n",
      "0s - loss: 0.0654 - acc: 0.9087 - val_loss: 0.0848 - val_acc: 0.8783\n",
      "Epoch 198/600\n",
      "0s - loss: 0.0653 - acc: 0.9058 - val_loss: 0.0833 - val_acc: 0.8739\n",
      "Epoch 199/600\n",
      "0s - loss: 0.0655 - acc: 0.9087 - val_loss: 0.0841 - val_acc: 0.8739\n",
      "Epoch 200/600\n",
      "0s - loss: 0.0649 - acc: 0.9072 - val_loss: 0.0850 - val_acc: 0.8739\n",
      "Epoch 201/600\n",
      "0s - loss: 0.0648 - acc: 0.9072 - val_loss: 0.0886 - val_acc: 0.8696\n",
      "Epoch 202/600\n",
      "0s - loss: 0.0653 - acc: 0.9130 - val_loss: 0.0845 - val_acc: 0.8739\n",
      "Epoch 203/600\n",
      "0s - loss: 0.0646 - acc: 0.9087 - val_loss: 0.0831 - val_acc: 0.8739\n",
      "Epoch 204/600\n",
      "0s - loss: 0.0650 - acc: 0.9058 - val_loss: 0.0836 - val_acc: 0.8739\n",
      "Epoch 205/600\n",
      "0s - loss: 0.0643 - acc: 0.9072 - val_loss: 0.0845 - val_acc: 0.8783\n",
      "Epoch 206/600\n",
      "0s - loss: 0.0642 - acc: 0.9072 - val_loss: 0.0842 - val_acc: 0.8783\n",
      "Epoch 207/600\n",
      "0s - loss: 0.0640 - acc: 0.9087 - val_loss: 0.0841 - val_acc: 0.8739\n",
      "Epoch 208/600\n",
      "0s - loss: 0.0641 - acc: 0.9072 - val_loss: 0.0856 - val_acc: 0.8696\n",
      "Epoch 209/600\n",
      "0s - loss: 0.0640 - acc: 0.9116 - val_loss: 0.0864 - val_acc: 0.8696\n",
      "Epoch 210/600\n",
      "0s - loss: 0.0639 - acc: 0.9101 - val_loss: 0.0868 - val_acc: 0.8652\n",
      "Epoch 211/600\n",
      "0s - loss: 0.0640 - acc: 0.9116 - val_loss: 0.0889 - val_acc: 0.8696\n",
      "Epoch 212/600\n",
      "0s - loss: 0.0642 - acc: 0.9116 - val_loss: 0.0860 - val_acc: 0.8739\n",
      "Epoch 213/600\n",
      "0s - loss: 0.0634 - acc: 0.9116 - val_loss: 0.0845 - val_acc: 0.8739\n",
      "Epoch 214/600\n",
      "0s - loss: 0.0634 - acc: 0.9116 - val_loss: 0.0859 - val_acc: 0.8696\n",
      "Epoch 215/600\n",
      "0s - loss: 0.0633 - acc: 0.9130 - val_loss: 0.0845 - val_acc: 0.8739\n",
      "Epoch 216/600\n",
      "0s - loss: 0.0634 - acc: 0.9101 - val_loss: 0.0835 - val_acc: 0.8826\n",
      "Epoch 217/600\n",
      "0s - loss: 0.0637 - acc: 0.9072 - val_loss: 0.0861 - val_acc: 0.8696\n",
      "Epoch 218/600\n",
      "0s - loss: 0.0627 - acc: 0.9101 - val_loss: 0.0865 - val_acc: 0.8696\n",
      "Epoch 219/600\n",
      "0s - loss: 0.0627 - acc: 0.9101 - val_loss: 0.0867 - val_acc: 0.8652\n",
      "Epoch 220/600\n",
      "0s - loss: 0.0631 - acc: 0.9116 - val_loss: 0.0883 - val_acc: 0.8652\n",
      "Epoch 221/600\n",
      "0s - loss: 0.0627 - acc: 0.9116 - val_loss: 0.0853 - val_acc: 0.8826\n",
      "Epoch 222/600\n",
      "0s - loss: 0.0628 - acc: 0.9101 - val_loss: 0.0883 - val_acc: 0.8652\n",
      "Epoch 223/600\n",
      "0s - loss: 0.0626 - acc: 0.9145 - val_loss: 0.0870 - val_acc: 0.8652\n",
      "Epoch 224/600\n",
      "0s - loss: 0.0622 - acc: 0.9101 - val_loss: 0.0877 - val_acc: 0.8652\n",
      "Epoch 225/600\n",
      "0s - loss: 0.0620 - acc: 0.9145 - val_loss: 0.0849 - val_acc: 0.8783\n",
      "Epoch 226/600\n",
      "0s - loss: 0.0624 - acc: 0.9116 - val_loss: 0.0862 - val_acc: 0.8696\n",
      "Epoch 227/600\n",
      "0s - loss: 0.0618 - acc: 0.9101 - val_loss: 0.0893 - val_acc: 0.8652\n",
      "Epoch 228/600\n",
      "0s - loss: 0.0622 - acc: 0.9130 - val_loss: 0.0869 - val_acc: 0.8652\n",
      "Epoch 229/600\n",
      "0s - loss: 0.0616 - acc: 0.9116 - val_loss: 0.0863 - val_acc: 0.8739\n",
      "Epoch 230/600\n",
      "0s - loss: 0.0615 - acc: 0.9116 - val_loss: 0.0863 - val_acc: 0.8696\n",
      "Epoch 231/600\n",
      "0s - loss: 0.0613 - acc: 0.9116 - val_loss: 0.0872 - val_acc: 0.8696\n",
      "Epoch 232/600\n",
      "0s - loss: 0.0614 - acc: 0.9145 - val_loss: 0.0862 - val_acc: 0.8696\n",
      "Epoch 233/600\n",
      "0s - loss: 0.0619 - acc: 0.9116 - val_loss: 0.0920 - val_acc: 0.8652\n",
      "Epoch 234/600\n",
      "0s - loss: 0.0623 - acc: 0.9130 - val_loss: 0.0869 - val_acc: 0.8696\n",
      "Epoch 235/600\n",
      "0s - loss: 0.0610 - acc: 0.9130 - val_loss: 0.0861 - val_acc: 0.8739\n",
      "Epoch 236/600\n",
      "0s - loss: 0.0613 - acc: 0.9116 - val_loss: 0.0853 - val_acc: 0.8826\n",
      "Epoch 237/600\n",
      "0s - loss: 0.0612 - acc: 0.9130 - val_loss: 0.0866 - val_acc: 0.8783\n",
      "Epoch 238/600\n",
      "0s - loss: 0.0611 - acc: 0.9130 - val_loss: 0.0859 - val_acc: 0.8783\n",
      "Epoch 239/600\n",
      "0s - loss: 0.0612 - acc: 0.9145 - val_loss: 0.0853 - val_acc: 0.8870\n",
      "Epoch 240/600\n",
      "0s - loss: 0.0615 - acc: 0.9130 - val_loss: 0.0852 - val_acc: 0.8870\n",
      "Epoch 241/600\n",
      "0s - loss: 0.0608 - acc: 0.9145 - val_loss: 0.0871 - val_acc: 0.8739\n",
      "Epoch 242/600\n",
      "0s - loss: 0.0602 - acc: 0.9130 - val_loss: 0.0885 - val_acc: 0.8652\n",
      "Epoch 243/600\n",
      "0s - loss: 0.0603 - acc: 0.9130 - val_loss: 0.0852 - val_acc: 0.8826\n",
      "Epoch 244/600\n",
      "0s - loss: 0.0606 - acc: 0.9116 - val_loss: 0.0899 - val_acc: 0.8609\n",
      "Epoch 245/600\n",
      "0s - loss: 0.0601 - acc: 0.9159 - val_loss: 0.0865 - val_acc: 0.8870\n",
      "Epoch 246/600\n",
      "0s - loss: 0.0622 - acc: 0.9130 - val_loss: 0.0860 - val_acc: 0.8870\n",
      "Epoch 247/600\n",
      "0s - loss: 0.0611 - acc: 0.9145 - val_loss: 0.0867 - val_acc: 0.8826\n",
      "Epoch 248/600\n",
      "0s - loss: 0.0601 - acc: 0.9145 - val_loss: 0.0881 - val_acc: 0.8696\n",
      "Epoch 249/600\n",
      "0s - loss: 0.0596 - acc: 0.9145 - val_loss: 0.0872 - val_acc: 0.8739\n",
      "Epoch 250/600\n",
      "0s - loss: 0.0597 - acc: 0.9188 - val_loss: 0.0888 - val_acc: 0.8739\n",
      "Epoch 251/600\n",
      "0s - loss: 0.0593 - acc: 0.9145 - val_loss: 0.0881 - val_acc: 0.8783\n",
      "Epoch 252/600\n",
      "0s - loss: 0.0593 - acc: 0.9159 - val_loss: 0.0916 - val_acc: 0.8565\n",
      "Epoch 253/600\n",
      "0s - loss: 0.0600 - acc: 0.9174 - val_loss: 0.0896 - val_acc: 0.8609\n",
      "Epoch 254/600\n",
      "0s - loss: 0.0591 - acc: 0.9174 - val_loss: 0.0876 - val_acc: 0.8783\n",
      "Epoch 255/600\n",
      "0s - loss: 0.0593 - acc: 0.9174 - val_loss: 0.0882 - val_acc: 0.8783\n",
      "Epoch 256/600\n",
      "0s - loss: 0.0589 - acc: 0.9174 - val_loss: 0.0903 - val_acc: 0.8609\n",
      "Epoch 257/600\n",
      "0s - loss: 0.0592 - acc: 0.9159 - val_loss: 0.0899 - val_acc: 0.8609\n",
      "Epoch 258/600\n",
      "0s - loss: 0.0587 - acc: 0.9174 - val_loss: 0.0876 - val_acc: 0.8783\n",
      "Epoch 259/600\n",
      "0s - loss: 0.0590 - acc: 0.9217 - val_loss: 0.0937 - val_acc: 0.8565\n",
      "Epoch 260/600\n",
      "0s - loss: 0.0596 - acc: 0.9174 - val_loss: 0.0894 - val_acc: 0.8696\n",
      "Epoch 261/600\n",
      "0s - loss: 0.0583 - acc: 0.9145 - val_loss: 0.0910 - val_acc: 0.8652\n",
      "Epoch 262/600\n",
      "0s - loss: 0.0588 - acc: 0.9174 - val_loss: 0.0920 - val_acc: 0.8565\n",
      "Epoch 263/600\n",
      "0s - loss: 0.0595 - acc: 0.9174 - val_loss: 0.0936 - val_acc: 0.8522\n",
      "Epoch 264/600\n",
      "0s - loss: 0.0584 - acc: 0.9246 - val_loss: 0.0888 - val_acc: 0.8739\n",
      "Epoch 265/600\n",
      "0s - loss: 0.0581 - acc: 0.9203 - val_loss: 0.0918 - val_acc: 0.8609\n",
      "Epoch 266/600\n",
      "0s - loss: 0.0579 - acc: 0.9188 - val_loss: 0.0894 - val_acc: 0.8739\n",
      "Epoch 267/600\n",
      "0s - loss: 0.0589 - acc: 0.9174 - val_loss: 0.0889 - val_acc: 0.8783\n",
      "Epoch 268/600\n",
      "0s - loss: 0.0580 - acc: 0.9188 - val_loss: 0.0898 - val_acc: 0.8696\n",
      "Epoch 269/600\n",
      "0s - loss: 0.0577 - acc: 0.9159 - val_loss: 0.0900 - val_acc: 0.8696\n",
      "Epoch 270/600\n",
      "0s - loss: 0.0580 - acc: 0.9159 - val_loss: 0.0892 - val_acc: 0.8783\n",
      "Epoch 271/600\n",
      "0s - loss: 0.0584 - acc: 0.9232 - val_loss: 0.0917 - val_acc: 0.8565\n",
      "Epoch 272/600\n",
      "0s - loss: 0.0580 - acc: 0.9217 - val_loss: 0.0885 - val_acc: 0.8826\n",
      "Epoch 273/600\n",
      "0s - loss: 0.0584 - acc: 0.9203 - val_loss: 0.0915 - val_acc: 0.8696\n",
      "Epoch 274/600\n",
      "0s - loss: 0.0573 - acc: 0.9174 - val_loss: 0.0923 - val_acc: 0.8565\n",
      "Epoch 275/600\n",
      "0s - loss: 0.0576 - acc: 0.9188 - val_loss: 0.0948 - val_acc: 0.8522\n",
      "Epoch 276/600\n",
      "0s - loss: 0.0574 - acc: 0.9246 - val_loss: 0.0896 - val_acc: 0.8783\n",
      "Epoch 277/600\n",
      "0s - loss: 0.0572 - acc: 0.9203 - val_loss: 0.0930 - val_acc: 0.8565\n",
      "Epoch 278/600\n",
      "0s - loss: 0.0572 - acc: 0.9246 - val_loss: 0.0919 - val_acc: 0.8565\n",
      "Epoch 279/600\n",
      "0s - loss: 0.0568 - acc: 0.9217 - val_loss: 0.0911 - val_acc: 0.8652\n",
      "Epoch 280/600\n",
      "0s - loss: 0.0565 - acc: 0.9203 - val_loss: 0.0904 - val_acc: 0.8696\n",
      "Epoch 281/600\n",
      "0s - loss: 0.0571 - acc: 0.9203 - val_loss: 0.0890 - val_acc: 0.8783\n",
      "Epoch 282/600\n",
      "0s - loss: 0.0574 - acc: 0.9188 - val_loss: 0.0915 - val_acc: 0.8565\n",
      "Epoch 283/600\n",
      "0s - loss: 0.0565 - acc: 0.9203 - val_loss: 0.0903 - val_acc: 0.8696\n",
      "Epoch 284/600\n",
      "0s - loss: 0.0562 - acc: 0.9174 - val_loss: 0.0924 - val_acc: 0.8565\n",
      "Epoch 285/600\n",
      "0s - loss: 0.0561 - acc: 0.9217 - val_loss: 0.0911 - val_acc: 0.8609\n",
      "Epoch 286/600\n",
      "0s - loss: 0.0560 - acc: 0.9203 - val_loss: 0.0912 - val_acc: 0.8696\n",
      "Epoch 287/600\n",
      "0s - loss: 0.0562 - acc: 0.9217 - val_loss: 0.0899 - val_acc: 0.8739\n",
      "Epoch 288/600\n",
      "0s - loss: 0.0572 - acc: 0.9203 - val_loss: 0.0887 - val_acc: 0.8826\n",
      "Epoch 289/600\n",
      "0s - loss: 0.0581 - acc: 0.9188 - val_loss: 0.0893 - val_acc: 0.8783\n",
      "Epoch 290/600\n",
      "0s - loss: 0.0560 - acc: 0.9217 - val_loss: 0.0915 - val_acc: 0.8609\n",
      "Epoch 291/600\n",
      "0s - loss: 0.0554 - acc: 0.9232 - val_loss: 0.0918 - val_acc: 0.8652\n",
      "Epoch 292/600\n",
      "0s - loss: 0.0554 - acc: 0.9246 - val_loss: 0.0902 - val_acc: 0.8739\n",
      "Epoch 293/600\n",
      "0s - loss: 0.0560 - acc: 0.9217 - val_loss: 0.0899 - val_acc: 0.8783\n",
      "Epoch 294/600\n",
      "0s - loss: 0.0553 - acc: 0.9246 - val_loss: 0.0951 - val_acc: 0.8609\n",
      "Epoch 295/600\n",
      "0s - loss: 0.0560 - acc: 0.9290 - val_loss: 0.0926 - val_acc: 0.8565\n",
      "Epoch 296/600\n",
      "0s - loss: 0.0550 - acc: 0.9261 - val_loss: 0.0918 - val_acc: 0.8652\n",
      "Epoch 297/600\n",
      "0s - loss: 0.0553 - acc: 0.9232 - val_loss: 0.0901 - val_acc: 0.8783\n",
      "Epoch 298/600\n",
      "0s - loss: 0.0558 - acc: 0.9217 - val_loss: 0.0934 - val_acc: 0.8565\n",
      "Epoch 299/600\n",
      "0s - loss: 0.0551 - acc: 0.9261 - val_loss: 0.0941 - val_acc: 0.8522\n",
      "Epoch 300/600\n",
      "0s - loss: 0.0551 - acc: 0.9261 - val_loss: 0.0932 - val_acc: 0.8522\n",
      "Epoch 301/600\n",
      "0s - loss: 0.0546 - acc: 0.9261 - val_loss: 0.0924 - val_acc: 0.8609\n",
      "Epoch 302/600\n",
      "0s - loss: 0.0546 - acc: 0.9290 - val_loss: 0.0968 - val_acc: 0.8478\n",
      "Epoch 303/600\n",
      "0s - loss: 0.0554 - acc: 0.9290 - val_loss: 0.0934 - val_acc: 0.8522\n",
      "Epoch 304/600\n",
      "0s - loss: 0.0543 - acc: 0.9304 - val_loss: 0.0932 - val_acc: 0.8522\n",
      "Epoch 305/600\n",
      "0s - loss: 0.0542 - acc: 0.9261 - val_loss: 0.0946 - val_acc: 0.8478\n",
      "Epoch 306/600\n",
      "0s - loss: 0.0547 - acc: 0.9246 - val_loss: 0.0967 - val_acc: 0.8609\n",
      "Epoch 307/600\n",
      "0s - loss: 0.0547 - acc: 0.9290 - val_loss: 0.0928 - val_acc: 0.8609\n",
      "Epoch 308/600\n",
      "0s - loss: 0.0540 - acc: 0.9261 - val_loss: 0.0925 - val_acc: 0.8652\n",
      "Epoch 309/600\n",
      "0s - loss: 0.0538 - acc: 0.9261 - val_loss: 0.0950 - val_acc: 0.8565\n",
      "Epoch 310/600\n",
      "0s - loss: 0.0540 - acc: 0.9304 - val_loss: 0.0911 - val_acc: 0.8783\n",
      "Epoch 311/600\n",
      "0s - loss: 0.0548 - acc: 0.9275 - val_loss: 0.0985 - val_acc: 0.8522\n",
      "Epoch 312/600\n",
      "0s - loss: 0.0539 - acc: 0.9333 - val_loss: 0.0912 - val_acc: 0.8696\n",
      "Epoch 313/600\n",
      "0s - loss: 0.0539 - acc: 0.9275 - val_loss: 0.0968 - val_acc: 0.8565\n",
      "Epoch 314/600\n",
      "0s - loss: 0.0537 - acc: 0.9290 - val_loss: 0.0928 - val_acc: 0.8609\n",
      "Epoch 315/600\n",
      "0s - loss: 0.0534 - acc: 0.9290 - val_loss: 0.0951 - val_acc: 0.8522\n",
      "Epoch 316/600\n",
      "0s - loss: 0.0534 - acc: 0.9275 - val_loss: 0.0931 - val_acc: 0.8696\n",
      "Epoch 317/600\n",
      "0s - loss: 0.0532 - acc: 0.9319 - val_loss: 0.0911 - val_acc: 0.8696\n",
      "Epoch 318/600\n",
      "0s - loss: 0.0533 - acc: 0.9290 - val_loss: 0.0930 - val_acc: 0.8696\n",
      "Epoch 319/600\n",
      "0s - loss: 0.0530 - acc: 0.9304 - val_loss: 0.0925 - val_acc: 0.8739\n",
      "Epoch 320/600\n",
      "0s - loss: 0.0536 - acc: 0.9333 - val_loss: 0.0921 - val_acc: 0.8696\n",
      "Epoch 321/600\n",
      "0s - loss: 0.0538 - acc: 0.9290 - val_loss: 0.0935 - val_acc: 0.8609\n",
      "Epoch 322/600\n",
      "0s - loss: 0.0526 - acc: 0.9290 - val_loss: 0.0936 - val_acc: 0.8652\n",
      "Epoch 323/600\n",
      "0s - loss: 0.0525 - acc: 0.9319 - val_loss: 0.0937 - val_acc: 0.8609\n",
      "Epoch 324/600\n",
      "0s - loss: 0.0527 - acc: 0.9319 - val_loss: 0.0924 - val_acc: 0.8739\n",
      "Epoch 325/600\n",
      "0s - loss: 0.0539 - acc: 0.9290 - val_loss: 0.0925 - val_acc: 0.8739\n",
      "Epoch 326/600\n",
      "0s - loss: 0.0527 - acc: 0.9304 - val_loss: 0.0964 - val_acc: 0.8565\n",
      "Epoch 327/600\n",
      "0s - loss: 0.0523 - acc: 0.9333 - val_loss: 0.0933 - val_acc: 0.8696\n",
      "Epoch 328/600\n",
      "0s - loss: 0.0533 - acc: 0.9304 - val_loss: 0.0928 - val_acc: 0.8696\n",
      "Epoch 329/600\n",
      "0s - loss: 0.0529 - acc: 0.9261 - val_loss: 0.0930 - val_acc: 0.8652\n",
      "Epoch 330/600\n",
      "0s - loss: 0.0523 - acc: 0.9348 - val_loss: 0.0943 - val_acc: 0.8652\n",
      "Epoch 331/600\n",
      "0s - loss: 0.0519 - acc: 0.9333 - val_loss: 0.0996 - val_acc: 0.8478\n",
      "Epoch 332/600\n",
      "0s - loss: 0.0525 - acc: 0.9304 - val_loss: 0.0958 - val_acc: 0.8609\n",
      "Epoch 333/600\n",
      "0s - loss: 0.0519 - acc: 0.9333 - val_loss: 0.0928 - val_acc: 0.8739\n",
      "Epoch 334/600\n",
      "0s - loss: 0.0525 - acc: 0.9275 - val_loss: 0.0951 - val_acc: 0.8652\n",
      "Epoch 335/600\n",
      "0s - loss: 0.0516 - acc: 0.9362 - val_loss: 0.0948 - val_acc: 0.8696\n",
      "Epoch 336/600\n",
      "0s - loss: 0.0515 - acc: 0.9319 - val_loss: 0.0969 - val_acc: 0.8609\n",
      "Epoch 337/600\n",
      "0s - loss: 0.0511 - acc: 0.9362 - val_loss: 0.0956 - val_acc: 0.8609\n",
      "Epoch 338/600\n",
      "0s - loss: 0.0511 - acc: 0.9333 - val_loss: 0.0966 - val_acc: 0.8609\n",
      "Epoch 339/600\n",
      "0s - loss: 0.0511 - acc: 0.9377 - val_loss: 0.0955 - val_acc: 0.8652\n",
      "Epoch 340/600\n",
      "0s - loss: 0.0511 - acc: 0.9362 - val_loss: 0.0970 - val_acc: 0.8609\n",
      "Epoch 341/600\n",
      "0s - loss: 0.0513 - acc: 0.9319 - val_loss: 0.1056 - val_acc: 0.8391\n",
      "Epoch 342/600\n",
      "0s - loss: 0.0526 - acc: 0.9319 - val_loss: 0.0958 - val_acc: 0.8696\n",
      "Epoch 343/600\n",
      "0s - loss: 0.0509 - acc: 0.9362 - val_loss: 0.0980 - val_acc: 0.8522\n",
      "Epoch 344/600\n",
      "0s - loss: 0.0505 - acc: 0.9391 - val_loss: 0.0956 - val_acc: 0.8696\n",
      "Epoch 345/600\n",
      "0s - loss: 0.0506 - acc: 0.9406 - val_loss: 0.0973 - val_acc: 0.8522\n",
      "Epoch 346/600\n",
      "0s - loss: 0.0501 - acc: 0.9377 - val_loss: 0.0966 - val_acc: 0.8609\n",
      "Epoch 347/600\n",
      "0s - loss: 0.0501 - acc: 0.9362 - val_loss: 0.0970 - val_acc: 0.8522\n",
      "Epoch 348/600\n",
      "0s - loss: 0.0501 - acc: 0.9362 - val_loss: 0.1004 - val_acc: 0.8435\n",
      "Epoch 349/600\n",
      "0s - loss: 0.0502 - acc: 0.9420 - val_loss: 0.0988 - val_acc: 0.8565\n",
      "Epoch 350/600\n",
      "0s - loss: 0.0499 - acc: 0.9362 - val_loss: 0.0956 - val_acc: 0.8739\n",
      "Epoch 351/600\n",
      "0s - loss: 0.0518 - acc: 0.9333 - val_loss: 0.0952 - val_acc: 0.8739\n",
      "Epoch 352/600\n",
      "0s - loss: 0.0503 - acc: 0.9406 - val_loss: 0.0980 - val_acc: 0.8609\n",
      "Epoch 353/600\n",
      "0s - loss: 0.0495 - acc: 0.9362 - val_loss: 0.0969 - val_acc: 0.8609\n",
      "Epoch 354/600\n",
      "0s - loss: 0.0493 - acc: 0.9406 - val_loss: 0.0958 - val_acc: 0.8739\n",
      "Epoch 355/600\n",
      "0s - loss: 0.0505 - acc: 0.9377 - val_loss: 0.0969 - val_acc: 0.8696\n",
      "Epoch 356/600\n",
      "0s - loss: 0.0495 - acc: 0.9362 - val_loss: 0.0956 - val_acc: 0.8739\n",
      "Epoch 357/600\n",
      "0s - loss: 0.0495 - acc: 0.9377 - val_loss: 0.0950 - val_acc: 0.8739\n",
      "Epoch 358/600\n",
      "0s - loss: 0.0491 - acc: 0.9420 - val_loss: 0.1001 - val_acc: 0.8478\n",
      "Epoch 359/600\n",
      "0s - loss: 0.0493 - acc: 0.9406 - val_loss: 0.0990 - val_acc: 0.8652\n",
      "Epoch 360/600\n",
      "0s - loss: 0.0488 - acc: 0.9406 - val_loss: 0.1012 - val_acc: 0.8522\n",
      "Epoch 361/600\n",
      "0s - loss: 0.0492 - acc: 0.9420 - val_loss: 0.1001 - val_acc: 0.8522\n",
      "Epoch 362/600\n",
      "0s - loss: 0.0486 - acc: 0.9420 - val_loss: 0.0981 - val_acc: 0.8696\n",
      "Epoch 363/600\n",
      "0s - loss: 0.0485 - acc: 0.9420 - val_loss: 0.1017 - val_acc: 0.8522\n",
      "Epoch 364/600\n",
      "0s - loss: 0.0491 - acc: 0.9435 - val_loss: 0.1035 - val_acc: 0.8348\n",
      "Epoch 365/600\n",
      "0s - loss: 0.0494 - acc: 0.9406 - val_loss: 0.1005 - val_acc: 0.8522\n",
      "Epoch 366/600\n",
      "0s - loss: 0.0487 - acc: 0.9435 - val_loss: 0.0962 - val_acc: 0.8739\n",
      "Epoch 367/600\n",
      "0s - loss: 0.0482 - acc: 0.9435 - val_loss: 0.1040 - val_acc: 0.8435\n",
      "Epoch 368/600\n",
      "0s - loss: 0.0484 - acc: 0.9435 - val_loss: 0.0976 - val_acc: 0.8696\n",
      "Epoch 369/600\n",
      "0s - loss: 0.0482 - acc: 0.9391 - val_loss: 0.1002 - val_acc: 0.8522\n",
      "Epoch 370/600\n",
      "0s - loss: 0.0478 - acc: 0.9391 - val_loss: 0.0967 - val_acc: 0.8739\n",
      "Epoch 371/600\n",
      "0s - loss: 0.0482 - acc: 0.9464 - val_loss: 0.0974 - val_acc: 0.8696\n",
      "Epoch 372/600\n",
      "0s - loss: 0.0476 - acc: 0.9377 - val_loss: 0.0972 - val_acc: 0.8696\n",
      "Epoch 373/600\n",
      "0s - loss: 0.0474 - acc: 0.9435 - val_loss: 0.1042 - val_acc: 0.8435\n",
      "Epoch 374/600\n",
      "0s - loss: 0.0484 - acc: 0.9420 - val_loss: 0.1012 - val_acc: 0.8522\n",
      "Epoch 375/600\n",
      "0s - loss: 0.0472 - acc: 0.9435 - val_loss: 0.0968 - val_acc: 0.8783\n",
      "Epoch 376/600\n",
      "0s - loss: 0.0483 - acc: 0.9391 - val_loss: 0.1022 - val_acc: 0.8522\n",
      "Epoch 377/600\n",
      "0s - loss: 0.0479 - acc: 0.9464 - val_loss: 0.1027 - val_acc: 0.8478\n",
      "Epoch 378/600\n",
      "0s - loss: 0.0472 - acc: 0.9449 - val_loss: 0.0957 - val_acc: 0.8696\n",
      "Epoch 379/600\n",
      "0s - loss: 0.0481 - acc: 0.9420 - val_loss: 0.1002 - val_acc: 0.8522\n",
      "Epoch 380/600\n",
      "0s - loss: 0.0471 - acc: 0.9435 - val_loss: 0.1033 - val_acc: 0.8522\n",
      "Epoch 381/600\n",
      "0s - loss: 0.0469 - acc: 0.9435 - val_loss: 0.0975 - val_acc: 0.8696\n",
      "Epoch 382/600\n",
      "0s - loss: 0.0472 - acc: 0.9478 - val_loss: 0.0981 - val_acc: 0.8696\n",
      "Epoch 383/600\n",
      "0s - loss: 0.0466 - acc: 0.9464 - val_loss: 0.1023 - val_acc: 0.8565\n",
      "Epoch 384/600\n",
      "0s - loss: 0.0465 - acc: 0.9435 - val_loss: 0.0981 - val_acc: 0.8783\n",
      "Epoch 385/600\n",
      "0s - loss: 0.0478 - acc: 0.9435 - val_loss: 0.0973 - val_acc: 0.8739\n",
      "Epoch 386/600\n",
      "0s - loss: 0.0465 - acc: 0.9449 - val_loss: 0.1047 - val_acc: 0.8478\n",
      "Epoch 387/600\n",
      "0s - loss: 0.0470 - acc: 0.9420 - val_loss: 0.0969 - val_acc: 0.8739\n",
      "Epoch 388/600\n",
      "0s - loss: 0.0474 - acc: 0.9478 - val_loss: 0.1015 - val_acc: 0.8565\n",
      "Epoch 389/600\n",
      "0s - loss: 0.0463 - acc: 0.9464 - val_loss: 0.1057 - val_acc: 0.8478\n",
      "Epoch 390/600\n",
      "0s - loss: 0.0473 - acc: 0.9464 - val_loss: 0.1036 - val_acc: 0.8522\n",
      "Epoch 391/600\n",
      "0s - loss: 0.0461 - acc: 0.9464 - val_loss: 0.0981 - val_acc: 0.8783\n",
      "Epoch 392/600\n",
      "0s - loss: 0.0464 - acc: 0.9493 - val_loss: 0.1021 - val_acc: 0.8522\n",
      "Epoch 393/600\n",
      "0s - loss: 0.0458 - acc: 0.9435 - val_loss: 0.1003 - val_acc: 0.8739\n",
      "Epoch 394/600\n",
      "0s - loss: 0.0460 - acc: 0.9478 - val_loss: 0.0975 - val_acc: 0.8739\n",
      "Epoch 395/600\n",
      "0s - loss: 0.0467 - acc: 0.9435 - val_loss: 0.0958 - val_acc: 0.8783\n",
      "Epoch 396/600\n",
      "0s - loss: 0.0474 - acc: 0.9449 - val_loss: 0.0969 - val_acc: 0.8739\n",
      "Epoch 397/600\n",
      "0s - loss: 0.0459 - acc: 0.9478 - val_loss: 0.0996 - val_acc: 0.8696\n",
      "Epoch 398/600\n",
      "0s - loss: 0.0454 - acc: 0.9464 - val_loss: 0.1000 - val_acc: 0.8652\n",
      "Epoch 399/600\n",
      "0s - loss: 0.0453 - acc: 0.9449 - val_loss: 0.0999 - val_acc: 0.8696\n",
      "Epoch 400/600\n",
      "0s - loss: 0.0452 - acc: 0.9464 - val_loss: 0.1006 - val_acc: 0.8609\n",
      "Epoch 401/600\n",
      "0s - loss: 0.0453 - acc: 0.9449 - val_loss: 0.0996 - val_acc: 0.8783\n",
      "Epoch 402/600\n",
      "0s - loss: 0.0464 - acc: 0.9449 - val_loss: 0.0991 - val_acc: 0.8739\n",
      "Epoch 403/600\n",
      "0s - loss: 0.0451 - acc: 0.9507 - val_loss: 0.1048 - val_acc: 0.8522\n",
      "Epoch 404/600\n",
      "0s - loss: 0.0453 - acc: 0.9449 - val_loss: 0.1009 - val_acc: 0.8652\n",
      "Epoch 405/600\n",
      "0s - loss: 0.0447 - acc: 0.9478 - val_loss: 0.1006 - val_acc: 0.8652\n",
      "Epoch 406/600\n",
      "0s - loss: 0.0447 - acc: 0.9493 - val_loss: 0.0990 - val_acc: 0.8739\n",
      "Epoch 407/600\n",
      "0s - loss: 0.0452 - acc: 0.9507 - val_loss: 0.1034 - val_acc: 0.8609\n",
      "Epoch 408/600\n",
      "0s - loss: 0.0445 - acc: 0.9478 - val_loss: 0.1015 - val_acc: 0.8652\n",
      "Epoch 409/600\n",
      "0s - loss: 0.0445 - acc: 0.9464 - val_loss: 0.0996 - val_acc: 0.8696\n",
      "Epoch 410/600\n",
      "0s - loss: 0.0444 - acc: 0.9493 - val_loss: 0.1082 - val_acc: 0.8435\n",
      "Epoch 411/600\n",
      "0s - loss: 0.0474 - acc: 0.9420 - val_loss: 0.1075 - val_acc: 0.8478\n",
      "Epoch 412/600\n",
      "0s - loss: 0.0450 - acc: 0.9449 - val_loss: 0.0990 - val_acc: 0.8739\n",
      "Epoch 413/600\n",
      "0s - loss: 0.0447 - acc: 0.9507 - val_loss: 0.1035 - val_acc: 0.8696\n",
      "Epoch 414/600\n",
      "0s - loss: 0.0442 - acc: 0.9493 - val_loss: 0.1015 - val_acc: 0.8696\n",
      "Epoch 415/600\n",
      "0s - loss: 0.0443 - acc: 0.9493 - val_loss: 0.1000 - val_acc: 0.8739\n",
      "Epoch 416/600\n",
      "0s - loss: 0.0449 - acc: 0.9507 - val_loss: 0.0984 - val_acc: 0.8739\n",
      "Epoch 417/600\n",
      "0s - loss: 0.0441 - acc: 0.9522 - val_loss: 0.1083 - val_acc: 0.8522\n",
      "Epoch 418/600\n",
      "0s - loss: 0.0449 - acc: 0.9464 - val_loss: 0.1005 - val_acc: 0.8696\n",
      "Epoch 419/600\n",
      "0s - loss: 0.0439 - acc: 0.9449 - val_loss: 0.1008 - val_acc: 0.8652\n",
      "Epoch 420/600\n",
      "0s - loss: 0.0438 - acc: 0.9522 - val_loss: 0.1022 - val_acc: 0.8652\n",
      "Epoch 421/600\n",
      "0s - loss: 0.0434 - acc: 0.9493 - val_loss: 0.1043 - val_acc: 0.8609\n",
      "Epoch 422/600\n",
      "0s - loss: 0.0439 - acc: 0.9478 - val_loss: 0.1046 - val_acc: 0.8565\n",
      "Epoch 423/600\n",
      "0s - loss: 0.0437 - acc: 0.9493 - val_loss: 0.1027 - val_acc: 0.8652\n",
      "Epoch 424/600\n",
      "0s - loss: 0.0435 - acc: 0.9507 - val_loss: 0.1071 - val_acc: 0.8565\n",
      "Epoch 425/600\n",
      "0s - loss: 0.0446 - acc: 0.9478 - val_loss: 0.1026 - val_acc: 0.8652\n",
      "Epoch 426/600\n",
      "0s - loss: 0.0439 - acc: 0.9478 - val_loss: 0.1092 - val_acc: 0.8478\n",
      "Epoch 427/600\n",
      "0s - loss: 0.0442 - acc: 0.9464 - val_loss: 0.0992 - val_acc: 0.8783\n",
      "Epoch 428/600\n",
      "0s - loss: 0.0440 - acc: 0.9478 - val_loss: 0.1004 - val_acc: 0.8696\n",
      "Epoch 429/600\n",
      "0s - loss: 0.0431 - acc: 0.9536 - val_loss: 0.1081 - val_acc: 0.8435\n",
      "Epoch 430/600\n",
      "0s - loss: 0.0445 - acc: 0.9449 - val_loss: 0.1059 - val_acc: 0.8609\n",
      "Epoch 431/600\n",
      "0s - loss: 0.0441 - acc: 0.9478 - val_loss: 0.1081 - val_acc: 0.8435\n",
      "Epoch 432/600\n",
      "0s - loss: 0.0435 - acc: 0.9478 - val_loss: 0.1003 - val_acc: 0.8739\n",
      "Epoch 433/600\n",
      "0s - loss: 0.0427 - acc: 0.9522 - val_loss: 0.1040 - val_acc: 0.8696\n",
      "Epoch 434/600\n",
      "0s - loss: 0.0426 - acc: 0.9493 - val_loss: 0.1052 - val_acc: 0.8609\n",
      "Epoch 435/600\n",
      "0s - loss: 0.0428 - acc: 0.9478 - val_loss: 0.1046 - val_acc: 0.8652\n",
      "Epoch 436/600\n",
      "0s - loss: 0.0424 - acc: 0.9507 - val_loss: 0.0987 - val_acc: 0.8739\n",
      "Epoch 437/600\n",
      "0s - loss: 0.0442 - acc: 0.9464 - val_loss: 0.0986 - val_acc: 0.8739\n",
      "Epoch 438/600\n",
      "0s - loss: 0.0426 - acc: 0.9522 - val_loss: 0.1016 - val_acc: 0.8739\n",
      "Epoch 439/600\n",
      "0s - loss: 0.0422 - acc: 0.9522 - val_loss: 0.1008 - val_acc: 0.8739\n",
      "Epoch 440/600\n",
      "0s - loss: 0.0424 - acc: 0.9522 - val_loss: 0.1076 - val_acc: 0.8609\n",
      "Epoch 441/600\n",
      "0s - loss: 0.0425 - acc: 0.9464 - val_loss: 0.1011 - val_acc: 0.8739\n",
      "Epoch 442/600\n",
      "0s - loss: 0.0424 - acc: 0.9536 - val_loss: 0.1060 - val_acc: 0.8609\n",
      "Epoch 443/600\n",
      "0s - loss: 0.0423 - acc: 0.9493 - val_loss: 0.1032 - val_acc: 0.8696\n",
      "Epoch 444/600\n",
      "0s - loss: 0.0420 - acc: 0.9536 - val_loss: 0.1033 - val_acc: 0.8696\n",
      "Epoch 445/600\n",
      "0s - loss: 0.0418 - acc: 0.9522 - val_loss: 0.1040 - val_acc: 0.8652\n",
      "Epoch 446/600\n",
      "0s - loss: 0.0423 - acc: 0.9493 - val_loss: 0.1056 - val_acc: 0.8652\n",
      "Epoch 447/600\n",
      "0s - loss: 0.0426 - acc: 0.9493 - val_loss: 0.1083 - val_acc: 0.8652\n",
      "Epoch 448/600\n",
      "0s - loss: 0.0433 - acc: 0.9507 - val_loss: 0.1056 - val_acc: 0.8609\n",
      "Epoch 449/600\n",
      "0s - loss: 0.0421 - acc: 0.9522 - val_loss: 0.1033 - val_acc: 0.8652\n",
      "Epoch 450/600\n",
      "0s - loss: 0.0416 - acc: 0.9507 - val_loss: 0.1061 - val_acc: 0.8565\n",
      "Epoch 451/600\n",
      "0s - loss: 0.0425 - acc: 0.9507 - val_loss: 0.1063 - val_acc: 0.8565\n",
      "Epoch 452/600\n",
      "0s - loss: 0.0416 - acc: 0.9536 - val_loss: 0.1018 - val_acc: 0.8696\n",
      "Epoch 453/600\n",
      "0s - loss: 0.0412 - acc: 0.9522 - val_loss: 0.1050 - val_acc: 0.8652\n",
      "Epoch 454/600\n",
      "0s - loss: 0.0421 - acc: 0.9478 - val_loss: 0.1093 - val_acc: 0.8652\n",
      "Epoch 455/600\n",
      "0s - loss: 0.0426 - acc: 0.9478 - val_loss: 0.1039 - val_acc: 0.8696\n",
      "Epoch 456/600\n",
      "0s - loss: 0.0410 - acc: 0.9536 - val_loss: 0.1052 - val_acc: 0.8696\n",
      "Epoch 457/600\n",
      "0s - loss: 0.0410 - acc: 0.9507 - val_loss: 0.1002 - val_acc: 0.8652\n",
      "Epoch 458/600\n",
      "0s - loss: 0.0416 - acc: 0.9536 - val_loss: 0.1033 - val_acc: 0.8696\n",
      "Epoch 459/600\n",
      "0s - loss: 0.0408 - acc: 0.9536 - val_loss: 0.1074 - val_acc: 0.8652\n",
      "Epoch 460/600\n",
      "0s - loss: 0.0418 - acc: 0.9493 - val_loss: 0.1068 - val_acc: 0.8652\n",
      "Epoch 461/600\n",
      "0s - loss: 0.0414 - acc: 0.9536 - val_loss: 0.1087 - val_acc: 0.8609\n",
      "Epoch 462/600\n",
      "0s - loss: 0.0414 - acc: 0.9522 - val_loss: 0.1058 - val_acc: 0.8652\n",
      "Epoch 463/600\n",
      "0s - loss: 0.0406 - acc: 0.9522 - val_loss: 0.1031 - val_acc: 0.8652\n",
      "Epoch 464/600\n",
      "0s - loss: 0.0407 - acc: 0.9522 - val_loss: 0.1021 - val_acc: 0.8652\n",
      "Epoch 465/600\n",
      "0s - loss: 0.0408 - acc: 0.9536 - val_loss: 0.1033 - val_acc: 0.8652\n",
      "Epoch 466/600\n",
      "0s - loss: 0.0410 - acc: 0.9536 - val_loss: 0.1029 - val_acc: 0.8652\n",
      "Epoch 467/600\n",
      "0s - loss: 0.0418 - acc: 0.9478 - val_loss: 0.0986 - val_acc: 0.8652\n",
      "Epoch 468/600\n",
      "0s - loss: 0.0434 - acc: 0.9580 - val_loss: 0.1044 - val_acc: 0.8696\n",
      "Epoch 469/600\n",
      "0s - loss: 0.0404 - acc: 0.9536 - val_loss: 0.0997 - val_acc: 0.8696\n",
      "Epoch 470/600\n",
      "0s - loss: 0.0411 - acc: 0.9551 - val_loss: 0.1034 - val_acc: 0.8696\n",
      "Epoch 471/600\n",
      "0s - loss: 0.0401 - acc: 0.9551 - val_loss: 0.1044 - val_acc: 0.8696\n",
      "Epoch 472/600\n",
      "0s - loss: 0.0400 - acc: 0.9507 - val_loss: 0.1068 - val_acc: 0.8696\n",
      "Epoch 473/600\n",
      "0s - loss: 0.0402 - acc: 0.9522 - val_loss: 0.0988 - val_acc: 0.8609\n",
      "Epoch 474/600\n",
      "0s - loss: 0.0431 - acc: 0.9536 - val_loss: 0.1001 - val_acc: 0.8652\n",
      "Epoch 475/600\n",
      "0s - loss: 0.0408 - acc: 0.9580 - val_loss: 0.1033 - val_acc: 0.8696\n",
      "Epoch 476/600\n",
      "0s - loss: 0.0398 - acc: 0.9522 - val_loss: 0.1051 - val_acc: 0.8696\n",
      "Epoch 477/600\n",
      "0s - loss: 0.0398 - acc: 0.9565 - val_loss: 0.0989 - val_acc: 0.8652\n",
      "Epoch 478/600\n",
      "0s - loss: 0.0423 - acc: 0.9536 - val_loss: 0.0995 - val_acc: 0.8609\n",
      "Epoch 479/600\n",
      "0s - loss: 0.0407 - acc: 0.9565 - val_loss: 0.1044 - val_acc: 0.8696\n",
      "Epoch 480/600\n",
      "0s - loss: 0.0396 - acc: 0.9507 - val_loss: 0.1025 - val_acc: 0.8609\n",
      "Epoch 481/600\n",
      "0s - loss: 0.0399 - acc: 0.9536 - val_loss: 0.1077 - val_acc: 0.8609\n",
      "Epoch 482/600\n",
      "0s - loss: 0.0395 - acc: 0.9551 - val_loss: 0.1025 - val_acc: 0.8696\n",
      "Epoch 483/600\n",
      "0s - loss: 0.0393 - acc: 0.9551 - val_loss: 0.1055 - val_acc: 0.8696\n",
      "Epoch 484/600\n",
      "0s - loss: 0.0393 - acc: 0.9536 - val_loss: 0.1024 - val_acc: 0.8652\n",
      "Epoch 485/600\n",
      "0s - loss: 0.0402 - acc: 0.9565 - val_loss: 0.1041 - val_acc: 0.8696\n",
      "Epoch 486/600\n",
      "0s - loss: 0.0392 - acc: 0.9551 - val_loss: 0.1040 - val_acc: 0.8696\n",
      "Epoch 487/600\n",
      "0s - loss: 0.0391 - acc: 0.9565 - val_loss: 0.1006 - val_acc: 0.8652\n",
      "Epoch 488/600\n",
      "0s - loss: 0.0398 - acc: 0.9609 - val_loss: 0.1016 - val_acc: 0.8652\n",
      "Epoch 489/600\n",
      "0s - loss: 0.0394 - acc: 0.9580 - val_loss: 0.1034 - val_acc: 0.8652\n",
      "Epoch 490/600\n",
      "0s - loss: 0.0393 - acc: 0.9580 - val_loss: 0.1025 - val_acc: 0.8609\n",
      "Epoch 491/600\n",
      "0s - loss: 0.0396 - acc: 0.9551 - val_loss: 0.1084 - val_acc: 0.8609\n",
      "Epoch 492/600\n",
      "0s - loss: 0.0391 - acc: 0.9580 - val_loss: 0.1045 - val_acc: 0.8696\n",
      "Epoch 493/600\n",
      "0s - loss: 0.0391 - acc: 0.9580 - val_loss: 0.1063 - val_acc: 0.8652\n",
      "Epoch 494/600\n",
      "0s - loss: 0.0392 - acc: 0.9551 - val_loss: 0.1023 - val_acc: 0.8652\n",
      "Epoch 495/600\n",
      "0s - loss: 0.0387 - acc: 0.9580 - val_loss: 0.1080 - val_acc: 0.8652\n",
      "Epoch 496/600\n",
      "0s - loss: 0.0390 - acc: 0.9565 - val_loss: 0.1077 - val_acc: 0.8609\n",
      "Epoch 497/600\n",
      "0s - loss: 0.0391 - acc: 0.9565 - val_loss: 0.1019 - val_acc: 0.8696\n",
      "Epoch 498/600\n",
      "0s - loss: 0.0388 - acc: 0.9594 - val_loss: 0.1046 - val_acc: 0.8696\n",
      "Epoch 499/600\n",
      "0s - loss: 0.0385 - acc: 0.9565 - val_loss: 0.1028 - val_acc: 0.8652\n",
      "Epoch 500/600\n",
      "0s - loss: 0.0386 - acc: 0.9580 - val_loss: 0.1039 - val_acc: 0.8609\n",
      "Epoch 501/600\n",
      "0s - loss: 0.0395 - acc: 0.9565 - val_loss: 0.1009 - val_acc: 0.8522\n",
      "Epoch 502/600\n",
      "0s - loss: 0.0398 - acc: 0.9522 - val_loss: 0.1036 - val_acc: 0.8696\n",
      "Epoch 503/600\n",
      "0s - loss: 0.0385 - acc: 0.9594 - val_loss: 0.1117 - val_acc: 0.8652\n",
      "Epoch 504/600\n",
      "0s - loss: 0.0407 - acc: 0.9522 - val_loss: 0.1059 - val_acc: 0.8696\n",
      "Epoch 505/600\n",
      "0s - loss: 0.0381 - acc: 0.9551 - val_loss: 0.1042 - val_acc: 0.8652\n",
      "Epoch 506/600\n",
      "0s - loss: 0.0379 - acc: 0.9565 - val_loss: 0.1067 - val_acc: 0.8652\n",
      "Epoch 507/600\n",
      "0s - loss: 0.0379 - acc: 0.9565 - val_loss: 0.1005 - val_acc: 0.8609\n",
      "Epoch 508/600\n",
      "0s - loss: 0.0395 - acc: 0.9565 - val_loss: 0.1004 - val_acc: 0.8565\n",
      "Epoch 509/600\n",
      "0s - loss: 0.0390 - acc: 0.9594 - val_loss: 0.1054 - val_acc: 0.8696\n",
      "Epoch 510/600\n",
      "0s - loss: 0.0378 - acc: 0.9609 - val_loss: 0.1073 - val_acc: 0.8652\n",
      "Epoch 511/600\n",
      "0s - loss: 0.0377 - acc: 0.9594 - val_loss: 0.1024 - val_acc: 0.8609\n",
      "Epoch 512/600\n",
      "0s - loss: 0.0378 - acc: 0.9594 - val_loss: 0.1050 - val_acc: 0.8696\n",
      "Epoch 513/600\n",
      "0s - loss: 0.0375 - acc: 0.9609 - val_loss: 0.1105 - val_acc: 0.8609\n",
      "Epoch 514/600\n",
      "0s - loss: 0.0394 - acc: 0.9536 - val_loss: 0.1120 - val_acc: 0.8652\n",
      "Epoch 515/600\n",
      "0s - loss: 0.0383 - acc: 0.9565 - val_loss: 0.1036 - val_acc: 0.8652\n",
      "Epoch 516/600\n",
      "0s - loss: 0.0374 - acc: 0.9623 - val_loss: 0.1044 - val_acc: 0.8609\n",
      "Epoch 517/600\n",
      "0s - loss: 0.0376 - acc: 0.9623 - val_loss: 0.1043 - val_acc: 0.8565\n",
      "Epoch 518/600\n",
      "0s - loss: 0.0375 - acc: 0.9594 - val_loss: 0.1092 - val_acc: 0.8652\n",
      "Epoch 519/600\n",
      "0s - loss: 0.0372 - acc: 0.9609 - val_loss: 0.1060 - val_acc: 0.8696\n",
      "Epoch 520/600\n",
      "0s - loss: 0.0370 - acc: 0.9623 - val_loss: 0.1029 - val_acc: 0.8565\n",
      "Epoch 521/600\n",
      "0s - loss: 0.0380 - acc: 0.9594 - val_loss: 0.1007 - val_acc: 0.8565\n",
      "Epoch 522/600\n",
      "0s - loss: 0.0379 - acc: 0.9594 - val_loss: 0.1047 - val_acc: 0.8696\n",
      "Epoch 523/600\n",
      "0s - loss: 0.0370 - acc: 0.9623 - val_loss: 0.1095 - val_acc: 0.8652\n",
      "Epoch 524/600\n",
      "0s - loss: 0.0378 - acc: 0.9551 - val_loss: 0.1032 - val_acc: 0.8696\n",
      "Epoch 525/600\n",
      "0s - loss: 0.0367 - acc: 0.9594 - val_loss: 0.1057 - val_acc: 0.8652\n",
      "Epoch 526/600\n",
      "0s - loss: 0.0367 - acc: 0.9623 - val_loss: 0.0999 - val_acc: 0.8522\n",
      "Epoch 527/600\n",
      "0s - loss: 0.0387 - acc: 0.9594 - val_loss: 0.1047 - val_acc: 0.8609\n",
      "Epoch 528/600\n",
      "0s - loss: 0.0368 - acc: 0.9609 - val_loss: 0.0996 - val_acc: 0.8609\n",
      "Epoch 529/600\n",
      "0s - loss: 0.0385 - acc: 0.9580 - val_loss: 0.1042 - val_acc: 0.8609\n",
      "Epoch 530/600\n",
      "0s - loss: 0.0365 - acc: 0.9594 - val_loss: 0.1052 - val_acc: 0.8609\n",
      "Epoch 531/600\n",
      "0s - loss: 0.0365 - acc: 0.9594 - val_loss: 0.1000 - val_acc: 0.8609\n",
      "Epoch 532/600\n",
      "0s - loss: 0.0379 - acc: 0.9609 - val_loss: 0.1049 - val_acc: 0.8652\n",
      "Epoch 533/600\n",
      "0s - loss: 0.0370 - acc: 0.9565 - val_loss: 0.1012 - val_acc: 0.8609\n",
      "Epoch 534/600\n",
      "0s - loss: 0.0370 - acc: 0.9623 - val_loss: 0.1044 - val_acc: 0.8609\n",
      "Epoch 535/600\n",
      "0s - loss: 0.0363 - acc: 0.9623 - val_loss: 0.1062 - val_acc: 0.8609\n",
      "Epoch 536/600\n",
      "0s - loss: 0.0371 - acc: 0.9594 - val_loss: 0.1014 - val_acc: 0.8565\n",
      "Epoch 537/600\n",
      "0s - loss: 0.0396 - acc: 0.9580 - val_loss: 0.1032 - val_acc: 0.8565\n",
      "Epoch 538/600\n",
      "0s - loss: 0.0363 - acc: 0.9623 - val_loss: 0.1079 - val_acc: 0.8609\n",
      "Epoch 539/600\n",
      "0s - loss: 0.0361 - acc: 0.9594 - val_loss: 0.1018 - val_acc: 0.8609\n",
      "Epoch 540/600\n",
      "0s - loss: 0.0362 - acc: 0.9623 - val_loss: 0.1072 - val_acc: 0.8609\n",
      "Epoch 541/600\n",
      "0s - loss: 0.0358 - acc: 0.9609 - val_loss: 0.1068 - val_acc: 0.8609\n",
      "Epoch 542/600\n",
      "0s - loss: 0.0357 - acc: 0.9594 - val_loss: 0.1037 - val_acc: 0.8565\n",
      "Epoch 543/600\n",
      "0s - loss: 0.0359 - acc: 0.9623 - val_loss: 0.1065 - val_acc: 0.8652\n",
      "Epoch 544/600\n",
      "0s - loss: 0.0359 - acc: 0.9623 - val_loss: 0.1071 - val_acc: 0.8652\n",
      "Epoch 545/600\n",
      "0s - loss: 0.0358 - acc: 0.9623 - val_loss: 0.1034 - val_acc: 0.8652\n",
      "Epoch 546/600\n",
      "0s - loss: 0.0360 - acc: 0.9580 - val_loss: 0.1008 - val_acc: 0.8609\n",
      "Epoch 547/600\n",
      "0s - loss: 0.0359 - acc: 0.9609 - val_loss: 0.1073 - val_acc: 0.8652\n",
      "Epoch 548/600\n",
      "0s - loss: 0.0358 - acc: 0.9580 - val_loss: 0.1066 - val_acc: 0.8652\n",
      "Epoch 549/600\n",
      "0s - loss: 0.0358 - acc: 0.9623 - val_loss: 0.1091 - val_acc: 0.8652\n",
      "Epoch 550/600\n",
      "0s - loss: 0.0362 - acc: 0.9580 - val_loss: 0.1081 - val_acc: 0.8652\n",
      "Epoch 551/600\n",
      "0s - loss: 0.0364 - acc: 0.9623 - val_loss: 0.1102 - val_acc: 0.8739\n",
      "Epoch 552/600\n",
      "0s - loss: 0.0371 - acc: 0.9594 - val_loss: 0.1074 - val_acc: 0.8652\n",
      "Epoch 553/600\n",
      "0s - loss: 0.0361 - acc: 0.9580 - val_loss: 0.1095 - val_acc: 0.8609\n",
      "Epoch 554/600\n",
      "0s - loss: 0.0355 - acc: 0.9594 - val_loss: 0.1049 - val_acc: 0.8609\n",
      "Epoch 555/600\n",
      "0s - loss: 0.0355 - acc: 0.9580 - val_loss: 0.1079 - val_acc: 0.8652\n",
      "Epoch 556/600\n",
      "0s - loss: 0.0350 - acc: 0.9609 - val_loss: 0.1019 - val_acc: 0.8565\n",
      "Epoch 557/600\n",
      "0s - loss: 0.0366 - acc: 0.9594 - val_loss: 0.1026 - val_acc: 0.8522\n",
      "Epoch 558/600\n",
      "0s - loss: 0.0357 - acc: 0.9609 - val_loss: 0.1062 - val_acc: 0.8652\n",
      "Epoch 559/600\n",
      "0s - loss: 0.0348 - acc: 0.9609 - val_loss: 0.1016 - val_acc: 0.8565\n",
      "Epoch 560/600\n",
      "0s - loss: 0.0356 - acc: 0.9623 - val_loss: 0.1020 - val_acc: 0.8565\n",
      "Epoch 561/600\n",
      "0s - loss: 0.0357 - acc: 0.9594 - val_loss: 0.1006 - val_acc: 0.8522\n",
      "Epoch 562/600\n",
      "0s - loss: 0.0355 - acc: 0.9594 - val_loss: 0.1092 - val_acc: 0.8609\n",
      "Epoch 563/600\n",
      "0s - loss: 0.0352 - acc: 0.9623 - val_loss: 0.1123 - val_acc: 0.8652\n",
      "Epoch 564/600\n",
      "0s - loss: 0.0361 - acc: 0.9594 - val_loss: 0.1054 - val_acc: 0.8609\n",
      "Epoch 565/600\n",
      "0s - loss: 0.0346 - acc: 0.9623 - val_loss: 0.1033 - val_acc: 0.8652\n",
      "Epoch 566/600\n",
      "0s - loss: 0.0345 - acc: 0.9623 - val_loss: 0.1102 - val_acc: 0.8609\n",
      "Epoch 567/600\n",
      "0s - loss: 0.0358 - acc: 0.9594 - val_loss: 0.1080 - val_acc: 0.8609\n",
      "Epoch 568/600\n",
      "0s - loss: 0.0352 - acc: 0.9623 - val_loss: 0.1085 - val_acc: 0.8609\n",
      "Epoch 569/600\n",
      "0s - loss: 0.0348 - acc: 0.9623 - val_loss: 0.1065 - val_acc: 0.8652\n",
      "Epoch 570/600\n",
      "0s - loss: 0.0344 - acc: 0.9623 - val_loss: 0.1032 - val_acc: 0.8522\n",
      "Epoch 571/600\n",
      "0s - loss: 0.0351 - acc: 0.9638 - val_loss: 0.1060 - val_acc: 0.8609\n",
      "Epoch 572/600\n",
      "0s - loss: 0.0349 - acc: 0.9609 - val_loss: 0.1013 - val_acc: 0.8522\n",
      "Epoch 573/600\n",
      "0s - loss: 0.0365 - acc: 0.9623 - val_loss: 0.1020 - val_acc: 0.8522\n",
      "Epoch 574/600\n",
      "0s - loss: 0.0362 - acc: 0.9594 - val_loss: 0.1029 - val_acc: 0.8522\n",
      "Epoch 575/600\n",
      "0s - loss: 0.0354 - acc: 0.9652 - val_loss: 0.1088 - val_acc: 0.8565\n",
      "Epoch 576/600\n",
      "0s - loss: 0.0342 - acc: 0.9609 - val_loss: 0.1057 - val_acc: 0.8652\n",
      "Epoch 577/600\n",
      "0s - loss: 0.0339 - acc: 0.9609 - val_loss: 0.1046 - val_acc: 0.8609\n",
      "Epoch 578/600\n",
      "0s - loss: 0.0339 - acc: 0.9609 - val_loss: 0.1044 - val_acc: 0.8609\n",
      "Epoch 579/600\n",
      "0s - loss: 0.0339 - acc: 0.9623 - val_loss: 0.1075 - val_acc: 0.8609\n",
      "Epoch 580/600\n",
      "0s - loss: 0.0340 - acc: 0.9609 - val_loss: 0.1066 - val_acc: 0.8609\n",
      "Epoch 581/600\n",
      "0s - loss: 0.0339 - acc: 0.9609 - val_loss: 0.1031 - val_acc: 0.8522\n",
      "Epoch 582/600\n",
      "0s - loss: 0.0362 - acc: 0.9580 - val_loss: 0.1013 - val_acc: 0.8522\n",
      "Epoch 583/600\n",
      "0s - loss: 0.0354 - acc: 0.9623 - val_loss: 0.1119 - val_acc: 0.8609\n",
      "Epoch 584/600\n",
      "0s - loss: 0.0344 - acc: 0.9609 - val_loss: 0.1068 - val_acc: 0.8609\n",
      "Epoch 585/600\n",
      "0s - loss: 0.0336 - acc: 0.9652 - val_loss: 0.1061 - val_acc: 0.8609\n",
      "Epoch 586/600\n",
      "0s - loss: 0.0337 - acc: 0.9609 - val_loss: 0.1056 - val_acc: 0.8609\n",
      "Epoch 587/600\n",
      "0s - loss: 0.0333 - acc: 0.9609 - val_loss: 0.1095 - val_acc: 0.8696\n",
      "Epoch 588/600\n",
      "0s - loss: 0.0335 - acc: 0.9652 - val_loss: 0.1047 - val_acc: 0.8609\n",
      "Epoch 589/600\n",
      "0s - loss: 0.0336 - acc: 0.9623 - val_loss: 0.1023 - val_acc: 0.8565\n",
      "Epoch 590/600\n",
      "0s - loss: 0.0341 - acc: 0.9667 - val_loss: 0.1042 - val_acc: 0.8565\n",
      "Epoch 591/600\n",
      "0s - loss: 0.0334 - acc: 0.9609 - val_loss: 0.1044 - val_acc: 0.8565\n",
      "Epoch 592/600\n",
      "0s - loss: 0.0342 - acc: 0.9638 - val_loss: 0.0996 - val_acc: 0.8522\n",
      "Epoch 593/600\n",
      "0s - loss: 0.0353 - acc: 0.9638 - val_loss: 0.1039 - val_acc: 0.8565\n",
      "Epoch 594/600\n",
      "0s - loss: 0.0335 - acc: 0.9638 - val_loss: 0.1037 - val_acc: 0.8522\n",
      "Epoch 595/600\n",
      "0s - loss: 0.0343 - acc: 0.9623 - val_loss: 0.1025 - val_acc: 0.8565\n",
      "Epoch 596/600\n",
      "0s - loss: 0.0337 - acc: 0.9638 - val_loss: 0.1043 - val_acc: 0.8565\n",
      "Epoch 597/600\n",
      "0s - loss: 0.0333 - acc: 0.9652 - val_loss: 0.1098 - val_acc: 0.8652\n",
      "Epoch 598/600\n",
      "0s - loss: 0.0336 - acc: 0.9667 - val_loss: 0.1028 - val_acc: 0.8609\n",
      "Epoch 599/600\n",
      "0s - loss: 0.0331 - acc: 0.9667 - val_loss: 0.1080 - val_acc: 0.8609\n",
      "Epoch 600/600\n",
      "0s - loss: 0.0329 - acc: 0.9652 - val_loss: 0.1097 - val_acc: 0.8696\n",
      "Train Score:  96.702591157\n",
      "Test Score:  89.0265353866\n"
     ]
    }
   ],
   "source": [
    "#without k best features,sigmoid and rmsprop\n",
    "m3=make_model('relu','rmsprop',x_train.shape[1],[x_train.shape[1],16],x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected 1 predicted: 0.16935   0\n",
      "expected 0 predicted: 0.756986   0\n",
      "expected 1 predicted: 0.129864   1\n",
      "expected 0 predicted: 0.766857   1\n",
      "expected 0 predicted: 1.0738   1\n",
      "expected 0 predicted: 0.90131   1\n",
      "expected 1 predicted: 0.0   1\n",
      "expected 1 predicted: 0.0   0\n",
      "expected 1 predicted: 0.0   0\n",
      "expected 1 predicted: 0.0   0\n",
      "expected 0 predicted: 0.881396   1\n",
      "expected 1 predicted: 0.301764   0\n",
      "expected 0 predicted: 0.819366   0\n",
      "expected 0 predicted: 0.823425   0\n",
      "expected 0 predicted: 0.43728   1\n",
      "expected 0 predicted: 0.653403   1\n",
      "expected 1 predicted: 0.0   0\n",
      "expected 1 predicted: 0.581686   0\n",
      "expected 1 predicted: 0.117042   1\n",
      "expected 1 predicted: 0.699658   0\n",
      "expected 0 predicted: 0.920601   1\n",
      "expected 1 predicted: 0.435114   0\n",
      "expected 1 predicted: 0.537698   0\n",
      "expected 1 predicted: 0.702074   0\n",
      "expected 0 predicted: 0.703102   1\n",
      "expected 0 predicted: 0.840468   0\n",
      "expected 1 predicted: 0.0789016   1\n",
      "expected 0 predicted: 0.951252   1\n",
      "expected 0 predicted: 0.825774   1\n",
      "expected 1 predicted: 0.0337467   0\n",
      "error 13\n"
     ]
    }
   ],
   "source": [
    "pr=m3.predict(x_test)\n",
    "u=0\n",
    "k=0\n",
    "k=0\n",
    "for u in range(len(x_test)):\n",
    "    if round(pr[u][0],1)>=0.2 and round(pr[u][0],1)<=0.75:\n",
    "        g=svmpred[u]\n",
    "    else:\n",
    "        g=round(pr[u][0],0)\n",
    "    if g!=y_test[u]:    \n",
    "        print \"expected\",y_test[u],\"predicted:\",pr[u][0],\" \",svmpred[u]\n",
    "        k=k+1\n",
    "print \"error\",k*100/len(y_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try K folds on SVM and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4242424242\n",
      "94.6564885496\n",
      "91.6030534351\n",
      "90.8396946565\n",
      "96.1832061069\n"
     ]
    }
   ],
   "source": [
    "#selecting the best  partition for testing and training....\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=7)\n",
    "kf.get_n_splits(dat)\n",
    "\n",
    "clf1 = svm.SVC(gamma=0.001, C=100)\n",
    "score=-9\n",
    "\n",
    "count =1\n",
    "\n",
    "sumy=0\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(dat):\n",
    "    fX_train, fX_test = dat[train_index],dat[test_index]\n",
    "    fy_train, fy_test = labels[train_index],labels[test_index]\n",
    "    clf1.fit(fX_train,fy_train)\n",
    "    g=clf1.score(fX_test,fy_test)*100\n",
    "    if count>2:\n",
    "        print g\n",
    "        sumy=sumy+g\n",
    "    if g>score:\n",
    "        score=g\n",
    "    count=count+1\n",
    "count=count-3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score : 93.1413370345\n",
      "best score : 96.1832061069\n"
     ]
    }
   ],
   "source": [
    "print \"cross validation score :\",sumy/(count)\n",
    "\n",
    "print \"best score :\",score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4242424242\n",
      "94.6564885496\n",
      "91.6030534351\n",
      "90.8396946565\n",
      "96.1832061069\n"
     ]
    }
   ],
   "source": [
    "#selecting the best  partition for testing and training....\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=7)\n",
    "kf.get_n_splits(X_new)\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "score=-9\n",
    "\n",
    "count =1\n",
    "\n",
    "sumy=0\n",
    "\n",
    "for train_index, test_index in kf.split(X_new):\n",
    "    fX_train, fX_test = X_new[train_index],X_new[test_index]\n",
    "    fy_train, fy_test = labels[train_index],labels[test_index]\n",
    "    clf.fit(fX_train,fy_train)\n",
    "    g=clf.score(fX_test,fy_test)*100\n",
    "    if count>2:\n",
    "        print g\n",
    "        sumy=sumy+g\n",
    "    if g>score:\n",
    "        score=g\n",
    "    count=count+1\n",
    "count=count-3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score best features: 93.1413370345\n",
      "best score best features: 96.1832061069\n"
     ]
    }
   ],
   "source": [
    "print \"cross validation score best features:\",sumy/(count)\n",
    "\n",
    "print \"best score best features:\",score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative 85\n",
      "False Positive 11\n",
      "False Negative 14\n",
      "True Positive 120\n",
      "precision : 91\n"
     ]
    }
   ],
   "source": [
    " from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,clf1.predict(x_test)).ravel()\n",
    "print \"True Negative\",tn\n",
    "print \"False Positive\",fp\n",
    "print \"False Negative\",fn\n",
    "print \"True Positive\",tp\n",
    "\n",
    "\n",
    "print \"precision :\",tp*100/(tp+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "m1=make_model('sigmoid','rmsprop',22,[220,22],btrain_x,btrain_y,btest_x,btest_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pr=m1.predict(x_test)\n",
    "u=0\n",
    "k=0\n",
    "k=0\n",
    "for u in range(len(x_test)):\n",
    "    if round(pr[u][0],1)>=0.2 and round(pr[u][0],1)<=0.75:\n",
    "        g=svmpred[u]\n",
    "    else:\n",
    "        g=round(pr[u][0],0)\n",
    "    if g!=y_test[u]:    \n",
    "        print \"expected\",y_test[u],\"predicted:\",pr[u][0],\" \",svmpred[u]\n",
    "        k=k+1\n",
    "    #if round(pr[u][0],0)==y_test[u]:\n",
    "    #    k=k+1\n",
    "print \"accuracy\",k*100/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 88.2608695652 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=120)\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "print \"Random Forest:\",rf.score(x_test,y_test)*100,\"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The accuracy of SVM has been increased,But no improvements with NN\n",
    "\n",
    "1. SVM:94.02%\n",
    "2. Logistic:89%\n",
    "3. Neural networks:92.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
